WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
Starting rank=0, seed=0, world_size=2.
[[34m2026-02-05 18:32:26[0m] Experiment directory created at results/000-DiT-XL-2
Starting rank=1, seed=1, world_size=2.
[[34m2026-02-05 18:32:27[0m] DiT Parameters: 29,690,529
[[34m2026-02-05 18:32:29[0m] Dataset contains 1,281,167 images (/data1/dataset/imagenet2012/train)
[[34m2026-02-05 18:32:29[0m] Training for 1400 epochs...
[[34m2026-02-05 18:32:29[0m] Beginning epoch 0...
[2026-02-05 18:32:42,188] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 4162753 closing signal SIGTERM
[2026-02-05 18:32:42,453] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -9) local_rank: 0 (pid: 4162752) of binary: /home/myeongjin/miniconda3/envs/diffusion_1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
train_flash.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-02-05_18:32:42
  host      : turing
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 4162752)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 4162752
========================================================
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
Starting rank=0, seed=0, world_size=2.
[[34m2026-02-05 18:35:41[0m] Experiment directory created at results/002-DiT-XL-2
Starting rank=1, seed=1, world_size=2.
[[34m2026-02-05 18:35:42[0m] DiT Parameters: 29,690,529
[[34m2026-02-05 18:35:44[0m] Dataset contains 1,281,167 images (/data1/dataset/imagenet2012/train)
[[34m2026-02-05 18:35:44[0m] Training for 1400 epochs...
[[34m2026-02-05 18:35:44[0m] Beginning epoch 0...
[[34m2026-02-05 18:36:53[0m] (step=0000100) Train Loss: 0.3628, Train Steps/Sec: 1.44
[[34m2026-02-05 18:38:02[0m] (step=0000200) Train Loss: 0.2088, Train Steps/Sec: 1.45
[[34m2026-02-05 18:39:11[0m] (step=0000300) Train Loss: 0.2072, Train Steps/Sec: 1.45
[[34m2026-02-05 18:40:20[0m] (step=0000400) Train Loss: 0.1983, Train Steps/Sec: 1.46
[[34m2026-02-05 18:41:28[0m] (step=0000500) Train Loss: 0.1917, Train Steps/Sec: 1.46
[[34m2026-02-05 18:42:37[0m] (step=0000600) Train Loss: 0.1946, Train Steps/Sec: 1.46
[[34m2026-02-05 18:43:45[0m] (step=0000700) Train Loss: 0.1888, Train Steps/Sec: 1.46
[[34m2026-02-05 18:44:54[0m] (step=0000800) Train Loss: 0.1888, Train Steps/Sec: 1.46
[[34m2026-02-05 18:46:02[0m] (step=0000900) Train Loss: 0.1867, Train Steps/Sec: 1.46
[[34m2026-02-05 18:47:11[0m] (step=0001000) Train Loss: 0.1833, Train Steps/Sec: 1.46
[[34m2026-02-05 18:48:19[0m] (step=0001100) Train Loss: 0.1863, Train Steps/Sec: 1.46
[[34m2026-02-05 18:49:28[0m] (step=0001200) Train Loss: 0.1858, Train Steps/Sec: 1.46
[[34m2026-02-05 18:50:36[0m] (step=0001300) Train Loss: 0.1869, Train Steps/Sec: 1.46
[[34m2026-02-05 18:51:45[0m] (step=0001400) Train Loss: 0.1832, Train Steps/Sec: 1.46
[[34m2026-02-05 18:52:53[0m] (step=0001500) Train Loss: 0.1848, Train Steps/Sec: 1.46
[[34m2026-02-05 18:54:02[0m] (step=0001600) Train Loss: 0.1858, Train Steps/Sec: 1.46
[[34m2026-02-05 18:55:10[0m] (step=0001700) Train Loss: 0.1866, Train Steps/Sec: 1.46
[[34m2026-02-05 18:56:19[0m] (step=0001800) Train Loss: 0.1855, Train Steps/Sec: 1.46
[[34m2026-02-05 18:57:27[0m] (step=0001900) Train Loss: 0.1770, Train Steps/Sec: 1.46
[[34m2026-02-05 18:58:36[0m] (step=0002000) Train Loss: 0.1847, Train Steps/Sec: 1.46
[[34m2026-02-05 18:59:44[0m] (step=0002100) Train Loss: 0.1799, Train Steps/Sec: 1.46
[[34m2026-02-05 19:00:53[0m] (step=0002200) Train Loss: 0.1745, Train Steps/Sec: 1.46
[[34m2026-02-05 19:02:01[0m] (step=0002300) Train Loss: 0.1803, Train Steps/Sec: 1.46
[[34m2026-02-05 19:03:09[0m] (step=0002400) Train Loss: 0.1781, Train Steps/Sec: 1.46
[[34m2026-02-05 19:04:18[0m] (step=0002500) Train Loss: 0.1768, Train Steps/Sec: 1.46
[[34m2026-02-05 19:05:26[0m] (step=0002600) Train Loss: 0.1785, Train Steps/Sec: 1.46
[[34m2026-02-05 19:06:35[0m] (step=0002700) Train Loss: 0.1737, Train Steps/Sec: 1.46
[[34m2026-02-05 19:07:43[0m] (step=0002800) Train Loss: 0.1753, Train Steps/Sec: 1.46
[[34m2026-02-05 19:08:52[0m] (step=0002900) Train Loss: 0.1780, Train Steps/Sec: 1.46
[[34m2026-02-05 19:10:00[0m] (step=0003000) Train Loss: 0.1797, Train Steps/Sec: 1.46
[[34m2026-02-05 19:11:09[0m] (step=0003100) Train Loss: 0.1793, Train Steps/Sec: 1.46
[[34m2026-02-05 19:12:17[0m] (step=0003200) Train Loss: 0.1804, Train Steps/Sec: 1.46
[[34m2026-02-05 19:13:25[0m] (step=0003300) Train Loss: 0.1777, Train Steps/Sec: 1.46
[[34m2026-02-05 19:14:34[0m] (step=0003400) Train Loss: 0.1742, Train Steps/Sec: 1.46
[[34m2026-02-05 19:15:42[0m] (step=0003500) Train Loss: 0.1689, Train Steps/Sec: 1.46
[[34m2026-02-05 19:16:51[0m] (step=0003600) Train Loss: 0.1766, Train Steps/Sec: 1.46
[[34m2026-02-05 19:17:59[0m] (step=0003700) Train Loss: 0.1754, Train Steps/Sec: 1.46
[[34m2026-02-05 19:19:08[0m] (step=0003800) Train Loss: 0.1773, Train Steps/Sec: 1.46
[[34m2026-02-05 19:20:16[0m] (step=0003900) Train Loss: 0.1768, Train Steps/Sec: 1.46
[[34m2026-02-05 19:21:25[0m] (step=0004000) Train Loss: 0.1737, Train Steps/Sec: 1.46
[[34m2026-02-05 19:22:33[0m] (step=0004100) Train Loss: 0.1774, Train Steps/Sec: 1.46
[[34m2026-02-05 19:23:42[0m] (step=0004200) Train Loss: 0.1743, Train Steps/Sec: 1.46
[[34m2026-02-05 19:24:50[0m] (step=0004300) Train Loss: 0.1774, Train Steps/Sec: 1.46
[[34m2026-02-05 19:25:59[0m] (step=0004400) Train Loss: 0.1733, Train Steps/Sec: 1.46
[[34m2026-02-05 19:27:07[0m] (step=0004500) Train Loss: 0.1745, Train Steps/Sec: 1.46
[[34m2026-02-05 19:28:16[0m] (step=0004600) Train Loss: 0.1823, Train Steps/Sec: 1.46
[[34m2026-02-05 19:29:24[0m] (step=0004700) Train Loss: 0.1738, Train Steps/Sec: 1.46
[[34m2026-02-05 19:30:32[0m] (step=0004800) Train Loss: 0.1745, Train Steps/Sec: 1.46
[[34m2026-02-05 19:31:41[0m] (step=0004900) Train Loss: 0.1747, Train Steps/Sec: 1.46
[[34m2026-02-05 19:32:49[0m] (step=0005000) Train Loss: 0.1721, Train Steps/Sec: 1.46
[[34m2026-02-05 19:33:58[0m] (step=0005100) Train Loss: 0.1723, Train Steps/Sec: 1.46
[[34m2026-02-05 19:35:06[0m] (step=0005200) Train Loss: 0.1728, Train Steps/Sec: 1.46
[[34m2026-02-05 19:36:15[0m] (step=0005300) Train Loss: 0.1713, Train Steps/Sec: 1.46
[[34m2026-02-05 19:37:23[0m] (step=0005400) Train Loss: 0.1639, Train Steps/Sec: 1.46
[[34m2026-02-05 19:38:32[0m] (step=0005500) Train Loss: 0.1732, Train Steps/Sec: 1.46
[[34m2026-02-05 19:39:40[0m] (step=0005600) Train Loss: 0.1734, Train Steps/Sec: 1.46
[[34m2026-02-05 19:40:48[0m] (step=0005700) Train Loss: 0.1736, Train Steps/Sec: 1.46
[[34m2026-02-05 19:41:57[0m] (step=0005800) Train Loss: 0.1713, Train Steps/Sec: 1.46
[[34m2026-02-05 19:43:05[0m] (step=0005900) Train Loss: 0.1685, Train Steps/Sec: 1.46
[[34m2026-02-05 19:44:14[0m] (step=0006000) Train Loss: 0.1741, Train Steps/Sec: 1.46
[[34m2026-02-05 19:45:22[0m] (step=0006100) Train Loss: 0.1652, Train Steps/Sec: 1.46
[[34m2026-02-05 19:46:31[0m] (step=0006200) Train Loss: 0.1678, Train Steps/Sec: 1.46
[[34m2026-02-05 19:47:39[0m] (step=0006300) Train Loss: 0.1710, Train Steps/Sec: 1.46
[[34m2026-02-05 19:48:47[0m] (step=0006400) Train Loss: 0.1667, Train Steps/Sec: 1.46
[[34m2026-02-05 19:49:56[0m] (step=0006500) Train Loss: 0.1680, Train Steps/Sec: 1.46
[[34m2026-02-05 19:51:04[0m] (step=0006600) Train Loss: 0.1698, Train Steps/Sec: 1.46
[[34m2026-02-05 19:52:13[0m] (step=0006700) Train Loss: 0.1743, Train Steps/Sec: 1.46
[[34m2026-02-05 19:53:21[0m] (step=0006800) Train Loss: 0.1692, Train Steps/Sec: 1.46
[[34m2026-02-05 19:54:30[0m] (step=0006900) Train Loss: 0.1709, Train Steps/Sec: 1.46
[[34m2026-02-05 19:55:38[0m] (step=0007000) Train Loss: 0.1693, Train Steps/Sec: 1.46
[[34m2026-02-05 19:56:47[0m] (step=0007100) Train Loss: 0.1676, Train Steps/Sec: 1.46
[[34m2026-02-05 19:57:55[0m] (step=0007200) Train Loss: 0.1716, Train Steps/Sec: 1.46
[[34m2026-02-05 19:59:04[0m] (step=0007300) Train Loss: 0.1701, Train Steps/Sec: 1.46
[[34m2026-02-05 20:00:12[0m] (step=0007400) Train Loss: 0.1717, Train Steps/Sec: 1.46
[[34m2026-02-05 20:01:20[0m] (step=0007500) Train Loss: 0.1693, Train Steps/Sec: 1.46
[[34m2026-02-05 20:02:29[0m] (step=0007600) Train Loss: 0.1710, Train Steps/Sec: 1.46
[[34m2026-02-05 20:03:37[0m] (step=0007700) Train Loss: 0.1666, Train Steps/Sec: 1.46
[[34m2026-02-05 20:04:46[0m] (step=0007800) Train Loss: 0.1704, Train Steps/Sec: 1.46
[[34m2026-02-05 20:05:54[0m] (step=0007900) Train Loss: 0.1694, Train Steps/Sec: 1.46
[[34m2026-02-05 20:07:03[0m] (step=0008000) Train Loss: 0.1665, Train Steps/Sec: 1.46
[[34m2026-02-05 20:08:11[0m] (step=0008100) Train Loss: 0.1690, Train Steps/Sec: 1.46
[[34m2026-02-05 20:09:20[0m] (step=0008200) Train Loss: 0.1696, Train Steps/Sec: 1.46
[[34m2026-02-05 20:10:28[0m] (step=0008300) Train Loss: 0.1680, Train Steps/Sec: 1.46
[[34m2026-02-05 20:11:37[0m] (step=0008400) Train Loss: 0.1716, Train Steps/Sec: 1.46
[[34m2026-02-05 20:12:45[0m] (step=0008500) Train Loss: 0.1722, Train Steps/Sec: 1.46
[[34m2026-02-05 20:13:54[0m] (step=0008600) Train Loss: 0.1666, Train Steps/Sec: 1.46
[[34m2026-02-05 20:15:02[0m] (step=0008700) Train Loss: 0.1662, Train Steps/Sec: 1.46
[[34m2026-02-05 20:16:11[0m] (step=0008800) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-05 20:17:19[0m] (step=0008900) Train Loss: 0.1694, Train Steps/Sec: 1.46
[[34m2026-02-05 20:18:27[0m] (step=0009000) Train Loss: 0.1622, Train Steps/Sec: 1.46
[[34m2026-02-05 20:19:36[0m] (step=0009100) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-05 20:20:44[0m] (step=0009200) Train Loss: 0.1646, Train Steps/Sec: 1.46
[[34m2026-02-05 20:21:53[0m] (step=0009300) Train Loss: 0.1665, Train Steps/Sec: 1.46
[[34m2026-02-05 20:23:01[0m] (step=0009400) Train Loss: 0.1641, Train Steps/Sec: 1.46
[[34m2026-02-05 20:24:09[0m] (step=0009500) Train Loss: 0.1637, Train Steps/Sec: 1.46
[[34m2026-02-05 20:25:18[0m] (step=0009600) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-05 20:26:26[0m] (step=0009700) Train Loss: 0.1705, Train Steps/Sec: 1.46
[[34m2026-02-05 20:27:35[0m] (step=0009800) Train Loss: 0.1686, Train Steps/Sec: 1.46
[[34m2026-02-05 20:28:43[0m] (step=0009900) Train Loss: 0.1682, Train Steps/Sec: 1.46
[[34m2026-02-05 20:29:51[0m] (step=0010000) Train Loss: 0.1621, Train Steps/Sec: 1.46
[[34m2026-02-05 20:31:00[0m] (step=0010100) Train Loss: 0.1694, Train Steps/Sec: 1.46
[[34m2026-02-05 20:32:08[0m] (step=0010200) Train Loss: 0.1700, Train Steps/Sec: 1.46
[[34m2026-02-05 20:33:16[0m] (step=0010300) Train Loss: 0.1633, Train Steps/Sec: 1.46
[[34m2026-02-05 20:34:25[0m] (step=0010400) Train Loss: 0.1640, Train Steps/Sec: 1.46
[[34m2026-02-05 20:35:33[0m] (step=0010500) Train Loss: 0.1681, Train Steps/Sec: 1.46
[[34m2026-02-05 20:36:42[0m] (step=0010600) Train Loss: 0.1710, Train Steps/Sec: 1.46
[[34m2026-02-05 20:37:50[0m] (step=0010700) Train Loss: 0.1645, Train Steps/Sec: 1.46
[[34m2026-02-05 20:38:59[0m] (step=0010800) Train Loss: 0.1659, Train Steps/Sec: 1.46
[[34m2026-02-05 20:40:07[0m] (step=0010900) Train Loss: 0.1712, Train Steps/Sec: 1.46
[[34m2026-02-05 20:41:15[0m] (step=0011000) Train Loss: 0.1695, Train Steps/Sec: 1.46
[[34m2026-02-05 20:42:24[0m] (step=0011100) Train Loss: 0.1606, Train Steps/Sec: 1.46
[[34m2026-02-05 20:43:32[0m] (step=0011200) Train Loss: 0.1658, Train Steps/Sec: 1.46
[[34m2026-02-05 20:44:41[0m] (step=0011300) Train Loss: 0.1630, Train Steps/Sec: 1.46
[[34m2026-02-05 20:45:49[0m] (step=0011400) Train Loss: 0.1641, Train Steps/Sec: 1.46
[[34m2026-02-05 20:46:58[0m] (step=0011500) Train Loss: 0.1629, Train Steps/Sec: 1.46
[[34m2026-02-05 20:48:06[0m] (step=0011600) Train Loss: 0.1612, Train Steps/Sec: 1.46
[[34m2026-02-05 20:49:15[0m] (step=0011700) Train Loss: 0.1593, Train Steps/Sec: 1.46
[[34m2026-02-05 20:50:23[0m] (step=0011800) Train Loss: 0.1622, Train Steps/Sec: 1.46
[[34m2026-02-05 20:51:31[0m] (step=0011900) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-05 20:52:40[0m] (step=0012000) Train Loss: 0.1644, Train Steps/Sec: 1.46
[[34m2026-02-05 20:53:48[0m] (step=0012100) Train Loss: 0.1680, Train Steps/Sec: 1.46
[[34m2026-02-05 20:54:57[0m] (step=0012200) Train Loss: 0.1632, Train Steps/Sec: 1.46
[[34m2026-02-05 20:56:05[0m] (step=0012300) Train Loss: 0.1685, Train Steps/Sec: 1.46
[[34m2026-02-05 20:57:14[0m] (step=0012400) Train Loss: 0.1649, Train Steps/Sec: 1.46
[[34m2026-02-05 20:58:22[0m] (step=0012500) Train Loss: 0.1688, Train Steps/Sec: 1.46
[[34m2026-02-05 20:59:31[0m] (step=0012600) Train Loss: 0.1664, Train Steps/Sec: 1.46
[[34m2026-02-05 21:00:39[0m] (step=0012700) Train Loss: 0.1640, Train Steps/Sec: 1.46
[[34m2026-02-05 21:01:48[0m] (step=0012800) Train Loss: 0.1677, Train Steps/Sec: 1.46
[[34m2026-02-05 21:02:56[0m] (step=0012900) Train Loss: 0.1651, Train Steps/Sec: 1.46
[[34m2026-02-05 21:04:04[0m] (step=0013000) Train Loss: 0.1599, Train Steps/Sec: 1.46
[[34m2026-02-05 21:05:13[0m] (step=0013100) Train Loss: 0.1642, Train Steps/Sec: 1.46
[[34m2026-02-05 21:06:21[0m] (step=0013200) Train Loss: 0.1617, Train Steps/Sec: 1.46
[[34m2026-02-05 21:07:30[0m] (step=0013300) Train Loss: 0.1711, Train Steps/Sec: 1.46
[[34m2026-02-05 21:08:38[0m] (step=0013400) Train Loss: 0.1651, Train Steps/Sec: 1.46
[[34m2026-02-05 21:09:47[0m] (step=0013500) Train Loss: 0.1700, Train Steps/Sec: 1.46
[[34m2026-02-05 21:10:55[0m] (step=0013600) Train Loss: 0.1639, Train Steps/Sec: 1.46
[[34m2026-02-05 21:12:03[0m] (step=0013700) Train Loss: 0.1695, Train Steps/Sec: 1.46
[[34m2026-02-05 21:13:12[0m] (step=0013800) Train Loss: 0.1624, Train Steps/Sec: 1.46
[[34m2026-02-05 21:14:20[0m] (step=0013900) Train Loss: 0.1626, Train Steps/Sec: 1.46
[[34m2026-02-05 21:15:29[0m] (step=0014000) Train Loss: 0.1744, Train Steps/Sec: 1.46
[[34m2026-02-05 21:16:37[0m] (step=0014100) Train Loss: 0.1665, Train Steps/Sec: 1.46
[[34m2026-02-05 21:17:45[0m] (step=0014200) Train Loss: 0.1633, Train Steps/Sec: 1.46
[[34m2026-02-05 21:18:54[0m] (step=0014300) Train Loss: 0.1606, Train Steps/Sec: 1.46
[[34m2026-02-05 21:20:02[0m] (step=0014400) Train Loss: 0.1671, Train Steps/Sec: 1.46
[[34m2026-02-05 21:21:11[0m] (step=0014500) Train Loss: 0.1681, Train Steps/Sec: 1.46
[[34m2026-02-05 21:22:19[0m] (step=0014600) Train Loss: 0.1609, Train Steps/Sec: 1.46
[[34m2026-02-05 21:23:27[0m] (step=0014700) Train Loss: 0.1613, Train Steps/Sec: 1.46
[[34m2026-02-05 21:24:36[0m] (step=0014800) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-05 21:25:44[0m] (step=0014900) Train Loss: 0.1605, Train Steps/Sec: 1.46
[[34m2026-02-05 21:26:53[0m] (step=0015000) Train Loss: 0.1679, Train Steps/Sec: 1.46
[[34m2026-02-05 21:28:01[0m] (step=0015100) Train Loss: 0.1608, Train Steps/Sec: 1.46
[[34m2026-02-05 21:29:10[0m] (step=0015200) Train Loss: 0.1602, Train Steps/Sec: 1.46
[[34m2026-02-05 21:30:18[0m] (step=0015300) Train Loss: 0.1702, Train Steps/Sec: 1.46
[[34m2026-02-05 21:31:26[0m] (step=0015400) Train Loss: 0.1610, Train Steps/Sec: 1.46
[[34m2026-02-05 21:32:35[0m] (step=0015500) Train Loss: 0.1654, Train Steps/Sec: 1.46
[[34m2026-02-05 21:33:43[0m] (step=0015600) Train Loss: 0.1666, Train Steps/Sec: 1.46
[[34m2026-02-05 21:34:52[0m] (step=0015700) Train Loss: 0.1604, Train Steps/Sec: 1.46
[[34m2026-02-05 21:36:00[0m] (step=0015800) Train Loss: 0.1566, Train Steps/Sec: 1.46
[[34m2026-02-05 21:37:08[0m] (step=0015900) Train Loss: 0.1703, Train Steps/Sec: 1.46
[[34m2026-02-05 21:38:17[0m] (step=0016000) Train Loss: 0.1689, Train Steps/Sec: 1.46
[[34m2026-02-05 21:39:25[0m] (step=0016100) Train Loss: 0.1679, Train Steps/Sec: 1.46
[[34m2026-02-05 21:40:34[0m] (step=0016200) Train Loss: 0.1657, Train Steps/Sec: 1.46
[[34m2026-02-05 21:41:42[0m] (step=0016300) Train Loss: 0.1668, Train Steps/Sec: 1.46
[[34m2026-02-05 21:42:51[0m] (step=0016400) Train Loss: 0.1597, Train Steps/Sec: 1.46
[[34m2026-02-05 21:43:59[0m] (step=0016500) Train Loss: 0.1652, Train Steps/Sec: 1.46
[[34m2026-02-05 21:45:08[0m] (step=0016600) Train Loss: 0.1663, Train Steps/Sec: 1.46
[[34m2026-02-05 21:46:16[0m] (step=0016700) Train Loss: 0.1662, Train Steps/Sec: 1.46
[[34m2026-02-05 21:47:24[0m] (step=0016800) Train Loss: 0.1653, Train Steps/Sec: 1.46
[[34m2026-02-05 21:48:33[0m] (step=0016900) Train Loss: 0.1655, Train Steps/Sec: 1.46
[[34m2026-02-05 21:49:41[0m] (step=0017000) Train Loss: 0.1578, Train Steps/Sec: 1.46
[[34m2026-02-05 21:50:50[0m] (step=0017100) Train Loss: 0.1641, Train Steps/Sec: 1.46
[[34m2026-02-05 21:51:58[0m] (step=0017200) Train Loss: 0.1598, Train Steps/Sec: 1.46
[[34m2026-02-05 21:53:07[0m] (step=0017300) Train Loss: 0.1615, Train Steps/Sec: 1.46
[[34m2026-02-05 21:54:15[0m] (step=0017400) Train Loss: 0.1581, Train Steps/Sec: 1.46
[[34m2026-02-05 21:55:23[0m] (step=0017500) Train Loss: 0.1656, Train Steps/Sec: 1.46
[[34m2026-02-05 21:56:32[0m] (step=0017600) Train Loss: 0.1653, Train Steps/Sec: 1.46
[[34m2026-02-05 21:57:40[0m] (step=0017700) Train Loss: 0.1645, Train Steps/Sec: 1.46
[[34m2026-02-05 21:58:49[0m] (step=0017800) Train Loss: 0.1544, Train Steps/Sec: 1.46
[[34m2026-02-05 21:59:57[0m] (step=0017900) Train Loss: 0.1573, Train Steps/Sec: 1.46
[[34m2026-02-05 22:01:06[0m] (step=0018000) Train Loss: 0.1594, Train Steps/Sec: 1.46
[[34m2026-02-05 22:02:14[0m] (step=0018100) Train Loss: 0.1595, Train Steps/Sec: 1.46
[[34m2026-02-05 22:03:23[0m] (step=0018200) Train Loss: 0.1583, Train Steps/Sec: 1.46
[[34m2026-02-05 22:04:31[0m] (step=0018300) Train Loss: 0.1629, Train Steps/Sec: 1.46
[[34m2026-02-05 22:05:39[0m] (step=0018400) Train Loss: 0.1638, Train Steps/Sec: 1.46
[[34m2026-02-05 22:06:48[0m] (step=0018500) Train Loss: 0.1575, Train Steps/Sec: 1.46
[[34m2026-02-05 22:07:56[0m] (step=0018600) Train Loss: 0.1603, Train Steps/Sec: 1.46
[[34m2026-02-05 22:09:05[0m] (step=0018700) Train Loss: 0.1561, Train Steps/Sec: 1.46
[[34m2026-02-05 22:10:13[0m] (step=0018800) Train Loss: 0.1670, Train Steps/Sec: 1.46
[[34m2026-02-05 22:11:21[0m] (step=0018900) Train Loss: 0.1597, Train Steps/Sec: 1.46
[[34m2026-02-05 22:12:30[0m] (step=0019000) Train Loss: 0.1590, Train Steps/Sec: 1.46
[[34m2026-02-05 22:13:38[0m] (step=0019100) Train Loss: 0.1675, Train Steps/Sec: 1.46
[[34m2026-02-05 22:14:47[0m] (step=0019200) Train Loss: 0.1644, Train Steps/Sec: 1.46
[[34m2026-02-05 22:15:55[0m] (step=0019300) Train Loss: 0.1596, Train Steps/Sec: 1.46
[[34m2026-02-05 22:17:04[0m] (step=0019400) Train Loss: 0.1657, Train Steps/Sec: 1.46
[[34m2026-02-05 22:18:12[0m] (step=0019500) Train Loss: 0.1594, Train Steps/Sec: 1.46
[[34m2026-02-05 22:19:20[0m] (step=0019600) Train Loss: 0.1638, Train Steps/Sec: 1.46
[[34m2026-02-05 22:20:29[0m] (step=0019700) Train Loss: 0.1678, Train Steps/Sec: 1.46
[[34m2026-02-05 22:21:37[0m] (step=0019800) Train Loss: 0.1612, Train Steps/Sec: 1.46
[[34m2026-02-05 22:22:46[0m] (step=0019900) Train Loss: 0.1606, Train Steps/Sec: 1.46
[[34m2026-02-05 22:23:54[0m] (step=0020000) Train Loss: 0.1668, Train Steps/Sec: 1.46
[[34m2026-02-05 22:24:07[0m] Beginning epoch 1...
[[34m2026-02-05 22:25:04[0m] (step=0020100) Train Loss: 0.1676, Train Steps/Sec: 1.43
[[34m2026-02-05 22:26:12[0m] (step=0020200) Train Loss: 0.1637, Train Steps/Sec: 1.46
[[34m2026-02-05 22:27:21[0m] (step=0020300) Train Loss: 0.1696, Train Steps/Sec: 1.46
[[34m2026-02-05 22:28:29[0m] (step=0020400) Train Loss: 0.1614, Train Steps/Sec: 1.46
[[34m2026-02-05 22:29:38[0m] (step=0020500) Train Loss: 0.1635, Train Steps/Sec: 1.46
[[34m2026-02-05 22:30:46[0m] (step=0020600) Train Loss: 0.1596, Train Steps/Sec: 1.46
[[34m2026-02-05 22:31:54[0m] (step=0020700) Train Loss: 0.1618, Train Steps/Sec: 1.46
[[34m2026-02-05 22:33:03[0m] (step=0020800) Train Loss: 0.1607, Train Steps/Sec: 1.46
[[34m2026-02-05 22:34:11[0m] (step=0020900) Train Loss: 0.1627, Train Steps/Sec: 1.46
[[34m2026-02-05 22:35:20[0m] (step=0021000) Train Loss: 0.1628, Train Steps/Sec: 1.46
[[34m2026-02-05 22:36:28[0m] (step=0021100) Train Loss: 0.1608, Train Steps/Sec: 1.46
[[34m2026-02-05 22:37:37[0m] (step=0021200) Train Loss: 0.1582, Train Steps/Sec: 1.46
[[34m2026-02-05 22:38:45[0m] (step=0021300) Train Loss: 0.1639, Train Steps/Sec: 1.46
[[34m2026-02-05 22:39:54[0m] (step=0021400) Train Loss: 0.1607, Train Steps/Sec: 1.46
[[34m2026-02-05 22:41:02[0m] (step=0021500) Train Loss: 0.1601, Train Steps/Sec: 1.46
[[34m2026-02-05 22:42:10[0m] (step=0021600) Train Loss: 0.1585, Train Steps/Sec: 1.46
[[34m2026-02-05 22:43:19[0m] (step=0021700) Train Loss: 0.1561, Train Steps/Sec: 1.46
[[34m2026-02-05 22:44:27[0m] (step=0021800) Train Loss: 0.1613, Train Steps/Sec: 1.46
[[34m2026-02-05 22:45:36[0m] (step=0021900) Train Loss: 0.1592, Train Steps/Sec: 1.46
[[34m2026-02-05 22:46:44[0m] (step=0022000) Train Loss: 0.1598, Train Steps/Sec: 1.46
[[34m2026-02-05 22:47:52[0m] (step=0022100) Train Loss: 0.1704, Train Steps/Sec: 1.46
[[34m2026-02-05 22:49:01[0m] (step=0022200) Train Loss: 0.1646, Train Steps/Sec: 1.46
[[34m2026-02-05 22:50:09[0m] (step=0022300) Train Loss: 0.1604, Train Steps/Sec: 1.46
[[34m2026-02-05 22:51:18[0m] (step=0022400) Train Loss: 0.1589, Train Steps/Sec: 1.46
[[34m2026-02-05 22:52:26[0m] (step=0022500) Train Loss: 0.1619, Train Steps/Sec: 1.46
[[34m2026-02-05 22:53:35[0m] (step=0022600) Train Loss: 0.1620, Train Steps/Sec: 1.46
[[34m2026-02-05 22:54:43[0m] (step=0022700) Train Loss: 0.1576, Train Steps/Sec: 1.46
[[34m2026-02-05 22:55:51[0m] (step=0022800) Train Loss: 0.1646, Train Steps/Sec: 1.46
[[34m2026-02-05 22:57:00[0m] (step=0022900) Train Loss: 0.1624, Train Steps/Sec: 1.46
[[34m2026-02-05 22:58:08[0m] (step=0023000) Train Loss: 0.1635, Train Steps/Sec: 1.46
[[34m2026-02-05 22:59:17[0m] (step=0023100) Train Loss: 0.1615, Train Steps/Sec: 1.46
[[34m2026-02-05 23:00:25[0m] (step=0023200) Train Loss: 0.1637, Train Steps/Sec: 1.46
[[34m2026-02-05 23:01:34[0m] (step=0023300) Train Loss: 0.1637, Train Steps/Sec: 1.46
[[34m2026-02-05 23:02:42[0m] (step=0023400) Train Loss: 0.1587, Train Steps/Sec: 1.46
[[34m2026-02-05 23:03:51[0m] (step=0023500) Train Loss: 0.1566, Train Steps/Sec: 1.46
[[34m2026-02-05 23:04:59[0m] (step=0023600) Train Loss: 0.1673, Train Steps/Sec: 1.46
[[34m2026-02-05 23:06:08[0m] (step=0023700) Train Loss: 0.1610, Train Steps/Sec: 1.46
[[34m2026-02-05 23:07:16[0m] (step=0023800) Train Loss: 0.1650, Train Steps/Sec: 1.46
[[34m2026-02-05 23:08:24[0m] (step=0023900) Train Loss: 0.1659, Train Steps/Sec: 1.46
[[34m2026-02-05 23:09:33[0m] (step=0024000) Train Loss: 0.1605, Train Steps/Sec: 1.46
[2026-02-05 23:09:42,853] torch.distributed.elastic.agent.server.api: [WARNING] Received 1 death signal, shutting down workers
[2026-02-05 23:09:42,855] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 4164621 closing signal SIGHUP
[2026-02-05 23:09:42,855] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 4164622 closing signal SIGHUP
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 727, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 868, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 4164551 got signal: 1
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
Starting rank=0, seed=0, world_size=2.
[[34m2026-02-06 13:38:39[0m] Experiment directory created at results/003-DiT-XL-2
Starting rank=1, seed=1, world_size=2.
[[34m2026-02-06 13:38:41[0m] DiT Parameters: 29,690,529
[[34m2026-02-06 13:38:43[0m] Dataset contains 1,281,167 images (/data1/dataset/imagenet2012/train)
[[34m2026-02-06 13:38:43[0m] Training for 1400 epochs...
[[34m2026-02-06 13:38:43[0m] Beginning epoch 0...
[[34m2026-02-06 13:39:52[0m] (step=0000100) Train Loss: 0.3628, Train Steps/Sec: 1.45
[[34m2026-02-06 13:41:01[0m] (step=0000200) Train Loss: 0.2088, Train Steps/Sec: 1.46
[[34m2026-02-06 13:42:09[0m] (step=0000300) Train Loss: 0.2072, Train Steps/Sec: 1.45
[[34m2026-02-06 13:43:18[0m] (step=0000400) Train Loss: 0.1983, Train Steps/Sec: 1.46
[[34m2026-02-06 13:44:27[0m] (step=0000500) Train Loss: 0.1917, Train Steps/Sec: 1.46
[[34m2026-02-06 13:45:35[0m] (step=0000600) Train Loss: 0.1946, Train Steps/Sec: 1.46
[[34m2026-02-06 13:46:44[0m] (step=0000700) Train Loss: 0.1888, Train Steps/Sec: 1.46
[[34m2026-02-06 13:47:53[0m] (step=0000800) Train Loss: 0.1888, Train Steps/Sec: 1.46
[[34m2026-02-06 13:49:01[0m] (step=0000900) Train Loss: 0.1867, Train Steps/Sec: 1.46
[[34m2026-02-06 13:50:10[0m] (step=0001000) Train Loss: 0.1833, Train Steps/Sec: 1.46
[[34m2026-02-06 13:51:18[0m] (step=0001100) Train Loss: 0.1863, Train Steps/Sec: 1.46
[[34m2026-02-06 13:52:27[0m] (step=0001200) Train Loss: 0.1858, Train Steps/Sec: 1.46
[[34m2026-02-06 13:53:35[0m] (step=0001300) Train Loss: 0.1869, Train Steps/Sec: 1.46
[[34m2026-02-06 13:54:45[0m] (step=0001400) Train Loss: 0.1832, Train Steps/Sec: 1.43
[[34m2026-02-06 13:55:54[0m] (step=0001500) Train Loss: 0.1848, Train Steps/Sec: 1.46
[[34m2026-02-06 13:57:02[0m] (step=0001600) Train Loss: 0.1858, Train Steps/Sec: 1.46
[[34m2026-02-06 13:58:11[0m] (step=0001700) Train Loss: 0.1866, Train Steps/Sec: 1.46
[[34m2026-02-06 13:59:19[0m] (step=0001800) Train Loss: 0.1855, Train Steps/Sec: 1.46
[[34m2026-02-06 14:00:28[0m] (step=0001900) Train Loss: 0.1770, Train Steps/Sec: 1.46
[[34m2026-02-06 14:01:36[0m] (step=0002000) Train Loss: 0.1847, Train Steps/Sec: 1.46
[[34m2026-02-06 14:02:46[0m] (step=0002100) Train Loss: 0.1799, Train Steps/Sec: 1.44
[[34m2026-02-06 14:03:54[0m] (step=0002200) Train Loss: 0.1745, Train Steps/Sec: 1.46
[[34m2026-02-06 14:05:02[0m] (step=0002300) Train Loss: 0.1803, Train Steps/Sec: 1.46
[[34m2026-02-06 14:06:11[0m] (step=0002400) Train Loss: 0.1781, Train Steps/Sec: 1.46
[[34m2026-02-06 14:07:20[0m] (step=0002500) Train Loss: 0.1768, Train Steps/Sec: 1.46
[[34m2026-02-06 14:08:28[0m] (step=0002600) Train Loss: 0.1785, Train Steps/Sec: 1.46
[[34m2026-02-06 14:09:36[0m] (step=0002700) Train Loss: 0.1737, Train Steps/Sec: 1.46
[[34m2026-02-06 14:10:45[0m] (step=0002800) Train Loss: 0.1753, Train Steps/Sec: 1.46
[[34m2026-02-06 14:11:53[0m] (step=0002900) Train Loss: 0.1780, Train Steps/Sec: 1.46
[[34m2026-02-06 14:13:02[0m] (step=0003000) Train Loss: 0.1797, Train Steps/Sec: 1.46
[[34m2026-02-06 14:14:10[0m] (step=0003100) Train Loss: 0.1793, Train Steps/Sec: 1.46
[[34m2026-02-06 14:15:19[0m] (step=0003200) Train Loss: 0.1804, Train Steps/Sec: 1.46
[[34m2026-02-06 14:16:27[0m] (step=0003300) Train Loss: 0.1777, Train Steps/Sec: 1.46
[[34m2026-02-06 14:17:36[0m] (step=0003400) Train Loss: 0.1742, Train Steps/Sec: 1.46
[[34m2026-02-06 14:18:44[0m] (step=0003500) Train Loss: 0.1689, Train Steps/Sec: 1.46
[[34m2026-02-06 14:19:53[0m] (step=0003600) Train Loss: 0.1766, Train Steps/Sec: 1.46
[[34m2026-02-06 14:21:01[0m] (step=0003700) Train Loss: 0.1754, Train Steps/Sec: 1.46
[[34m2026-02-06 14:22:10[0m] (step=0003800) Train Loss: 0.1773, Train Steps/Sec: 1.46
[[34m2026-02-06 14:23:18[0m] (step=0003900) Train Loss: 0.1768, Train Steps/Sec: 1.46
[[34m2026-02-06 14:24:26[0m] (step=0004000) Train Loss: 0.1737, Train Steps/Sec: 1.46
[[34m2026-02-06 14:25:35[0m] (step=0004100) Train Loss: 0.1774, Train Steps/Sec: 1.46
[[34m2026-02-06 14:26:43[0m] (step=0004200) Train Loss: 0.1743, Train Steps/Sec: 1.46
[[34m2026-02-06 14:27:52[0m] (step=0004300) Train Loss: 0.1774, Train Steps/Sec: 1.46
[[34m2026-02-06 14:29:00[0m] (step=0004400) Train Loss: 0.1733, Train Steps/Sec: 1.46
[[34m2026-02-06 14:30:09[0m] (step=0004500) Train Loss: 0.1745, Train Steps/Sec: 1.46
[[34m2026-02-06 14:31:17[0m] (step=0004600) Train Loss: 0.1823, Train Steps/Sec: 1.46
[[34m2026-02-06 14:32:25[0m] (step=0004700) Train Loss: 0.1738, Train Steps/Sec: 1.46
[[34m2026-02-06 14:33:34[0m] (step=0004800) Train Loss: 0.1745, Train Steps/Sec: 1.46
[[34m2026-02-06 14:34:42[0m] (step=0004900) Train Loss: 0.1747, Train Steps/Sec: 1.46
[[34m2026-02-06 14:35:51[0m] (step=0005000) Train Loss: 0.1721, Train Steps/Sec: 1.46
[[34m2026-02-06 14:36:59[0m] (step=0005100) Train Loss: 0.1723, Train Steps/Sec: 1.46
[[34m2026-02-06 14:38:08[0m] (step=0005200) Train Loss: 0.1728, Train Steps/Sec: 1.46
[[34m2026-02-06 14:39:16[0m] (step=0005300) Train Loss: 0.1713, Train Steps/Sec: 1.46
[[34m2026-02-06 14:40:25[0m] (step=0005400) Train Loss: 0.1639, Train Steps/Sec: 1.46
[[34m2026-02-06 14:41:33[0m] (step=0005500) Train Loss: 0.1732, Train Steps/Sec: 1.46
[[34m2026-02-06 14:42:42[0m] (step=0005600) Train Loss: 0.1734, Train Steps/Sec: 1.46
[[34m2026-02-06 14:43:50[0m] (step=0005700) Train Loss: 0.1736, Train Steps/Sec: 1.46
[[34m2026-02-06 14:44:59[0m] (step=0005800) Train Loss: 0.1713, Train Steps/Sec: 1.46
[[34m2026-02-06 14:46:07[0m] (step=0005900) Train Loss: 0.1685, Train Steps/Sec: 1.46
[[34m2026-02-06 14:47:15[0m] (step=0006000) Train Loss: 0.1741, Train Steps/Sec: 1.46
[[34m2026-02-06 14:48:24[0m] (step=0006100) Train Loss: 0.1652, Train Steps/Sec: 1.46
[[34m2026-02-06 14:49:32[0m] (step=0006200) Train Loss: 0.1678, Train Steps/Sec: 1.46
[[34m2026-02-06 14:50:41[0m] (step=0006300) Train Loss: 0.1710, Train Steps/Sec: 1.46
[[34m2026-02-06 14:51:49[0m] (step=0006400) Train Loss: 0.1667, Train Steps/Sec: 1.46
[[34m2026-02-06 14:52:58[0m] (step=0006500) Train Loss: 0.1680, Train Steps/Sec: 1.46
[[34m2026-02-06 14:54:06[0m] (step=0006600) Train Loss: 0.1698, Train Steps/Sec: 1.46
[[34m2026-02-06 14:55:15[0m] (step=0006700) Train Loss: 0.1743, Train Steps/Sec: 1.46
[[34m2026-02-06 14:56:23[0m] (step=0006800) Train Loss: 0.1692, Train Steps/Sec: 1.46
[[34m2026-02-06 14:57:32[0m] (step=0006900) Train Loss: 0.1709, Train Steps/Sec: 1.46
[[34m2026-02-06 14:58:40[0m] (step=0007000) Train Loss: 0.1693, Train Steps/Sec: 1.46
[[34m2026-02-06 14:59:49[0m] (step=0007100) Train Loss: 0.1676, Train Steps/Sec: 1.46
[[34m2026-02-06 15:00:57[0m] (step=0007200) Train Loss: 0.1716, Train Steps/Sec: 1.46
[[34m2026-02-06 15:02:05[0m] (step=0007300) Train Loss: 0.1701, Train Steps/Sec: 1.46
[[34m2026-02-06 15:03:14[0m] (step=0007400) Train Loss: 0.1717, Train Steps/Sec: 1.46
[[34m2026-02-06 15:04:22[0m] (step=0007500) Train Loss: 0.1693, Train Steps/Sec: 1.46
[[34m2026-02-06 15:05:30[0m] (step=0007600) Train Loss: 0.1710, Train Steps/Sec: 1.46
[[34m2026-02-06 15:06:39[0m] (step=0007700) Train Loss: 0.1666, Train Steps/Sec: 1.46
[[34m2026-02-06 15:07:47[0m] (step=0007800) Train Loss: 0.1704, Train Steps/Sec: 1.46
[[34m2026-02-06 15:08:56[0m] (step=0007900) Train Loss: 0.1694, Train Steps/Sec: 1.46
[[34m2026-02-06 15:10:04[0m] (step=0008000) Train Loss: 0.1665, Train Steps/Sec: 1.46
[[34m2026-02-06 15:11:13[0m] (step=0008100) Train Loss: 0.1690, Train Steps/Sec: 1.46
[[34m2026-02-06 15:12:21[0m] (step=0008200) Train Loss: 0.1696, Train Steps/Sec: 1.46
[[34m2026-02-06 15:13:30[0m] (step=0008300) Train Loss: 0.1680, Train Steps/Sec: 1.46
[[34m2026-02-06 15:14:38[0m] (step=0008400) Train Loss: 0.1716, Train Steps/Sec: 1.46
[[34m2026-02-06 15:15:46[0m] (step=0008500) Train Loss: 0.1722, Train Steps/Sec: 1.46
[[34m2026-02-06 15:16:55[0m] (step=0008600) Train Loss: 0.1666, Train Steps/Sec: 1.46
[[34m2026-02-06 15:18:03[0m] (step=0008700) Train Loss: 0.1662, Train Steps/Sec: 1.46
[[34m2026-02-06 15:19:12[0m] (step=0008800) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-06 15:20:20[0m] (step=0008900) Train Loss: 0.1694, Train Steps/Sec: 1.46
[[34m2026-02-06 15:21:29[0m] (step=0009000) Train Loss: 0.1622, Train Steps/Sec: 1.46
[[34m2026-02-06 15:22:37[0m] (step=0009100) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-06 15:23:45[0m] (step=0009200) Train Loss: 0.1646, Train Steps/Sec: 1.46
[[34m2026-02-06 15:24:54[0m] (step=0009300) Train Loss: 0.1665, Train Steps/Sec: 1.46
[[34m2026-02-06 15:26:02[0m] (step=0009400) Train Loss: 0.1641, Train Steps/Sec: 1.46
[[34m2026-02-06 15:27:11[0m] (step=0009500) Train Loss: 0.1637, Train Steps/Sec: 1.46
[[34m2026-02-06 15:28:19[0m] (step=0009600) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-06 15:29:27[0m] (step=0009700) Train Loss: 0.1705, Train Steps/Sec: 1.46
[[34m2026-02-06 15:30:36[0m] (step=0009800) Train Loss: 0.1686, Train Steps/Sec: 1.46
[[34m2026-02-06 15:31:44[0m] (step=0009900) Train Loss: 0.1682, Train Steps/Sec: 1.46
[[34m2026-02-06 15:32:53[0m] (step=0010000) Train Loss: 0.1621, Train Steps/Sec: 1.46
[[34m2026-02-06 15:34:01[0m] (step=0010100) Train Loss: 0.1694, Train Steps/Sec: 1.46
[[34m2026-02-06 15:35:10[0m] (step=0010200) Train Loss: 0.1700, Train Steps/Sec: 1.46
[[34m2026-02-06 15:36:18[0m] (step=0010300) Train Loss: 0.1633, Train Steps/Sec: 1.46
[[34m2026-02-06 15:37:27[0m] (step=0010400) Train Loss: 0.1640, Train Steps/Sec: 1.46
[[34m2026-02-06 15:38:35[0m] (step=0010500) Train Loss: 0.1681, Train Steps/Sec: 1.46
[[34m2026-02-06 15:39:43[0m] (step=0010600) Train Loss: 0.1710, Train Steps/Sec: 1.46
[[34m2026-02-06 15:40:52[0m] (step=0010700) Train Loss: 0.1645, Train Steps/Sec: 1.46
[[34m2026-02-06 15:42:00[0m] (step=0010800) Train Loss: 0.1659, Train Steps/Sec: 1.46
[[34m2026-02-06 15:43:09[0m] (step=0010900) Train Loss: 0.1712, Train Steps/Sec: 1.46
[[34m2026-02-06 15:44:17[0m] (step=0011000) Train Loss: 0.1695, Train Steps/Sec: 1.46
[[34m2026-02-06 15:45:26[0m] (step=0011100) Train Loss: 0.1606, Train Steps/Sec: 1.46
[[34m2026-02-06 15:46:34[0m] (step=0011200) Train Loss: 0.1658, Train Steps/Sec: 1.46
[[34m2026-02-06 15:47:42[0m] (step=0011300) Train Loss: 0.1630, Train Steps/Sec: 1.46
[[34m2026-02-06 15:48:51[0m] (step=0011400) Train Loss: 0.1641, Train Steps/Sec: 1.46
[[34m2026-02-06 15:49:59[0m] (step=0011500) Train Loss: 0.1629, Train Steps/Sec: 1.46
[[34m2026-02-06 15:51:08[0m] (step=0011600) Train Loss: 0.1612, Train Steps/Sec: 1.46
[[34m2026-02-06 15:52:16[0m] (step=0011700) Train Loss: 0.1593, Train Steps/Sec: 1.46
[[34m2026-02-06 15:53:25[0m] (step=0011800) Train Loss: 0.1622, Train Steps/Sec: 1.46
[[34m2026-02-06 15:54:33[0m] (step=0011900) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-06 15:55:42[0m] (step=0012000) Train Loss: 0.1644, Train Steps/Sec: 1.46
[[34m2026-02-06 15:56:50[0m] (step=0012100) Train Loss: 0.1680, Train Steps/Sec: 1.46
[[34m2026-02-06 15:57:59[0m] (step=0012200) Train Loss: 0.1632, Train Steps/Sec: 1.46
[[34m2026-02-06 15:59:07[0m] (step=0012300) Train Loss: 0.1685, Train Steps/Sec: 1.46
[[34m2026-02-06 16:00:15[0m] (step=0012400) Train Loss: 0.1649, Train Steps/Sec: 1.46
[[34m2026-02-06 16:01:24[0m] (step=0012500) Train Loss: 0.1688, Train Steps/Sec: 1.46
[[34m2026-02-06 16:02:32[0m] (step=0012600) Train Loss: 0.1664, Train Steps/Sec: 1.46
[[34m2026-02-06 16:03:40[0m] (step=0012700) Train Loss: 0.1640, Train Steps/Sec: 1.46
[[34m2026-02-06 16:04:49[0m] (step=0012800) Train Loss: 0.1677, Train Steps/Sec: 1.46
[[34m2026-02-06 16:05:57[0m] (step=0012900) Train Loss: 0.1651, Train Steps/Sec: 1.46
[[34m2026-02-06 16:07:06[0m] (step=0013000) Train Loss: 0.1599, Train Steps/Sec: 1.46
[[34m2026-02-06 16:08:14[0m] (step=0013100) Train Loss: 0.1642, Train Steps/Sec: 1.46
[[34m2026-02-06 16:09:22[0m] (step=0013200) Train Loss: 0.1617, Train Steps/Sec: 1.46
[[34m2026-02-06 16:10:31[0m] (step=0013300) Train Loss: 0.1711, Train Steps/Sec: 1.46
[[34m2026-02-06 16:11:39[0m] (step=0013400) Train Loss: 0.1651, Train Steps/Sec: 1.46
[[34m2026-02-06 16:12:47[0m] (step=0013500) Train Loss: 0.1700, Train Steps/Sec: 1.46
[[34m2026-02-06 16:13:56[0m] (step=0013600) Train Loss: 0.1639, Train Steps/Sec: 1.46
[[34m2026-02-06 16:15:04[0m] (step=0013700) Train Loss: 0.1695, Train Steps/Sec: 1.46
[[34m2026-02-06 16:16:13[0m] (step=0013800) Train Loss: 0.1624, Train Steps/Sec: 1.46
[[34m2026-02-06 16:17:21[0m] (step=0013900) Train Loss: 0.1626, Train Steps/Sec: 1.46
[[34m2026-02-06 16:18:30[0m] (step=0014000) Train Loss: 0.1744, Train Steps/Sec: 1.46
[[34m2026-02-06 16:19:38[0m] (step=0014100) Train Loss: 0.1665, Train Steps/Sec: 1.46
[[34m2026-02-06 16:20:46[0m] (step=0014200) Train Loss: 0.1633, Train Steps/Sec: 1.46
[[34m2026-02-06 16:21:55[0m] (step=0014300) Train Loss: 0.1606, Train Steps/Sec: 1.46
[[34m2026-02-06 16:23:03[0m] (step=0014400) Train Loss: 0.1671, Train Steps/Sec: 1.46
[[34m2026-02-06 16:24:12[0m] (step=0014500) Train Loss: 0.1681, Train Steps/Sec: 1.46
[[34m2026-02-06 16:25:20[0m] (step=0014600) Train Loss: 0.1609, Train Steps/Sec: 1.46
[[34m2026-02-06 16:26:28[0m] (step=0014700) Train Loss: 0.1613, Train Steps/Sec: 1.46
[[34m2026-02-06 16:27:37[0m] (step=0014800) Train Loss: 0.1660, Train Steps/Sec: 1.46
[[34m2026-02-06 16:28:45[0m] (step=0014900) Train Loss: 0.1605, Train Steps/Sec: 1.46
[[34m2026-02-06 16:29:53[0m] (step=0015000) Train Loss: 0.1679, Train Steps/Sec: 1.46
[[34m2026-02-06 16:31:02[0m] (step=0015100) Train Loss: 0.1608, Train Steps/Sec: 1.46
[[34m2026-02-06 16:32:10[0m] (step=0015200) Train Loss: 0.1602, Train Steps/Sec: 1.46
[[34m2026-02-06 16:33:19[0m] (step=0015300) Train Loss: 0.1702, Train Steps/Sec: 1.46
[[34m2026-02-06 16:34:27[0m] (step=0015400) Train Loss: 0.1610, Train Steps/Sec: 1.46
[[34m2026-02-06 16:35:35[0m] (step=0015500) Train Loss: 0.1654, Train Steps/Sec: 1.46
[[34m2026-02-06 16:36:44[0m] (step=0015600) Train Loss: 0.1666, Train Steps/Sec: 1.46
[[34m2026-02-06 16:37:52[0m] (step=0015700) Train Loss: 0.1604, Train Steps/Sec: 1.46
[[34m2026-02-06 16:39:01[0m] (step=0015800) Train Loss: 0.1566, Train Steps/Sec: 1.46
[[34m2026-02-06 16:40:09[0m] (step=0015900) Train Loss: 0.1703, Train Steps/Sec: 1.46
[[34m2026-02-06 16:41:17[0m] (step=0016000) Train Loss: 0.1689, Train Steps/Sec: 1.46
[[34m2026-02-06 16:42:26[0m] (step=0016100) Train Loss: 0.1679, Train Steps/Sec: 1.46
[[34m2026-02-06 16:43:34[0m] (step=0016200) Train Loss: 0.1657, Train Steps/Sec: 1.46
[[34m2026-02-06 16:44:43[0m] (step=0016300) Train Loss: 0.1668, Train Steps/Sec: 1.46
[[34m2026-02-06 16:45:51[0m] (step=0016400) Train Loss: 0.1597, Train Steps/Sec: 1.46
[[34m2026-02-06 16:46:59[0m] (step=0016500) Train Loss: 0.1652, Train Steps/Sec: 1.46
[[34m2026-02-06 16:48:08[0m] (step=0016600) Train Loss: 0.1663, Train Steps/Sec: 1.46
[[34m2026-02-06 16:49:16[0m] (step=0016700) Train Loss: 0.1662, Train Steps/Sec: 1.46
[[34m2026-02-06 16:50:25[0m] (step=0016800) Train Loss: 0.1653, Train Steps/Sec: 1.46
[[34m2026-02-06 16:51:33[0m] (step=0016900) Train Loss: 0.1655, Train Steps/Sec: 1.46
[[34m2026-02-06 16:52:42[0m] (step=0017000) Train Loss: 0.1578, Train Steps/Sec: 1.46
[[34m2026-02-06 16:53:50[0m] (step=0017100) Train Loss: 0.1641, Train Steps/Sec: 1.46
[[34m2026-02-06 16:54:59[0m] (step=0017200) Train Loss: 0.1598, Train Steps/Sec: 1.46
[[34m2026-02-06 16:56:07[0m] (step=0017300) Train Loss: 0.1615, Train Steps/Sec: 1.46
[[34m2026-02-06 16:57:16[0m] (step=0017400) Train Loss: 0.1581, Train Steps/Sec: 1.46
[[34m2026-02-06 16:58:24[0m] (step=0017500) Train Loss: 0.1656, Train Steps/Sec: 1.46
[[34m2026-02-06 16:59:32[0m] (step=0017600) Train Loss: 0.1653, Train Steps/Sec: 1.46
[[34m2026-02-06 17:00:41[0m] (step=0017700) Train Loss: 0.1645, Train Steps/Sec: 1.46
[[34m2026-02-06 17:01:49[0m] (step=0017800) Train Loss: 0.1544, Train Steps/Sec: 1.46
[[34m2026-02-06 17:02:58[0m] (step=0017900) Train Loss: 0.1573, Train Steps/Sec: 1.46
[[34m2026-02-06 17:04:06[0m] (step=0018000) Train Loss: 0.1594, Train Steps/Sec: 1.46
[[34m2026-02-06 17:05:14[0m] (step=0018100) Train Loss: 0.1595, Train Steps/Sec: 1.46
[[34m2026-02-06 17:06:23[0m] (step=0018200) Train Loss: 0.1583, Train Steps/Sec: 1.46
[[34m2026-02-06 17:07:31[0m] (step=0018300) Train Loss: 0.1629, Train Steps/Sec: 1.46
[[34m2026-02-06 17:08:40[0m] (step=0018400) Train Loss: 0.1638, Train Steps/Sec: 1.46
[[34m2026-02-06 17:09:48[0m] (step=0018500) Train Loss: 0.1575, Train Steps/Sec: 1.46
[[34m2026-02-06 17:10:56[0m] (step=0018600) Train Loss: 0.1603, Train Steps/Sec: 1.46
[[34m2026-02-06 17:12:05[0m] (step=0018700) Train Loss: 0.1561, Train Steps/Sec: 1.46
[[34m2026-02-06 17:13:13[0m] (step=0018800) Train Loss: 0.1670, Train Steps/Sec: 1.46
[[34m2026-02-06 17:14:22[0m] (step=0018900) Train Loss: 0.1597, Train Steps/Sec: 1.46
[[34m2026-02-06 17:15:30[0m] (step=0019000) Train Loss: 0.1590, Train Steps/Sec: 1.46
[[34m2026-02-06 17:16:38[0m] (step=0019100) Train Loss: 0.1675, Train Steps/Sec: 1.46
[[34m2026-02-06 17:17:47[0m] (step=0019200) Train Loss: 0.1644, Train Steps/Sec: 1.46
[[34m2026-02-06 17:18:55[0m] (step=0019300) Train Loss: 0.1596, Train Steps/Sec: 1.46
[[34m2026-02-06 17:20:03[0m] (step=0019400) Train Loss: 0.1657, Train Steps/Sec: 1.46
[[34m2026-02-06 17:21:12[0m] (step=0019500) Train Loss: 0.1594, Train Steps/Sec: 1.46
[[34m2026-02-06 17:22:20[0m] (step=0019600) Train Loss: 0.1638, Train Steps/Sec: 1.46
[[34m2026-02-06 17:23:29[0m] (step=0019700) Train Loss: 0.1678, Train Steps/Sec: 1.46
[[34m2026-02-06 17:24:37[0m] (step=0019800) Train Loss: 0.1612, Train Steps/Sec: 1.46
[[34m2026-02-06 17:25:45[0m] (step=0019900) Train Loss: 0.1606, Train Steps/Sec: 1.46
[[34m2026-02-06 17:26:54[0m] (step=0020000) Train Loss: 0.1668, Train Steps/Sec: 1.46
[[34m2026-02-06 17:26:54[0m] Saved checkpoint to results/003-DiT-XL-2/checkpoints/0020000.pt
[[34m2026-02-06 17:27:07[0m] Beginning epoch 1...
[[34m2026-02-06 17:28:03[0m] (step=0020100) Train Loss: 0.1676, Train Steps/Sec: 1.44
[[34m2026-02-06 17:29:12[0m] (step=0020200) Train Loss: 0.1637, Train Steps/Sec: 1.46
[[34m2026-02-06 17:30:20[0m] (step=0020300) Train Loss: 0.1696, Train Steps/Sec: 1.46
[[34m2026-02-06 17:31:28[0m] (step=0020400) Train Loss: 0.1614, Train Steps/Sec: 1.46
[[34m2026-02-06 17:32:37[0m] (step=0020500) Train Loss: 0.1635, Train Steps/Sec: 1.46
[[34m2026-02-06 17:33:45[0m] (step=0020600) Train Loss: 0.1596, Train Steps/Sec: 1.46
[[34m2026-02-06 17:34:54[0m] (step=0020700) Train Loss: 0.1618, Train Steps/Sec: 1.46
[[34m2026-02-06 17:36:02[0m] (step=0020800) Train Loss: 0.1607, Train Steps/Sec: 1.46
[[34m2026-02-06 17:37:11[0m] (step=0020900) Train Loss: 0.1627, Train Steps/Sec: 1.46
[[34m2026-02-06 17:38:19[0m] (step=0021000) Train Loss: 0.1628, Train Steps/Sec: 1.46
[[34m2026-02-06 17:39:27[0m] (step=0021100) Train Loss: 0.1608, Train Steps/Sec: 1.46
[[34m2026-02-06 17:40:36[0m] (step=0021200) Train Loss: 0.1582, Train Steps/Sec: 1.46
[[34m2026-02-06 17:41:44[0m] (step=0021300) Train Loss: 0.1639, Train Steps/Sec: 1.46
[[34m2026-02-06 17:42:53[0m] (step=0021400) Train Loss: 0.1607, Train Steps/Sec: 1.46
[[34m2026-02-06 17:44:01[0m] (step=0021500) Train Loss: 0.1601, Train Steps/Sec: 1.46
[[34m2026-02-06 17:45:10[0m] (step=0021600) Train Loss: 0.1585, Train Steps/Sec: 1.46
[[34m2026-02-06 17:46:18[0m] (step=0021700) Train Loss: 0.1561, Train Steps/Sec: 1.46
[[34m2026-02-06 17:47:27[0m] (step=0021800) Train Loss: 0.1613, Train Steps/Sec: 1.46
[[34m2026-02-06 17:48:35[0m] (step=0021900) Train Loss: 0.1592, Train Steps/Sec: 1.46
[[34m2026-02-06 17:49:44[0m] (step=0022000) Train Loss: 0.1598, Train Steps/Sec: 1.46
[[34m2026-02-06 17:50:52[0m] (step=0022100) Train Loss: 0.1704, Train Steps/Sec: 1.46
[[34m2026-02-06 17:52:00[0m] (step=0022200) Train Loss: 0.1646, Train Steps/Sec: 1.46
[[34m2026-02-06 17:53:09[0m] (step=0022300) Train Loss: 0.1604, Train Steps/Sec: 1.46
[[34m2026-02-06 17:54:17[0m] (step=0022400) Train Loss: 0.1589, Train Steps/Sec: 1.46
[[34m2026-02-06 17:55:26[0m] (step=0022500) Train Loss: 0.1619, Train Steps/Sec: 1.46
[[34m2026-02-06 17:56:34[0m] (step=0022600) Train Loss: 0.1620, Train Steps/Sec: 1.46
[[34m2026-02-06 17:57:43[0m] (step=0022700) Train Loss: 0.1576, Train Steps/Sec: 1.46
[[34m2026-02-06 17:58:51[0m] (step=0022800) Train Loss: 0.1646, Train Steps/Sec: 1.46
[[34m2026-02-06 18:00:00[0m] (step=0022900) Train Loss: 0.1624, Train Steps/Sec: 1.46
[[34m2026-02-06 18:01:08[0m] (step=0023000) Train Loss: 0.1635, Train Steps/Sec: 1.46
[[34m2026-02-06 18:02:17[0m] (step=0023100) Train Loss: 0.1615, Train Steps/Sec: 1.46
[[34m2026-02-06 18:03:25[0m] (step=0023200) Train Loss: 0.1637, Train Steps/Sec: 1.46
[[34m2026-02-06 18:04:33[0m] (step=0023300) Train Loss: 0.1637, Train Steps/Sec: 1.46
[[34m2026-02-06 18:05:42[0m] (step=0023400) Train Loss: 0.1587, Train Steps/Sec: 1.46
[[34m2026-02-06 18:06:50[0m] (step=0023500) Train Loss: 0.1566, Train Steps/Sec: 1.46
[[34m2026-02-06 18:07:59[0m] (step=0023600) Train Loss: 0.1673, Train Steps/Sec: 1.46
[[34m2026-02-06 18:09:07[0m] (step=0023700) Train Loss: 0.1610, Train Steps/Sec: 1.46
[[34m2026-02-06 18:10:16[0m] (step=0023800) Train Loss: 0.1650, Train Steps/Sec: 1.46
[[34m2026-02-06 18:11:24[0m] (step=0023900) Train Loss: 0.1659, Train Steps/Sec: 1.46
[[34m2026-02-06 18:12:33[0m] (step=0024000) Train Loss: 0.1605, Train Steps/Sec: 1.46
[[34m2026-02-06 18:13:41[0m] (step=0024100) Train Loss: 0.1635, Train Steps/Sec: 1.46
[[34m2026-02-06 18:14:50[0m] (step=0024200) Train Loss: 0.1603, Train Steps/Sec: 1.46
[[34m2026-02-06 18:15:58[0m] (step=0024300) Train Loss: 0.1612, Train Steps/Sec: 1.46
[[34m2026-02-06 18:17:07[0m] (step=0024400) Train Loss: 0.1645, Train Steps/Sec: 1.46
[2026-02-06 18:17:59,628] torch.distributed.elastic.agent.server.api: [WARNING] Received 1 death signal, shutting down workers
[2026-02-06 18:17:59,628] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 4192881 closing signal SIGHUP
[2026-02-06 18:17:59,629] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 4192882 closing signal SIGHUP
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 727, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 868, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 4192790 got signal: 1
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
Starting rank=0, seed=0, world_size=2.
[[34m2026-02-07 00:36:13[0m] Experiment directory created at results/008-DiT-XL-2
Starting rank=1, seed=1, world_size=2.
[[34m2026-02-07 00:36:14[0m] Resumed from /home/myeongjin/diffusion_1/DiT/results/003-DiT-XL-2/checkpoints/0020000.pt at step=20000
[[34m2026-02-07 00:36:15[0m] DiT Parameters: 29,690,529
[[34m2026-02-07 00:36:17[0m] Dataset contains 1,281,167 images (/data1/dataset/imagenet2012/train)
[[34m2026-02-07 00:36:17[0m] Training for 1400 epochs...
[[34m2026-02-07 00:36:17[0m] Beginning epoch 0...
[2026-02-07 00:37:35,135] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 37789 closing signal SIGTERM
[2026-02-07 00:37:35,651] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -9) local_rank: 1 (pid: 37790) of binary: /home/myeongjin/miniconda3/envs/diffusion_1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
======================================================
train_flash.py FAILED
------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-02-07_00:37:35
  host      : turing
  rank      : 1 (local_rank: 1)
  exitcode  : -9 (pid: 37790)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 37790
======================================================
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
Starting rank=0, seed=0, world_size=2.
[[34m2026-02-07 01:05:08[0m] Experiment directory created at results/009-DiT-XL-2
Starting rank=1, seed=1, world_size=2.
[[34m2026-02-07 01:05:09[0m] Resumed from /home/myeongjin/diffusion_1/DiT/results/003-DiT-XL-2/checkpoints/0020000.pt at step=20000
[[34m2026-02-07 01:05:11[0m] DiT Parameters: 29,690,529
[[34m2026-02-07 01:05:13[0m] Dataset contains 1,281,167 images (/data1/dataset/imagenet2012/train)
[[34m2026-02-07 01:05:13[0m] Training for 1400 epochs...
[[34m2026-02-07 01:05:13[0m] Beginning epoch 0...
[2026-02-07 01:11:46,103] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 47249 closing signal SIGTERM
[2026-02-07 01:11:46,217] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -9) local_rank: 0 (pid: 47248) of binary: /home/myeongjin/miniconda3/envs/diffusion_1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
======================================================
train_flash.py FAILED
------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-02-07_01:11:46
  host      : turing
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 47248)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 47248
======================================================
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/myeongjin/miniconda3/envs/diffusion_1/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
Starting rank=0, seed=0, world_size=2.
[[34m2026-02-07 01:15:25[0m] Experiment directory created at results/004-DiT-XL-2
Starting rank=1, seed=1, world_size=2.
[[34m2026-02-07 01:15:26[0m] Resumed from /home/myeongjin/diffusion_1/DiT/results/003-DiT-XL-2/checkpoints/0020000.pt at step=20000
[[34m2026-02-07 01:15:27[0m] DiT Parameters: 29,690,529
[[34m2026-02-07 01:15:29[0m] Dataset contains 1,281,167 images (/data1/dataset/imagenet2012/train)
[[34m2026-02-07 01:15:29[0m] Training for 1400 epochs...
[[34m2026-02-07 01:15:29[0m] Beginning epoch 0...

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Starting rank=0, seed=0, world_size=4.
[[34m2026-02-08 02:06:51[0m] Experiment directory created at /data4/haksoo/trm_repa/000-DiT-XL-2
Starting rank=3, seed=3, world_size=4.
Starting rank=1, seed=1, world_size=4.
Starting rank=2, seed=2, world_size=4.
[[34m2026-02-08 02:06:52[0m] Loading REPA teacher via torch.hub: facebookresearch/dinov2::dinov2_vitb14
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
[[34m2026-02-08 02:06:52[0m] using MLP layer as FFN
[[34m2026-02-08 02:06:54[0m] Attached REPA projector: student_dim=1152 -> teacher_dim=768
[[34m2026-02-08 02:06:55[0m] Registered REPA forward hooks on student blocks.
[[34m2026-02-08 02:06:55[0m] DiT Parameters: 30,578,338
[[34m2026-02-08 02:06:58[0m] Dataset contains 1,281,167 images (/data/ImageNet1k/train)
[[34m2026-02-08 02:06:58[0m] Training for 1400 epochs...
[[34m2026-02-08 02:06:58[0m] Beginning epoch 0...
[[34m2026-02-08 02:07:35[0m] (step=0000100) Loss: 0.6079 (diff=0.3841, repa=0.4476, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 02:08:12[0m] (step=0000200) Loss: 0.3521 (diff=0.2083, repa=0.2875, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:08:49[0m] (step=0000300) Loss: 0.3469 (diff=0.2054, repa=0.2830, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:09:25[0m] (step=0000400) Loss: 0.3373 (diff=0.1971, repa=0.2804, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:10:02[0m] (step=0000500) Loss: 0.3293 (diff=0.1899, repa=0.2788, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:10:39[0m] (step=0000600) Loss: 0.3313 (diff=0.1928, repa=0.2769, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:11:16[0m] (step=0000700) Loss: 0.3306 (diff=0.1930, repa=0.2751, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:11:52[0m] (step=0000800) Loss: 0.3241 (diff=0.1871, repa=0.2739, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:12:29[0m] (step=0000900) Loss: 0.3184 (diff=0.1819, repa=0.2730, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:13:06[0m] (step=0001000) Loss: 0.3250 (diff=0.1896, repa=0.2708, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:13:43[0m] (step=0001100) Loss: 0.3207 (diff=0.1855, repa=0.2705, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:14:20[0m] (step=0001200) Loss: 0.3172 (diff=0.1830, repa=0.2685, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:14:56[0m] (step=0001300) Loss: 0.3211 (diff=0.1871, repa=0.2680, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:15:33[0m] (step=0001400) Loss: 0.3190 (diff=0.1856, repa=0.2669, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:16:10[0m] (step=0001500) Loss: 0.3214 (diff=0.1882, repa=0.2664, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:16:47[0m] (step=0001600) Loss: 0.3160 (diff=0.1837, repa=0.2646, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:17:24[0m] (step=0001700) Loss: 0.3189 (diff=0.1867, repa=0.2643, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:18:01[0m] (step=0001800) Loss: 0.3189 (diff=0.1870, repa=0.2638, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:18:37[0m] (step=0001900) Loss: 0.3103 (diff=0.1786, repa=0.2634, λ=0.5) Steps/Sec: 2.71
[[34m2026-02-08 02:19:14[0m] (step=0002000) Loss: 0.3150 (diff=0.1839, repa=0.2621, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:19:51[0m] (step=0002100) Loss: 0.3147 (diff=0.1839, repa=0.2616, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:20:28[0m] (step=0002200) Loss: 0.3042 (diff=0.1738, repa=0.2609, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:21:05[0m] (step=0002300) Loss: 0.3109 (diff=0.1811, repa=0.2596, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:21:41[0m] (step=0002400) Loss: 0.3074 (diff=0.1781, repa=0.2587, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:22:18[0m] (step=0002500) Loss: 0.3100 (diff=0.1806, repa=0.2589, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:22:55[0m] (step=0002600) Loss: 0.3078 (diff=0.1787, repa=0.2582, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:23:32[0m] (step=0002700) Loss: 0.3060 (diff=0.1772, repa=0.2576, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:24:09[0m] (step=0002800) Loss: 0.3011 (diff=0.1725, repa=0.2574, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:24:45[0m] (step=0002900) Loss: 0.3080 (diff=0.1798, repa=0.2563, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:25:22[0m] (step=0003000) Loss: 0.3096 (diff=0.1821, repa=0.2549, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:25:59[0m] (step=0003100) Loss: 0.3078 (diff=0.1801, repa=0.2555, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:26:36[0m] (step=0003200) Loss: 0.3058 (diff=0.1785, repa=0.2547, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:27:13[0m] (step=0003300) Loss: 0.3079 (diff=0.1805, repa=0.2547, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:27:49[0m] (step=0003400) Loss: 0.3078 (diff=0.1807, repa=0.2542, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:28:26[0m] (step=0003500) Loss: 0.2992 (diff=0.1723, repa=0.2538, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:29:03[0m] (step=0003600) Loss: 0.3061 (diff=0.1796, repa=0.2529, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:29:40[0m] (step=0003700) Loss: 0.3085 (diff=0.1822, repa=0.2526, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:30:17[0m] (step=0003800) Loss: 0.2958 (diff=0.1694, repa=0.2528, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:30:53[0m] (step=0003900) Loss: 0.3023 (diff=0.1762, repa=0.2521, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:31:30[0m] (step=0004000) Loss: 0.3056 (diff=0.1802, repa=0.2509, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:32:07[0m] (step=0004100) Loss: 0.2995 (diff=0.1739, repa=0.2511, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:32:44[0m] (step=0004200) Loss: 0.2982 (diff=0.1724, repa=0.2516, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:33:21[0m] (step=0004300) Loss: 0.3048 (diff=0.1796, repa=0.2505, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:33:57[0m] (step=0004400) Loss: 0.3028 (diff=0.1778, repa=0.2499, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:34:34[0m] (step=0004500) Loss: 0.3046 (diff=0.1797, repa=0.2497, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:35:11[0m] (step=0004600) Loss: 0.3094 (diff=0.1848, repa=0.2492, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:35:48[0m] (step=0004700) Loss: 0.3049 (diff=0.1805, repa=0.2489, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:36:25[0m] (step=0004800) Loss: 0.2991 (diff=0.1745, repa=0.2491, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:37:01[0m] (step=0004900) Loss: 0.2937 (diff=0.1690, repa=0.2494, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:37:38[0m] (step=0005000) Loss: 0.3022 (diff=0.1781, repa=0.2482, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:38:15[0m] (step=0005100) Loss: 0.3041 (diff=0.1806, repa=0.2470, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:38:52[0m] (step=0005200) Loss: 0.2991 (diff=0.1753, repa=0.2476, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:39:28[0m] (step=0005300) Loss: 0.2887 (diff=0.1644, repa=0.2486, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:40:05[0m] (step=0005400) Loss: 0.2946 (diff=0.1709, repa=0.2475, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:40:42[0m] (step=0005500) Loss: 0.3004 (diff=0.1769, repa=0.2469, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:41:19[0m] (step=0005600) Loss: 0.3018 (diff=0.1786, repa=0.2463, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:41:56[0m] (step=0005700) Loss: 0.2997 (diff=0.1768, repa=0.2459, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:42:32[0m] (step=0005800) Loss: 0.2914 (diff=0.1681, repa=0.2466, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:43:09[0m] (step=0005900) Loss: 0.2931 (diff=0.1698, repa=0.2466, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:43:46[0m] (step=0006000) Loss: 0.2966 (diff=0.1739, repa=0.2455, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:44:23[0m] (step=0006100) Loss: 0.2957 (diff=0.1733, repa=0.2447, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 02:45:14[0m] (step=0006200) Loss: 0.2948 (diff=0.1724, repa=0.2446, λ=0.5) Steps/Sec: 1.93
[[34m2026-02-08 02:46:11[0m] (step=0006300) Loss: 0.3009 (diff=0.1787, repa=0.2445, λ=0.5) Steps/Sec: 1.78
[[34m2026-02-08 02:47:11[0m] (step=0006400) Loss: 0.2890 (diff=0.1666, repa=0.2449, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 02:48:13[0m] (step=0006500) Loss: 0.2924 (diff=0.1701, repa=0.2445, λ=0.5) Steps/Sec: 1.62
[[34m2026-02-08 02:49:13[0m] (step=0006600) Loss: 0.3000 (diff=0.1782, repa=0.2436, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 02:50:13[0m] (step=0006700) Loss: 0.2972 (diff=0.1755, repa=0.2434, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 02:51:14[0m] (step=0006800) Loss: 0.2968 (diff=0.1748, repa=0.2440, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 02:52:13[0m] (step=0006900) Loss: 0.2942 (diff=0.1723, repa=0.2438, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 02:53:13[0m] (step=0007000) Loss: 0.2977 (diff=0.1759, repa=0.2436, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 02:54:17[0m] (step=0007100) Loss: 0.2918 (diff=0.1703, repa=0.2430, λ=0.5) Steps/Sec: 1.58
[[34m2026-02-08 02:55:16[0m] (step=0007200) Loss: 0.2954 (diff=0.1737, repa=0.2433, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 02:56:17[0m] (step=0007300) Loss: 0.2915 (diff=0.1696, repa=0.2437, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 02:57:20[0m] (step=0007400) Loss: 0.2919 (diff=0.1704, repa=0.2430, λ=0.5) Steps/Sec: 1.60
[[34m2026-02-08 02:58:19[0m] (step=0007500) Loss: 0.2926 (diff=0.1713, repa=0.2426, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 02:59:21[0m] (step=0007600) Loss: 0.2914 (diff=0.1701, repa=0.2426, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 03:00:22[0m] (step=0007700) Loss: 0.2929 (diff=0.1721, repa=0.2416, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 03:01:23[0m] (step=0007800) Loss: 0.2858 (diff=0.1644, repa=0.2429, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 03:02:22[0m] (step=0007900) Loss: 0.2909 (diff=0.1697, repa=0.2424, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 03:03:23[0m] (step=0008000) Loss: 0.2987 (diff=0.1782, repa=0.2410, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 03:04:22[0m] (step=0008100) Loss: 0.2917 (diff=0.1708, repa=0.2418, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 03:05:22[0m] (step=0008200) Loss: 0.2916 (diff=0.1711, repa=0.2410, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:06:21[0m] (step=0008300) Loss: 0.2916 (diff=0.1710, repa=0.2412, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 03:07:22[0m] (step=0008400) Loss: 0.2907 (diff=0.1699, repa=0.2416, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 03:08:21[0m] (step=0008500) Loss: 0.2874 (diff=0.1665, repa=0.2418, λ=0.5) Steps/Sec: 1.70
[[34m2026-02-08 03:09:20[0m] (step=0008600) Loss: 0.2877 (diff=0.1670, repa=0.2414, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 03:10:21[0m] (step=0008700) Loss: 0.2933 (diff=0.1729, repa=0.2408, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 03:11:20[0m] (step=0008800) Loss: 0.2937 (diff=0.1735, repa=0.2404, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 03:12:19[0m] (step=0008900) Loss: 0.2900 (diff=0.1694, repa=0.2410, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:13:18[0m] (step=0009000) Loss: 0.2917 (diff=0.1713, repa=0.2406, λ=0.5) Steps/Sec: 1.72
[[34m2026-02-08 03:14:17[0m] (step=0009100) Loss: 0.2909 (diff=0.1705, repa=0.2408, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 03:15:15[0m] (step=0009200) Loss: 0.2937 (diff=0.1738, repa=0.2398, λ=0.5) Steps/Sec: 1.72
[[34m2026-02-08 03:16:17[0m] (step=0009300) Loss: 0.2868 (diff=0.1664, repa=0.2408, λ=0.5) Steps/Sec: 1.62
[[34m2026-02-08 03:17:15[0m] (step=0009400) Loss: 0.2833 (diff=0.1630, repa=0.2405, λ=0.5) Steps/Sec: 1.72
[[34m2026-02-08 03:18:17[0m] (step=0009500) Loss: 0.2828 (diff=0.1628, repa=0.2401, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 03:19:17[0m] (step=0009600) Loss: 0.2871 (diff=0.1670, repa=0.2401, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:20:15[0m] (step=0009700) Loss: 0.2916 (diff=0.1717, repa=0.2398, λ=0.5) Steps/Sec: 1.71
[[34m2026-02-08 03:21:18[0m] (step=0009800) Loss: 0.2879 (diff=0.1682, repa=0.2395, λ=0.5) Steps/Sec: 1.59
[[34m2026-02-08 03:22:18[0m] (step=0009900) Loss: 0.2870 (diff=0.1669, repa=0.2402, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 03:23:18[0m] (step=0010000) Loss: 0.2851 (diff=0.1653, repa=0.2396, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:24:18[0m] (step=0010100) Loss: 0.2933 (diff=0.1739, repa=0.2388, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 03:25:19[0m] (step=0010200) Loss: 0.2904 (diff=0.1707, repa=0.2394, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 03:26:20[0m] (step=0010300) Loss: 0.2858 (diff=0.1660, repa=0.2396, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 03:27:19[0m] (step=0010400) Loss: 0.2897 (diff=0.1699, repa=0.2395, λ=0.5) Steps/Sec: 1.70
[[34m2026-02-08 03:28:20[0m] (step=0010500) Loss: 0.2863 (diff=0.1669, repa=0.2390, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 03:29:20[0m] (step=0010600) Loss: 0.2913 (diff=0.1718, repa=0.2391, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 03:30:19[0m] (step=0010700) Loss: 0.2856 (diff=0.1662, repa=0.2389, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 03:31:21[0m] (step=0010800) Loss: 0.2909 (diff=0.1715, repa=0.2389, λ=0.5) Steps/Sec: 1.61
[[34m2026-02-08 03:32:21[0m] (step=0010900) Loss: 0.2917 (diff=0.1726, repa=0.2380, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 03:33:22[0m] (step=0011000) Loss: 0.2887 (diff=0.1695, repa=0.2384, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 03:34:24[0m] (step=0011100) Loss: 0.2838 (diff=0.1644, repa=0.2387, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 03:35:23[0m] (step=0011200) Loss: 0.2825 (diff=0.1632, repa=0.2385, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 03:36:22[0m] (step=0011300) Loss: 0.2855 (diff=0.1663, repa=0.2385, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 03:37:23[0m] (step=0011400) Loss: 0.2809 (diff=0.1611, repa=0.2395, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 03:38:24[0m] (step=0011500) Loss: 0.2867 (diff=0.1677, repa=0.2381, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 03:39:25[0m] (step=0011600) Loss: 0.2909 (diff=0.1720, repa=0.2379, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 03:40:25[0m] (step=0011700) Loss: 0.2836 (diff=0.1643, repa=0.2387, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 03:41:25[0m] (step=0011800) Loss: 0.2832 (diff=0.1642, repa=0.2380, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:42:25[0m] (step=0011900) Loss: 0.2870 (diff=0.1680, repa=0.2380, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 03:43:26[0m] (step=0012000) Loss: 0.2889 (diff=0.1698, repa=0.2382, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 03:44:26[0m] (step=0012100) Loss: 0.2893 (diff=0.1704, repa=0.2379, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 03:45:26[0m] (step=0012200) Loss: 0.2821 (diff=0.1628, repa=0.2385, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 03:46:26[0m] (step=0012300) Loss: 0.2853 (diff=0.1667, repa=0.2373, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 03:47:27[0m] (step=0012400) Loss: 0.2845 (diff=0.1654, repa=0.2382, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 03:48:26[0m] (step=0012500) Loss: 0.2880 (diff=0.1694, repa=0.2373, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 03:49:26[0m] (step=0012600) Loss: 0.2866 (diff=0.1680, repa=0.2372, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:50:27[0m] (step=0012700) Loss: 0.2876 (diff=0.1690, repa=0.2374, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 03:51:25[0m] (step=0012800) Loss: 0.2875 (diff=0.1690, repa=0.2368, λ=0.5) Steps/Sec: 1.71
[[34m2026-02-08 03:52:26[0m] (step=0012900) Loss: 0.2839 (diff=0.1651, repa=0.2377, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 03:53:27[0m] (step=0013000) Loss: 0.2824 (diff=0.1636, repa=0.2375, λ=0.5) Steps/Sec: 1.62
[[34m2026-02-08 03:54:27[0m] (step=0013100) Loss: 0.2852 (diff=0.1664, repa=0.2375, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:55:27[0m] (step=0013200) Loss: 0.2819 (diff=0.1633, repa=0.2374, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:56:27[0m] (step=0013300) Loss: 0.2898 (diff=0.1715, repa=0.2365, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:57:27[0m] (step=0013400) Loss: 0.2865 (diff=0.1680, repa=0.2370, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 03:58:27[0m] (step=0013500) Loss: 0.2904 (diff=0.1721, repa=0.2367, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 03:59:26[0m] (step=0013600) Loss: 0.2824 (diff=0.1642, repa=0.2364, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 04:00:27[0m] (step=0013700) Loss: 0.2881 (diff=0.1698, repa=0.2366, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 04:01:28[0m] (step=0013800) Loss: 0.2809 (diff=0.1624, repa=0.2371, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:02:28[0m] (step=0013900) Loss: 0.2806 (diff=0.1622, repa=0.2368, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:03:28[0m] (step=0014000) Loss: 0.2900 (diff=0.1720, repa=0.2360, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:04:28[0m] (step=0014100) Loss: 0.2891 (diff=0.1712, repa=0.2358, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:05:27[0m] (step=0014200) Loss: 0.2838 (diff=0.1656, repa=0.2365, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 04:06:28[0m] (step=0014300) Loss: 0.2863 (diff=0.1682, repa=0.2362, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 04:07:31[0m] (step=0014400) Loss: 0.2931 (diff=0.1750, repa=0.2362, λ=0.5) Steps/Sec: 1.60
[[34m2026-02-08 04:08:29[0m] (step=0014500) Loss: 0.2870 (diff=0.1689, repa=0.2362, λ=0.5) Steps/Sec: 1.71
[[34m2026-02-08 04:09:29[0m] (step=0014600) Loss: 0.2853 (diff=0.1672, repa=0.2363, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:10:29[0m] (step=0014700) Loss: 0.2844 (diff=0.1664, repa=0.2360, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:11:29[0m] (step=0014800) Loss: 0.2840 (diff=0.1659, repa=0.2362, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:12:29[0m] (step=0014900) Loss: 0.2835 (diff=0.1653, repa=0.2364, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:13:29[0m] (step=0015000) Loss: 0.2882 (diff=0.1706, repa=0.2352, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:14:28[0m] (step=0015100) Loss: 0.2847 (diff=0.1668, repa=0.2359, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 04:15:30[0m] (step=0015200) Loss: 0.2858 (diff=0.1682, repa=0.2353, λ=0.5) Steps/Sec: 1.62
[[34m2026-02-08 04:16:29[0m] (step=0015300) Loss: 0.2920 (diff=0.1747, repa=0.2345, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 04:17:29[0m] (step=0015400) Loss: 0.2818 (diff=0.1637, repa=0.2361, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:18:29[0m] (step=0015500) Loss: 0.2831 (diff=0.1653, repa=0.2355, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:19:29[0m] (step=0015600) Loss: 0.2899 (diff=0.1723, repa=0.2353, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 04:20:30[0m] (step=0015700) Loss: 0.2832 (diff=0.1652, repa=0.2360, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 04:21:30[0m] (step=0015800) Loss: 0.2744 (diff=0.1562, repa=0.2365, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 04:22:30[0m] (step=0015900) Loss: 0.2845 (diff=0.1664, repa=0.2362, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:23:29[0m] (step=0016000) Loss: 0.2880 (diff=0.1702, repa=0.2355, λ=0.5) Steps/Sec: 1.70
[[34m2026-02-08 04:24:29[0m] (step=0016100) Loss: 0.2796 (diff=0.1618, repa=0.2356, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:25:28[0m] (step=0016200) Loss: 0.2842 (diff=0.1662, repa=0.2358, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:26:29[0m] (step=0016300) Loss: 0.2856 (diff=0.1682, repa=0.2349, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 04:27:29[0m] (step=0016400) Loss: 0.2788 (diff=0.1611, repa=0.2354, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:28:28[0m] (step=0016500) Loss: 0.2830 (diff=0.1653, repa=0.2353, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 04:29:28[0m] (step=0016600) Loss: 0.2795 (diff=0.1616, repa=0.2358, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 04:30:28[0m] (step=0016700) Loss: 0.2788 (diff=0.1610, repa=0.2355, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:31:26[0m] (step=0016800) Loss: 0.2849 (diff=0.1676, repa=0.2345, λ=0.5) Steps/Sec: 1.73
[[34m2026-02-08 04:32:27[0m] (step=0016900) Loss: 0.2884 (diff=0.1713, repa=0.2342, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 04:33:26[0m] (step=0017000) Loss: 0.2809 (diff=0.1634, repa=0.2351, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 04:34:25[0m] (step=0017100) Loss: 0.2797 (diff=0.1623, repa=0.2348, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 04:35:25[0m] (step=0017200) Loss: 0.2825 (diff=0.1649, repa=0.2352, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:36:27[0m] (step=0017300) Loss: 0.2809 (diff=0.1632, repa=0.2353, λ=0.5) Steps/Sec: 1.62
[[34m2026-02-08 04:37:26[0m] (step=0017400) Loss: 0.2820 (diff=0.1645, repa=0.2349, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 04:38:26[0m] (step=0017500) Loss: 0.2863 (diff=0.1690, repa=0.2347, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 04:39:27[0m] (step=0017600) Loss: 0.2812 (diff=0.1637, repa=0.2350, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 04:40:25[0m] (step=0017700) Loss: 0.2771 (diff=0.1595, repa=0.2352, λ=0.5) Steps/Sec: 1.72
[[34m2026-02-08 04:41:27[0m] (step=0017800) Loss: 0.2788 (diff=0.1612, repa=0.2351, λ=0.5) Steps/Sec: 1.62
[[34m2026-02-08 04:42:26[0m] (step=0017900) Loss: 0.2771 (diff=0.1595, repa=0.2351, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 04:43:27[0m] (step=0018000) Loss: 0.2822 (diff=0.1652, repa=0.2340, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:44:27[0m] (step=0018100) Loss: 0.2772 (diff=0.1598, repa=0.2348, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:45:27[0m] (step=0018200) Loss: 0.2776 (diff=0.1602, repa=0.2349, λ=0.5) Steps/Sec: 1.64
[[34m2026-02-08 04:46:27[0m] (step=0018300) Loss: 0.2803 (diff=0.1630, repa=0.2346, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:47:28[0m] (step=0018400) Loss: 0.2823 (diff=0.1654, repa=0.2339, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 04:48:27[0m] (step=0018500) Loss: 0.2809 (diff=0.1638, repa=0.2340, λ=0.5) Steps/Sec: 1.70
[[34m2026-02-08 04:49:28[0m] (step=0018600) Loss: 0.2821 (diff=0.1652, repa=0.2338, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 04:50:26[0m] (step=0018700) Loss: 0.2737 (diff=0.1561, repa=0.2351, λ=0.5) Steps/Sec: 1.72
[[34m2026-02-08 04:51:28[0m] (step=0018800) Loss: 0.2867 (diff=0.1695, repa=0.2344, λ=0.5) Steps/Sec: 1.62
[[34m2026-02-08 04:52:27[0m] (step=0018900) Loss: 0.2800 (diff=0.1631, repa=0.2339, λ=0.5) Steps/Sec: 1.67
[[34m2026-02-08 04:53:28[0m] (step=0019000) Loss: 0.2827 (diff=0.1659, repa=0.2337, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 04:54:29[0m] (step=0019100) Loss: 0.2840 (diff=0.1672, repa=0.2336, λ=0.5) Steps/Sec: 1.63
[[34m2026-02-08 04:55:28[0m] (step=0019200) Loss: 0.2817 (diff=0.1647, repa=0.2341, λ=0.5) Steps/Sec: 1.71
[[34m2026-02-08 04:56:28[0m] (step=0019300) Loss: 0.2831 (diff=0.1659, repa=0.2344, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 04:57:25[0m] (step=0019400) Loss: 0.2817 (diff=0.1647, repa=0.2339, λ=0.5) Steps/Sec: 1.77
[[34m2026-02-08 04:58:28[0m] (step=0019500) Loss: 0.2833 (diff=0.1668, repa=0.2329, λ=0.5) Steps/Sec: 1.58
[[34m2026-02-08 04:59:27[0m] (step=0019600) Loss: 0.2818 (diff=0.1649, repa=0.2340, λ=0.5) Steps/Sec: 1.70
[[34m2026-02-08 05:00:26[0m] (step=0019700) Loss: 0.2817 (diff=0.1652, repa=0.2331, λ=0.5) Steps/Sec: 1.69
[[34m2026-02-08 05:01:26[0m] (step=0019800) Loss: 0.2823 (diff=0.1653, repa=0.2339, λ=0.5) Steps/Sec: 1.68
[[34m2026-02-08 05:02:26[0m] (step=0019900) Loss: 0.2753 (diff=0.1583, repa=0.2339, λ=0.5) Steps/Sec: 1.65
[[34m2026-02-08 05:03:27[0m] (step=0020000) Loss: 0.2829 (diff=0.1662, repa=0.2334, λ=0.5) Steps/Sec: 1.66
[[34m2026-02-08 05:03:27[0m] Saved checkpoint to /data4/haksoo/trm_repa/000-DiT-XL-2/checkpoints/0020000.pt
/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  return func(*args, **kwargs)
[[34m2026-02-08 05:03:37[0m] Beginning epoch 1...
[[34m2026-02-08 05:04:08[0m] (step=0020100) Loss: 0.2822 (diff=0.1656, repa=0.2332, λ=0.5) Steps/Sec: 2.43
[[34m2026-02-08 05:04:45[0m] (step=0020200) Loss: 0.2815 (diff=0.1647, repa=0.2336, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:05:21[0m] (step=0020300) Loss: 0.2790 (diff=0.1624, repa=0.2332, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:05:58[0m] (step=0020400) Loss: 0.2786 (diff=0.1618, repa=0.2337, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:06:35[0m] (step=0020500) Loss: 0.2824 (diff=0.1658, repa=0.2331, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:07:12[0m] (step=0020600) Loss: 0.2750 (diff=0.1581, repa=0.2337, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:07:49[0m] (step=0020700) Loss: 0.2796 (diff=0.1631, repa=0.2330, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:08:25[0m] (step=0020800) Loss: 0.2793 (diff=0.1628, repa=0.2331, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:09:02[0m] (step=0020900) Loss: 0.2796 (diff=0.1629, repa=0.2336, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:09:39[0m] (step=0021000) Loss: 0.2799 (diff=0.1632, repa=0.2335, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:10:16[0m] (step=0021100) Loss: 0.2804 (diff=0.1636, repa=0.2338, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:10:53[0m] (step=0021200) Loss: 0.2777 (diff=0.1605, repa=0.2343, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:11:29[0m] (step=0021300) Loss: 0.2771 (diff=0.1604, repa=0.2335, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:12:06[0m] (step=0021400) Loss: 0.2774 (diff=0.1607, repa=0.2336, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:12:43[0m] (step=0021500) Loss: 0.2808 (diff=0.1640, repa=0.2336, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:13:20[0m] (step=0021600) Loss: 0.2722 (diff=0.1549, repa=0.2347, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:13:56[0m] (step=0021700) Loss: 0.2745 (diff=0.1574, repa=0.2343, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:14:33[0m] (step=0021800) Loss: 0.2809 (diff=0.1642, repa=0.2332, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:15:10[0m] (step=0021900) Loss: 0.2780 (diff=0.1613, repa=0.2334, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:15:47[0m] (step=0022000) Loss: 0.2812 (diff=0.1647, repa=0.2330, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:16:24[0m] (step=0022100) Loss: 0.2831 (diff=0.1669, repa=0.2325, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:17:00[0m] (step=0022200) Loss: 0.2798 (diff=0.1632, repa=0.2333, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:17:37[0m] (step=0022300) Loss: 0.2790 (diff=0.1623, repa=0.2335, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:18:14[0m] (step=0022400) Loss: 0.2752 (diff=0.1584, repa=0.2337, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:18:51[0m] (step=0022500) Loss: 0.2797 (diff=0.1632, repa=0.2331, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:19:27[0m] (step=0022600) Loss: 0.2755 (diff=0.1588, repa=0.2333, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:20:04[0m] (step=0022700) Loss: 0.2769 (diff=0.1600, repa=0.2337, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:20:41[0m] (step=0022800) Loss: 0.2821 (diff=0.1657, repa=0.2328, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:21:18[0m] (step=0022900) Loss: 0.2784 (diff=0.1619, repa=0.2331, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:21:55[0m] (step=0023000) Loss: 0.2816 (diff=0.1651, repa=0.2330, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:22:31[0m] (step=0023100) Loss: 0.2777 (diff=0.1615, repa=0.2324, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:23:08[0m] (step=0023200) Loss: 0.2776 (diff=0.1611, repa=0.2330, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:23:45[0m] (step=0023300) Loss: 0.2804 (diff=0.1643, repa=0.2322, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:24:22[0m] (step=0023400) Loss: 0.2784 (diff=0.1619, repa=0.2330, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:24:59[0m] (step=0023500) Loss: 0.2761 (diff=0.1598, repa=0.2326, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:25:35[0m] (step=0023600) Loss: 0.2885 (diff=0.1724, repa=0.2322, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:26:12[0m] (step=0023700) Loss: 0.2801 (diff=0.1636, repa=0.2331, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:26:49[0m] (step=0023800) Loss: 0.2817 (diff=0.1652, repa=0.2330, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:27:26[0m] (step=0023900) Loss: 0.2823 (diff=0.1664, repa=0.2317, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:28:02[0m] (step=0024000) Loss: 0.2755 (diff=0.1591, repa=0.2327, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:28:39[0m] (step=0024100) Loss: 0.2780 (diff=0.1615, repa=0.2330, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:29:16[0m] (step=0024200) Loss: 0.2790 (diff=0.1624, repa=0.2331, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:29:53[0m] (step=0024300) Loss: 0.2808 (diff=0.1648, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:30:30[0m] (step=0024400) Loss: 0.2766 (diff=0.1602, repa=0.2328, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:31:06[0m] (step=0024500) Loss: 0.2741 (diff=0.1576, repa=0.2330, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:31:43[0m] (step=0024600) Loss: 0.2778 (diff=0.1616, repa=0.2325, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:32:20[0m] (step=0024700) Loss: 0.2735 (diff=0.1571, repa=0.2328, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:32:57[0m] (step=0024800) Loss: 0.2782 (diff=0.1622, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:33:33[0m] (step=0024900) Loss: 0.2715 (diff=0.1549, repa=0.2331, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:34:10[0m] (step=0025000) Loss: 0.2777 (diff=0.1611, repa=0.2332, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:34:47[0m] (step=0025100) Loss: 0.2775 (diff=0.1615, repa=0.2319, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:35:24[0m] (step=0025200) Loss: 0.2794 (diff=0.1631, repa=0.2326, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:36:01[0m] (step=0025300) Loss: 0.2792 (diff=0.1630, repa=0.2325, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:36:37[0m] (step=0025400) Loss: 0.2759 (diff=0.1595, repa=0.2327, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:37:14[0m] (step=0025500) Loss: 0.2747 (diff=0.1587, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:37:51[0m] (step=0025600) Loss: 0.2739 (diff=0.1579, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:38:28[0m] (step=0025700) Loss: 0.2754 (diff=0.1591, repa=0.2327, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:39:05[0m] (step=0025800) Loss: 0.2808 (diff=0.1646, repa=0.2325, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:39:41[0m] (step=0025900) Loss: 0.2824 (diff=0.1665, repa=0.2317, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:40:18[0m] (step=0026000) Loss: 0.2808 (diff=0.1648, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:40:55[0m] (step=0026100) Loss: 0.2806 (diff=0.1650, repa=0.2313, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:41:32[0m] (step=0026200) Loss: 0.2770 (diff=0.1607, repa=0.2326, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:42:08[0m] (step=0026300) Loss: 0.2760 (diff=0.1598, repa=0.2324, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:42:45[0m] (step=0026400) Loss: 0.2750 (diff=0.1586, repa=0.2328, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:43:22[0m] (step=0026500) Loss: 0.2773 (diff=0.1612, repa=0.2324, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:43:59[0m] (step=0026600) Loss: 0.2736 (diff=0.1572, repa=0.2328, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:44:36[0m] (step=0026700) Loss: 0.2795 (diff=0.1635, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:45:12[0m] (step=0026800) Loss: 0.2741 (diff=0.1581, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:45:49[0m] (step=0026900) Loss: 0.2794 (diff=0.1634, repa=0.2319, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:46:26[0m] (step=0027000) Loss: 0.2780 (diff=0.1616, repa=0.2328, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:47:03[0m] (step=0027100) Loss: 0.2737 (diff=0.1577, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:47:40[0m] (step=0027200) Loss: 0.2765 (diff=0.1605, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:48:16[0m] (step=0027300) Loss: 0.2758 (diff=0.1597, repa=0.2322, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:48:53[0m] (step=0027400) Loss: 0.2807 (diff=0.1649, repa=0.2316, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:49:30[0m] (step=0027500) Loss: 0.2777 (diff=0.1621, repa=0.2313, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:50:07[0m] (step=0027600) Loss: 0.2759 (diff=0.1600, repa=0.2319, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:50:43[0m] (step=0027700) Loss: 0.2791 (diff=0.1633, repa=0.2316, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:51:20[0m] (step=0027800) Loss: 0.2785 (diff=0.1626, repa=0.2318, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:51:57[0m] (step=0027900) Loss: 0.2819 (diff=0.1663, repa=0.2313, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:52:34[0m] (step=0028000) Loss: 0.2780 (diff=0.1621, repa=0.2317, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:53:11[0m] (step=0028100) Loss: 0.2754 (diff=0.1595, repa=0.2317, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:53:47[0m] (step=0028200) Loss: 0.2750 (diff=0.1591, repa=0.2317, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:54:24[0m] (step=0028300) Loss: 0.2793 (diff=0.1635, repa=0.2316, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:55:01[0m] (step=0028400) Loss: 0.2785 (diff=0.1628, repa=0.2315, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:55:38[0m] (step=0028500) Loss: 0.2790 (diff=0.1630, repa=0.2321, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:56:15[0m] (step=0028600) Loss: 0.2770 (diff=0.1615, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:56:51[0m] (step=0028700) Loss: 0.2737 (diff=0.1578, repa=0.2317, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:57:28[0m] (step=0028800) Loss: 0.2794 (diff=0.1637, repa=0.2314, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:58:05[0m] (step=0028900) Loss: 0.2736 (diff=0.1575, repa=0.2322, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:58:42[0m] (step=0029000) Loss: 0.2718 (diff=0.1557, repa=0.2322, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:59:18[0m] (step=0029100) Loss: 0.2770 (diff=0.1610, repa=0.2320, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 05:59:55[0m] (step=0029200) Loss: 0.2757 (diff=0.1596, repa=0.2322, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:00:32[0m] (step=0029300) Loss: 0.2794 (diff=0.1636, repa=0.2317, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:01:09[0m] (step=0029400) Loss: 0.2847 (diff=0.1693, repa=0.2307, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:01:46[0m] (step=0029500) Loss: 0.2772 (diff=0.1615, repa=0.2315, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:02:22[0m] (step=0029600) Loss: 0.2766 (diff=0.1608, repa=0.2315, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:02:59[0m] (step=0029700) Loss: 0.2765 (diff=0.1606, repa=0.2319, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:03:36[0m] (step=0029800) Loss: 0.2755 (diff=0.1597, repa=0.2316, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:04:13[0m] (step=0029900) Loss: 0.2766 (diff=0.1610, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:04:49[0m] (step=0030000) Loss: 0.2749 (diff=0.1589, repa=0.2321, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:05:26[0m] (step=0030100) Loss: 0.2793 (diff=0.1642, repa=0.2302, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:06:03[0m] (step=0030200) Loss: 0.2767 (diff=0.1613, repa=0.2309, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:06:40[0m] (step=0030300) Loss: 0.2765 (diff=0.1608, repa=0.2313, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:07:17[0m] (step=0030400) Loss: 0.2751 (diff=0.1591, repa=0.2321, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:07:53[0m] (step=0030500) Loss: 0.2770 (diff=0.1613, repa=0.2313, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:08:30[0m] (step=0030600) Loss: 0.2788 (diff=0.1632, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:09:07[0m] (step=0030700) Loss: 0.2756 (diff=0.1596, repa=0.2319, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:09:44[0m] (step=0030800) Loss: 0.2672 (diff=0.1508, repa=0.2328, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:10:20[0m] (step=0030900) Loss: 0.2778 (diff=0.1622, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:10:57[0m] (step=0031000) Loss: 0.2791 (diff=0.1638, repa=0.2307, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:11:34[0m] (step=0031100) Loss: 0.2728 (diff=0.1570, repa=0.2318, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:12:11[0m] (step=0031200) Loss: 0.2794 (diff=0.1637, repa=0.2314, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:12:48[0m] (step=0031300) Loss: 0.2758 (diff=0.1603, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:13:24[0m] (step=0031400) Loss: 0.2794 (diff=0.1641, repa=0.2306, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:14:01[0m] (step=0031500) Loss: 0.2772 (diff=0.1615, repa=0.2313, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:14:38[0m] (step=0031600) Loss: 0.2746 (diff=0.1591, repa=0.2310, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:15:15[0m] (step=0031700) Loss: 0.2763 (diff=0.1607, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:15:51[0m] (step=0031800) Loss: 0.2782 (diff=0.1624, repa=0.2314, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:16:28[0m] (step=0031900) Loss: 0.2801 (diff=0.1648, repa=0.2304, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:17:05[0m] (step=0032000) Loss: 0.2762 (diff=0.1607, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:17:42[0m] (step=0032100) Loss: 0.2788 (diff=0.1633, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:18:19[0m] (step=0032200) Loss: 0.2762 (diff=0.1608, repa=0.2309, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:18:55[0m] (step=0032300) Loss: 0.2811 (diff=0.1656, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:19:32[0m] (step=0032400) Loss: 0.2792 (diff=0.1639, repa=0.2307, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:20:09[0m] (step=0032500) Loss: 0.2760 (diff=0.1606, repa=0.2309, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:20:46[0m] (step=0032600) Loss: 0.2795 (diff=0.1645, repa=0.2301, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:21:22[0m] (step=0032700) Loss: 0.2771 (diff=0.1617, repa=0.2306, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:21:59[0m] (step=0032800) Loss: 0.2793 (diff=0.1638, repa=0.2309, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:22:36[0m] (step=0032900) Loss: 0.2785 (diff=0.1633, repa=0.2303, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:23:13[0m] (step=0033000) Loss: 0.2749 (diff=0.1592, repa=0.2315, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:23:50[0m] (step=0033100) Loss: 0.2742 (diff=0.1585, repa=0.2312, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:24:26[0m] (step=0033200) Loss: 0.2729 (diff=0.1571, repa=0.2316, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:25:03[0m] (step=0033300) Loss: 0.2751 (diff=0.1597, repa=0.2308, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:25:40[0m] (step=0033400) Loss: 0.2796 (diff=0.1645, repa=0.2303, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:26:17[0m] (step=0033500) Loss: 0.2714 (diff=0.1557, repa=0.2314, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:26:53[0m] (step=0033600) Loss: 0.2745 (diff=0.1589, repa=0.2313, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:27:30[0m] (step=0033700) Loss: 0.2770 (diff=0.1615, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:28:07[0m] (step=0033800) Loss: 0.2762 (diff=0.1609, repa=0.2306, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:28:44[0m] (step=0033900) Loss: 0.2758 (diff=0.1605, repa=0.2306, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:29:21[0m] (step=0034000) Loss: 0.2798 (diff=0.1644, repa=0.2310, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:29:57[0m] (step=0034100) Loss: 0.2745 (diff=0.1592, repa=0.2306, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:30:34[0m] (step=0034200) Loss: 0.2736 (diff=0.1580, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:31:11[0m] (step=0034300) Loss: 0.2712 (diff=0.1556, repa=0.2312, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:31:48[0m] (step=0034400) Loss: 0.2757 (diff=0.1601, repa=0.2314, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:32:24[0m] (step=0034500) Loss: 0.2759 (diff=0.1603, repa=0.2312, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:33:01[0m] (step=0034600) Loss: 0.2821 (diff=0.1667, repa=0.2308, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:33:38[0m] (step=0034700) Loss: 0.2779 (diff=0.1631, repa=0.2297, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:34:15[0m] (step=0034800) Loss: 0.2791 (diff=0.1637, repa=0.2307, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:34:51[0m] (step=0034900) Loss: 0.2759 (diff=0.1605, repa=0.2309, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:35:28[0m] (step=0035000) Loss: 0.2747 (diff=0.1595, repa=0.2304, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:36:05[0m] (step=0035100) Loss: 0.2793 (diff=0.1642, repa=0.2303, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:36:42[0m] (step=0035200) Loss: 0.2787 (diff=0.1634, repa=0.2305, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:37:19[0m] (step=0035300) Loss: 0.2749 (diff=0.1596, repa=0.2307, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:37:55[0m] (step=0035400) Loss: 0.2789 (diff=0.1637, repa=0.2303, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:38:32[0m] (step=0035500) Loss: 0.2806 (diff=0.1652, repa=0.2308, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:39:09[0m] (step=0035600) Loss: 0.2739 (diff=0.1583, repa=0.2312, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:39:46[0m] (step=0035700) Loss: 0.2771 (diff=0.1618, repa=0.2304, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:40:22[0m] (step=0035800) Loss: 0.2783 (diff=0.1633, repa=0.2300, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:40:59[0m] (step=0035900) Loss: 0.2749 (diff=0.1596, repa=0.2307, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:41:36[0m] (step=0036000) Loss: 0.2744 (diff=0.1591, repa=0.2307, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:42:13[0m] (step=0036100) Loss: 0.2747 (diff=0.1594, repa=0.2305, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:42:50[0m] (step=0036200) Loss: 0.2759 (diff=0.1607, repa=0.2305, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:43:26[0m] (step=0036300) Loss: 0.2752 (diff=0.1600, repa=0.2304, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:44:03[0m] (step=0036400) Loss: 0.2726 (diff=0.1570, repa=0.2311, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:44:40[0m] (step=0036500) Loss: 0.2775 (diff=0.1625, repa=0.2300, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:45:17[0m] (step=0036600) Loss: 0.2825 (diff=0.1680, repa=0.2290, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:45:53[0m] (step=0036700) Loss: 0.2750 (diff=0.1599, repa=0.2302, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:46:30[0m] (step=0036800) Loss: 0.2797 (diff=0.1648, repa=0.2298, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:47:07[0m] (step=0036900) Loss: 0.2824 (diff=0.1673, repa=0.2302, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:47:44[0m] (step=0037000) Loss: 0.2718 (diff=0.1563, repa=0.2308, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:48:21[0m] (step=0037100) Loss: 0.2682 (diff=0.1523, repa=0.2318, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:48:57[0m] (step=0037200) Loss: 0.2753 (diff=0.1598, repa=0.2310, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:49:34[0m] (step=0037300) Loss: 0.2787 (diff=0.1640, repa=0.2293, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:50:11[0m] (step=0037400) Loss: 0.2759 (diff=0.1607, repa=0.2303, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:50:48[0m] (step=0037500) Loss: 0.2713 (diff=0.1557, repa=0.2313, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:51:24[0m] (step=0037600) Loss: 0.2763 (diff=0.1614, repa=0.2300, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:52:01[0m] (step=0037700) Loss: 0.2804 (diff=0.1654, repa=0.2300, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:52:38[0m] (step=0037800) Loss: 0.2850 (diff=0.1704, repa=0.2291, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:53:15[0m] (step=0037900) Loss: 0.2736 (diff=0.1581, repa=0.2310, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:53:51[0m] (step=0038000) Loss: 0.2765 (diff=0.1615, repa=0.2300, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:54:28[0m] (step=0038100) Loss: 0.2731 (diff=0.1578, repa=0.2307, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:55:05[0m] (step=0038200) Loss: 0.2728 (diff=0.1577, repa=0.2302, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:55:42[0m] (step=0038300) Loss: 0.2753 (diff=0.1603, repa=0.2301, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:56:19[0m] (step=0038400) Loss: 0.2735 (diff=0.1583, repa=0.2304, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:56:55[0m] (step=0038500) Loss: 0.2755 (diff=0.1604, repa=0.2302, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:57:32[0m] (step=0038600) Loss: 0.2712 (diff=0.1560, repa=0.2303, λ=0.5) Steps/Sec: 2.72
[[34m2026-02-08 06:58:09[0m] (step=0038700) Loss: 0.2797 (diff=0.1650, repa=0.2295, λ=0.5) Steps/Sec: 2.72
W0208 06:58:20.165000 463670 site-packages/torch/distributed/elastic/agent/server/api.py:739] Received 1 death signal, shutting down workers
W0208 06:58:20.169000 463670 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 463761 closing signal SIGHUP
W0208 06:58:20.170000 463670 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 463762 closing signal SIGHUP
W0208 06:58:20.172000 463670 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 463763 closing signal SIGHUP
W0208 06:58:20.173000 463670 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 463764 closing signal SIGHUP
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 995, in <module>
    main()
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 991, in main
    run(args)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 982, in run
    elastic_launch(
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 170, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 308, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 134, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 731, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 908, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 86, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 463670 got signal: 1

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Starting rank=0, seed=0, world_size=4.
[[34m2026-02-08 10:59:22[0m] Experiment directory created at /data4/haksoo/trm_repa/001-DiT-XL-2
Starting rank=1, seed=1, world_size=4.
Starting rank=2, seed=2, world_size=4.
Starting rank=3, seed=3, world_size=4.
[[34m2026-02-08 10:59:22[0m] Loading REPA teacher via torch.hub: facebookresearch/dinov2::dinov2_vitb14
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
[[34m2026-02-08 10:59:23[0m] using MLP layer as FFN
[[34m2026-02-08 10:59:25[0m] Attached REPA projector: student_dim=1152 -> teacher_dim=768
[[34m2026-02-08 10:59:25[0m] Resumed from /data4/haksoo/trm_repa/000-DiT-XL-2/checkpoints/0020000.pt at step=20000
[[34m2026-02-08 10:59:25[0m] Registered REPA forward hooks on student blocks.
[[34m2026-02-08 10:59:26[0m] DiT Parameters: 30,578,338
[[34m2026-02-08 10:59:28[0m] Dataset contains 1,281,167 images (/data/ImageNet1k/train)
[[34m2026-02-08 10:59:28[0m] Training for 1400 epochs...
[[34m2026-02-08 10:59:28[0m] Beginning epoch 0...
[[34m2026-02-08 11:00:06[0m] (step=0000100) Loss: 0.2810 (diff=0.1641, repa=0.2338, λ=0.5) Steps/Sec: 2.62
[[34m2026-02-08 11:00:44[0m] (step=0000200) Loss: 0.2790 (diff=0.1622, repa=0.2337, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:01:21[0m] (step=0000300) Loss: 0.2839 (diff=0.1671, repa=0.2336, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 11:01:58[0m] (step=0000400) Loss: 0.2810 (diff=0.1641, repa=0.2337, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 11:02:36[0m] (step=0000500) Loss: 0.2771 (diff=0.1601, repa=0.2341, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 11:03:13[0m] (step=0000600) Loss: 0.2809 (diff=0.1641, repa=0.2336, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:03:51[0m] (step=0000700) Loss: 0.2822 (diff=0.1656, repa=0.2333, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:04:28[0m] (step=0000800) Loss: 0.2780 (diff=0.1611, repa=0.2337, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:05:05[0m] (step=0000900) Loss: 0.2745 (diff=0.1573, repa=0.2344, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:05:43[0m] (step=0001000) Loss: 0.2818 (diff=0.1651, repa=0.2333, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:06:20[0m] (step=0001100) Loss: 0.2790 (diff=0.1620, repa=0.2340, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:06:57[0m] (step=0001200) Loss: 0.2778 (diff=0.1609, repa=0.2339, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:07:35[0m] (step=0001300) Loss: 0.2820 (diff=0.1651, repa=0.2338, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:08:12[0m] (step=0001400) Loss: 0.2802 (diff=0.1635, repa=0.2334, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:08:49[0m] (step=0001500) Loss: 0.2835 (diff=0.1669, repa=0.2333, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:09:27[0m] (step=0001600) Loss: 0.2790 (diff=0.1626, repa=0.2329, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:10:04[0m] (step=0001700) Loss: 0.2829 (diff=0.1664, repa=0.2330, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:10:41[0m] (step=0001800) Loss: 0.2841 (diff=0.1675, repa=0.2333, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:11:19[0m] (step=0001900) Loss: 0.2764 (diff=0.1598, repa=0.2332, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:11:56[0m] (step=0002000) Loss: 0.2821 (diff=0.1653, repa=0.2336, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:12:33[0m] (step=0002100) Loss: 0.2822 (diff=0.1655, repa=0.2334, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:13:11[0m] (step=0002200) Loss: 0.2732 (diff=0.1563, repa=0.2337, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:13:48[0m] (step=0002300) Loss: 0.2799 (diff=0.1635, repa=0.2328, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:14:25[0m] (step=0002400) Loss: 0.2772 (diff=0.1609, repa=0.2325, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:15:03[0m] (step=0002500) Loss: 0.2804 (diff=0.1638, repa=0.2332, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:15:40[0m] (step=0002600) Loss: 0.2790 (diff=0.1624, repa=0.2332, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:16:17[0m] (step=0002700) Loss: 0.2785 (diff=0.1619, repa=0.2332, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:16:55[0m] (step=0002800) Loss: 0.2739 (diff=0.1570, repa=0.2337, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:17:32[0m] (step=0002900) Loss: 0.2803 (diff=0.1637, repa=0.2330, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:18:09[0m] (step=0003000) Loss: 0.2823 (diff=0.1664, repa=0.2318, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:18:47[0m] (step=0003100) Loss: 0.2810 (diff=0.1646, repa=0.2327, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:19:24[0m] (step=0003200) Loss: 0.2804 (diff=0.1639, repa=0.2329, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:20:01[0m] (step=0003300) Loss: 0.2821 (diff=0.1657, repa=0.2328, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:20:38[0m] (step=0003400) Loss: 0.2831 (diff=0.1665, repa=0.2332, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:21:16[0m] (step=0003500) Loss: 0.2748 (diff=0.1582, repa=0.2332, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:21:53[0m] (step=0003600) Loss: 0.2819 (diff=0.1655, repa=0.2330, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:22:30[0m] (step=0003700) Loss: 0.2844 (diff=0.1682, repa=0.2324, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:23:08[0m] (step=0003800) Loss: 0.2728 (diff=0.1563, repa=0.2331, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:23:45[0m] (step=0003900) Loss: 0.2792 (diff=0.1629, repa=0.2327, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:24:22[0m] (step=0004000) Loss: 0.2828 (diff=0.1669, repa=0.2318, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:25:00[0m] (step=0004100) Loss: 0.2776 (diff=0.1614, repa=0.2324, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:25:37[0m] (step=0004200) Loss: 0.2767 (diff=0.1599, repa=0.2335, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:26:14[0m] (step=0004300) Loss: 0.2824 (diff=0.1661, repa=0.2324, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:26:52[0m] (step=0004400) Loss: 0.2813 (diff=0.1652, repa=0.2321, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:27:29[0m] (step=0004500) Loss: 0.2835 (diff=0.1674, repa=0.2321, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:28:06[0m] (step=0004600) Loss: 0.2883 (diff=0.1722, repa=0.2322, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:28:44[0m] (step=0004700) Loss: 0.2839 (diff=0.1679, repa=0.2319, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:29:21[0m] (step=0004800) Loss: 0.2790 (diff=0.1629, repa=0.2323, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:29:58[0m] (step=0004900) Loss: 0.2737 (diff=0.1572, repa=0.2329, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:30:36[0m] (step=0005000) Loss: 0.2824 (diff=0.1663, repa=0.2323, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:31:13[0m] (step=0005100) Loss: 0.2841 (diff=0.1684, repa=0.2313, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:31:50[0m] (step=0005200) Loss: 0.2799 (diff=0.1637, repa=0.2323, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:32:28[0m] (step=0005300) Loss: 0.2704 (diff=0.1536, repa=0.2336, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:33:05[0m] (step=0005400) Loss: 0.2762 (diff=0.1599, repa=0.2325, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:33:42[0m] (step=0005500) Loss: 0.2817 (diff=0.1657, repa=0.2320, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:34:20[0m] (step=0005600) Loss: 0.2834 (diff=0.1675, repa=0.2317, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:34:57[0m] (step=0005700) Loss: 0.2812 (diff=0.1655, repa=0.2316, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:35:34[0m] (step=0005800) Loss: 0.2744 (diff=0.1579, repa=0.2331, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:36:12[0m] (step=0005900) Loss: 0.2758 (diff=0.1592, repa=0.2332, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:36:49[0m] (step=0006000) Loss: 0.2793 (diff=0.1635, repa=0.2317, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:37:26[0m] (step=0006100) Loss: 0.2787 (diff=0.1629, repa=0.2316, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:38:04[0m] (step=0006200) Loss: 0.2778 (diff=0.1619, repa=0.2317, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:38:41[0m] (step=0006300) Loss: 0.2839 (diff=0.1681, repa=0.2315, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:39:18[0m] (step=0006400) Loss: 0.2730 (diff=0.1567, repa=0.2325, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:39:56[0m] (step=0006500) Loss: 0.2764 (diff=0.1603, repa=0.2322, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:40:33[0m] (step=0006600) Loss: 0.2837 (diff=0.1680, repa=0.2314, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:41:10[0m] (step=0006700) Loss: 0.2813 (diff=0.1656, repa=0.2314, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:41:48[0m] (step=0006800) Loss: 0.2807 (diff=0.1646, repa=0.2322, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:42:25[0m] (step=0006900) Loss: 0.2789 (diff=0.1628, repa=0.2322, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:43:02[0m] (step=0007000) Loss: 0.2822 (diff=0.1662, repa=0.2321, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:43:40[0m] (step=0007100) Loss: 0.2763 (diff=0.1606, repa=0.2315, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:44:17[0m] (step=0007200) Loss: 0.2803 (diff=0.1644, repa=0.2318, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:44:54[0m] (step=0007300) Loss: 0.2767 (diff=0.1604, repa=0.2328, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:45:32[0m] (step=0007400) Loss: 0.2773 (diff=0.1612, repa=0.2322, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:46:09[0m] (step=0007500) Loss: 0.2779 (diff=0.1620, repa=0.2318, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:46:47[0m] (step=0007600) Loss: 0.2770 (diff=0.1611, repa=0.2318, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:47:24[0m] (step=0007700) Loss: 0.2784 (diff=0.1629, repa=0.2310, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:48:01[0m] (step=0007800) Loss: 0.2721 (diff=0.1557, repa=0.2327, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:48:39[0m] (step=0007900) Loss: 0.2769 (diff=0.1608, repa=0.2322, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:49:16[0m] (step=0008000) Loss: 0.2846 (diff=0.1693, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:49:53[0m] (step=0008100) Loss: 0.2778 (diff=0.1618, repa=0.2319, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:50:31[0m] (step=0008200) Loss: 0.2779 (diff=0.1623, repa=0.2312, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:51:08[0m] (step=0008300) Loss: 0.2781 (diff=0.1624, repa=0.2315, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:51:45[0m] (step=0008400) Loss: 0.2775 (diff=0.1614, repa=0.2322, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:52:23[0m] (step=0008500) Loss: 0.2744 (diff=0.1583, repa=0.2323, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:53:00[0m] (step=0008600) Loss: 0.2747 (diff=0.1587, repa=0.2320, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:53:37[0m] (step=0008700) Loss: 0.2801 (diff=0.1644, repa=0.2314, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:54:15[0m] (step=0008800) Loss: 0.2805 (diff=0.1650, repa=0.2310, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:54:52[0m] (step=0008900) Loss: 0.2773 (diff=0.1614, repa=0.2318, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:55:29[0m] (step=0009000) Loss: 0.2790 (diff=0.1632, repa=0.2316, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:56:07[0m] (step=0009100) Loss: 0.2785 (diff=0.1627, repa=0.2317, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:56:44[0m] (step=0009200) Loss: 0.2810 (diff=0.1655, repa=0.2309, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:57:21[0m] (step=0009300) Loss: 0.2745 (diff=0.1583, repa=0.2323, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:57:59[0m] (step=0009400) Loss: 0.2716 (diff=0.1556, repa=0.2320, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:58:36[0m] (step=0009500) Loss: 0.2712 (diff=0.1554, repa=0.2316, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:59:13[0m] (step=0009600) Loss: 0.2756 (diff=0.1596, repa=0.2319, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 11:59:51[0m] (step=0009700) Loss: 0.2795 (diff=0.1638, repa=0.2314, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:00:28[0m] (step=0009800) Loss: 0.2762 (diff=0.1606, repa=0.2313, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:01:05[0m] (step=0009900) Loss: 0.2752 (diff=0.1592, repa=0.2320, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:01:43[0m] (step=0010000) Loss: 0.2737 (diff=0.1580, repa=0.2315, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:02:20[0m] (step=0010100) Loss: 0.2817 (diff=0.1664, repa=0.2307, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:02:57[0m] (step=0010200) Loss: 0.2789 (diff=0.1632, repa=0.2315, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:03:35[0m] (step=0010300) Loss: 0.2748 (diff=0.1589, repa=0.2317, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:04:12[0m] (step=0010400) Loss: 0.2782 (diff=0.1625, repa=0.2316, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:04:50[0m] (step=0010500) Loss: 0.2753 (diff=0.1597, repa=0.2312, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:05:27[0m] (step=0010600) Loss: 0.2803 (diff=0.1645, repa=0.2314, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:06:04[0m] (step=0010700) Loss: 0.2748 (diff=0.1592, repa=0.2311, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:06:42[0m] (step=0010800) Loss: 0.2799 (diff=0.1643, repa=0.2312, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:07:19[0m] (step=0010900) Loss: 0.2806 (diff=0.1654, repa=0.2303, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:07:56[0m] (step=0011000) Loss: 0.2779 (diff=0.1625, repa=0.2309, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:08:34[0m] (step=0011100) Loss: 0.2734 (diff=0.1578, repa=0.2313, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:09:11[0m] (step=0011200) Loss: 0.2722 (diff=0.1566, repa=0.2312, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:09:48[0m] (step=0011300) Loss: 0.2751 (diff=0.1595, repa=0.2311, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:10:26[0m] (step=0011400) Loss: 0.2709 (diff=0.1547, repa=0.2325, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:11:03[0m] (step=0011500) Loss: 0.2765 (diff=0.1611, repa=0.2309, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:11:40[0m] (step=0011600) Loss: 0.2807 (diff=0.1653, repa=0.2309, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:12:18[0m] (step=0011700) Loss: 0.2739 (diff=0.1580, repa=0.2318, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:12:55[0m] (step=0011800) Loss: 0.2733 (diff=0.1577, repa=0.2312, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:13:32[0m] (step=0011900) Loss: 0.2770 (diff=0.1616, repa=0.2309, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:14:10[0m] (step=0012000) Loss: 0.2788 (diff=0.1631, repa=0.2313, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:14:47[0m] (step=0012100) Loss: 0.2795 (diff=0.1640, repa=0.2311, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:15:24[0m] (step=0012200) Loss: 0.2726 (diff=0.1567, repa=0.2319, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:16:02[0m] (step=0012300) Loss: 0.2758 (diff=0.1605, repa=0.2307, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:16:39[0m] (step=0012400) Loss: 0.2750 (diff=0.1592, repa=0.2317, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:17:16[0m] (step=0012500) Loss: 0.2782 (diff=0.1629, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:17:54[0m] (step=0012600) Loss: 0.2771 (diff=0.1617, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:18:31[0m] (step=0012700) Loss: 0.2782 (diff=0.1628, repa=0.2308, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:19:08[0m] (step=0012800) Loss: 0.2780 (diff=0.1629, repa=0.2303, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:19:46[0m] (step=0012900) Loss: 0.2748 (diff=0.1591, repa=0.2315, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:20:23[0m] (step=0013000) Loss: 0.2733 (diff=0.1577, repa=0.2312, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:21:00[0m] (step=0013100) Loss: 0.2761 (diff=0.1605, repa=0.2313, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:21:38[0m] (step=0013200) Loss: 0.2730 (diff=0.1574, repa=0.2312, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:22:15[0m] (step=0013300) Loss: 0.2804 (diff=0.1654, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:22:52[0m] (step=0013400) Loss: 0.2777 (diff=0.1622, repa=0.2309, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:23:30[0m] (step=0013500) Loss: 0.2812 (diff=0.1660, repa=0.2305, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:24:07[0m] (step=0013600) Loss: 0.2737 (diff=0.1585, repa=0.2304, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:24:44[0m] (step=0013700) Loss: 0.2792 (diff=0.1639, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:25:22[0m] (step=0013800) Loss: 0.2723 (diff=0.1567, repa=0.2312, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:25:59[0m] (step=0013900) Loss: 0.2723 (diff=0.1568, repa=0.2310, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:26:36[0m] (step=0014000) Loss: 0.2812 (diff=0.1662, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:27:14[0m] (step=0014100) Loss: 0.2804 (diff=0.1655, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:27:51[0m] (step=0014200) Loss: 0.2755 (diff=0.1600, repa=0.2308, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:28:28[0m] (step=0014300) Loss: 0.2778 (diff=0.1626, repa=0.2304, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:29:05[0m] (step=0014400) Loss: 0.2845 (diff=0.1692, repa=0.2305, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:29:43[0m] (step=0014500) Loss: 0.2787 (diff=0.1635, repa=0.2305, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:30:20[0m] (step=0014600) Loss: 0.2769 (diff=0.1616, repa=0.2307, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:30:57[0m] (step=0014700) Loss: 0.2762 (diff=0.1609, repa=0.2305, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:31:35[0m] (step=0014800) Loss: 0.2757 (diff=0.1603, repa=0.2307, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:32:12[0m] (step=0014900) Loss: 0.2754 (diff=0.1600, repa=0.2308, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:32:49[0m] (step=0015000) Loss: 0.2799 (diff=0.1651, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:33:27[0m] (step=0015100) Loss: 0.2768 (diff=0.1615, repa=0.2305, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:34:04[0m] (step=0015200) Loss: 0.2778 (diff=0.1629, repa=0.2298, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:34:41[0m] (step=0015300) Loss: 0.2838 (diff=0.1692, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:35:19[0m] (step=0015400) Loss: 0.2741 (diff=0.1587, repa=0.2308, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:35:56[0m] (step=0015500) Loss: 0.2754 (diff=0.1602, repa=0.2304, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:36:33[0m] (step=0015600) Loss: 0.2819 (diff=0.1669, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:37:11[0m] (step=0015700) Loss: 0.2754 (diff=0.1601, repa=0.2308, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:37:48[0m] (step=0015800) Loss: 0.2672 (diff=0.1515, repa=0.2314, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:38:25[0m] (step=0015900) Loss: 0.2770 (diff=0.1614, repa=0.2311, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:39:03[0m] (step=0016000) Loss: 0.2802 (diff=0.1651, repa=0.2302, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:39:40[0m] (step=0016100) Loss: 0.2722 (diff=0.1569, repa=0.2307, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:40:17[0m] (step=0016200) Loss: 0.2768 (diff=0.1614, repa=0.2309, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:40:55[0m] (step=0016300) Loss: 0.2782 (diff=0.1632, repa=0.2298, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:41:32[0m] (step=0016400) Loss: 0.2717 (diff=0.1564, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:42:09[0m] (step=0016500) Loss: 0.2757 (diff=0.1605, repa=0.2304, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:42:47[0m] (step=0016600) Loss: 0.2724 (diff=0.1569, repa=0.2310, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:43:24[0m] (step=0016700) Loss: 0.2718 (diff=0.1564, repa=0.2308, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:44:01[0m] (step=0016800) Loss: 0.2776 (diff=0.1628, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:44:39[0m] (step=0016900) Loss: 0.2812 (diff=0.1665, repa=0.2294, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:45:16[0m] (step=0017000) Loss: 0.2738 (diff=0.1586, repa=0.2304, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:45:53[0m] (step=0017100) Loss: 0.2727 (diff=0.1576, repa=0.2301, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:46:31[0m] (step=0017200) Loss: 0.2755 (diff=0.1602, repa=0.2307, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:47:08[0m] (step=0017300) Loss: 0.2741 (diff=0.1587, repa=0.2308, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:47:45[0m] (step=0017400) Loss: 0.2751 (diff=0.1600, repa=0.2302, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:48:22[0m] (step=0017500) Loss: 0.2793 (diff=0.1642, repa=0.2301, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:49:00[0m] (step=0017600) Loss: 0.2745 (diff=0.1592, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:49:37[0m] (step=0017700) Loss: 0.2704 (diff=0.1550, repa=0.2307, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:50:14[0m] (step=0017800) Loss: 0.2720 (diff=0.1567, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:50:52[0m] (step=0017900) Loss: 0.2705 (diff=0.1552, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:51:29[0m] (step=0018000) Loss: 0.2756 (diff=0.1608, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:52:06[0m] (step=0018100) Loss: 0.2707 (diff=0.1555, repa=0.2303, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:52:44[0m] (step=0018200) Loss: 0.2712 (diff=0.1559, repa=0.2305, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:53:21[0m] (step=0018300) Loss: 0.2737 (diff=0.1586, repa=0.2302, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:53:58[0m] (step=0018400) Loss: 0.2758 (diff=0.1609, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:54:36[0m] (step=0018500) Loss: 0.2744 (diff=0.1595, repa=0.2297, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:55:13[0m] (step=0018600) Loss: 0.2756 (diff=0.1608, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:55:50[0m] (step=0018700) Loss: 0.2674 (diff=0.1520, repa=0.2309, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:56:28[0m] (step=0018800) Loss: 0.2804 (diff=0.1653, repa=0.2301, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:57:05[0m] (step=0018900) Loss: 0.2737 (diff=0.1589, repa=0.2297, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:57:42[0m] (step=0019000) Loss: 0.2763 (diff=0.1616, repa=0.2295, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:58:20[0m] (step=0019100) Loss: 0.2776 (diff=0.1628, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:58:57[0m] (step=0019200) Loss: 0.2756 (diff=0.1606, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 12:59:34[0m] (step=0019300) Loss: 0.2768 (diff=0.1617, repa=0.2302, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:00:12[0m] (step=0019400) Loss: 0.2754 (diff=0.1605, repa=0.2298, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:00:49[0m] (step=0019500) Loss: 0.2770 (diff=0.1626, repa=0.2288, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:01:26[0m] (step=0019600) Loss: 0.2758 (diff=0.1609, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:02:03[0m] (step=0019700) Loss: 0.2757 (diff=0.1611, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:02:41[0m] (step=0019800) Loss: 0.2762 (diff=0.1612, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:03:18[0m] (step=0019900) Loss: 0.2695 (diff=0.1545, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:03:55[0m] (step=0020000) Loss: 0.2768 (diff=0.1620, repa=0.2295, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:03:56[0m] Saved checkpoint to /data4/haksoo/trm_repa/001-DiT-XL-2/checkpoints/0020000.pt
/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  return func(*args, **kwargs)
[[34m2026-02-08 13:04:03[0m] Beginning epoch 1...
[[34m2026-02-08 13:04:34[0m] (step=0020100) Loss: 0.2764 (diff=0.1617, repa=0.2294, λ=0.5) Steps/Sec: 2.60
[[34m2026-02-08 13:05:11[0m] (step=0020200) Loss: 0.2757 (diff=0.1609, repa=0.2297, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:05:49[0m] (step=0020300) Loss: 0.2732 (diff=0.1585, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:06:26[0m] (step=0020400) Loss: 0.2729 (diff=0.1580, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:07:03[0m] (step=0020500) Loss: 0.2767 (diff=0.1621, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:07:41[0m] (step=0020600) Loss: 0.2694 (diff=0.1544, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:08:18[0m] (step=0020700) Loss: 0.2740 (diff=0.1594, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:08:55[0m] (step=0020800) Loss: 0.2739 (diff=0.1592, repa=0.2294, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:09:33[0m] (step=0020900) Loss: 0.2741 (diff=0.1592, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:10:10[0m] (step=0021000) Loss: 0.2743 (diff=0.1595, repa=0.2297, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:10:48[0m] (step=0021100) Loss: 0.2751 (diff=0.1600, repa=0.2302, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:11:25[0m] (step=0021200) Loss: 0.2724 (diff=0.1570, repa=0.2308, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:12:02[0m] (step=0021300) Loss: 0.2718 (diff=0.1569, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:12:40[0m] (step=0021400) Loss: 0.2722 (diff=0.1572, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:13:17[0m] (step=0021500) Loss: 0.2756 (diff=0.1606, repa=0.2302, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:13:54[0m] (step=0021600) Loss: 0.2672 (diff=0.1516, repa=0.2312, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:14:32[0m] (step=0021700) Loss: 0.2694 (diff=0.1540, repa=0.2308, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:15:09[0m] (step=0021800) Loss: 0.2757 (diff=0.1608, repa=0.2298, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:15:46[0m] (step=0021900) Loss: 0.2728 (diff=0.1578, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:16:24[0m] (step=0022000) Loss: 0.2761 (diff=0.1612, repa=0.2297, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:17:01[0m] (step=0022100) Loss: 0.2779 (diff=0.1633, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:17:38[0m] (step=0022200) Loss: 0.2747 (diff=0.1598, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:18:16[0m] (step=0022300) Loss: 0.2739 (diff=0.1589, repa=0.2301, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:18:53[0m] (step=0022400) Loss: 0.2702 (diff=0.1550, repa=0.2303, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:19:30[0m] (step=0022500) Loss: 0.2747 (diff=0.1599, repa=0.2297, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:20:08[0m] (step=0022600) Loss: 0.2705 (diff=0.1555, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:20:45[0m] (step=0022700) Loss: 0.2720 (diff=0.1567, repa=0.2305, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:21:22[0m] (step=0022800) Loss: 0.2771 (diff=0.1624, repa=0.2295, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:22:00[0m] (step=0022900) Loss: 0.2736 (diff=0.1587, repa=0.2298, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:22:37[0m] (step=0023000) Loss: 0.2768 (diff=0.1619, repa=0.2298, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:23:14[0m] (step=0023100) Loss: 0.2728 (diff=0.1582, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:23:52[0m] (step=0023200) Loss: 0.2728 (diff=0.1578, repa=0.2298, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:24:29[0m] (step=0023300) Loss: 0.2755 (diff=0.1610, repa=0.2290, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:25:06[0m] (step=0023400) Loss: 0.2736 (diff=0.1587, repa=0.2298, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:25:44[0m] (step=0023500) Loss: 0.2713 (diff=0.1566, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:26:21[0m] (step=0023600) Loss: 0.2835 (diff=0.1690, repa=0.2289, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:26:58[0m] (step=0023700) Loss: 0.2756 (diff=0.1606, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:27:36[0m] (step=0023800) Loss: 0.2769 (diff=0.1620, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:28:13[0m] (step=0023900) Loss: 0.2775 (diff=0.1632, repa=0.2286, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:28:50[0m] (step=0024000) Loss: 0.2710 (diff=0.1561, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:29:28[0m] (step=0024100) Loss: 0.2733 (diff=0.1584, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:30:05[0m] (step=0024200) Loss: 0.2744 (diff=0.1594, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:30:42[0m] (step=0024300) Loss: 0.2762 (diff=0.1617, repa=0.2289, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:31:20[0m] (step=0024400) Loss: 0.2720 (diff=0.1571, repa=0.2297, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:31:57[0m] (step=0024500) Loss: 0.2696 (diff=0.1546, repa=0.2300, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:32:34[0m] (step=0024600) Loss: 0.2732 (diff=0.1585, repa=0.2295, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:33:12[0m] (step=0024700) Loss: 0.2690 (diff=0.1541, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:33:49[0m] (step=0024800) Loss: 0.2736 (diff=0.1592, repa=0.2290, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:34:26[0m] (step=0024900) Loss: 0.2672 (diff=0.1521, repa=0.2302, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:35:04[0m] (step=0025000) Loss: 0.2732 (diff=0.1580, repa=0.2303, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:35:41[0m] (step=0025100) Loss: 0.2731 (diff=0.1586, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:36:18[0m] (step=0025200) Loss: 0.2748 (diff=0.1600, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:36:56[0m] (step=0025300) Loss: 0.2748 (diff=0.1600, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:37:33[0m] (step=0025400) Loss: 0.2716 (diff=0.1567, repa=0.2298, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:38:10[0m] (step=0025500) Loss: 0.2705 (diff=0.1559, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:38:48[0m] (step=0025600) Loss: 0.2695 (diff=0.1550, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:39:25[0m] (step=0025700) Loss: 0.2713 (diff=0.1564, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:40:02[0m] (step=0025800) Loss: 0.2765 (diff=0.1617, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:40:40[0m] (step=0025900) Loss: 0.2780 (diff=0.1636, repa=0.2289, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:41:17[0m] (step=0026000) Loss: 0.2765 (diff=0.1619, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:41:54[0m] (step=0026100) Loss: 0.2763 (diff=0.1620, repa=0.2285, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:42:32[0m] (step=0026200) Loss: 0.2729 (diff=0.1579, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:43:09[0m] (step=0026300) Loss: 0.2719 (diff=0.1570, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:43:46[0m] (step=0026400) Loss: 0.2709 (diff=0.1558, repa=0.2301, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:44:24[0m] (step=0026500) Loss: 0.2732 (diff=0.1584, repa=0.2297, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:45:01[0m] (step=0026600) Loss: 0.2695 (diff=0.1545, repa=0.2301, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:45:38[0m] (step=0026700) Loss: 0.2754 (diff=0.1607, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:46:16[0m] (step=0026800) Loss: 0.2701 (diff=0.1554, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:46:53[0m] (step=0026900) Loss: 0.2753 (diff=0.1607, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:47:30[0m] (step=0027000) Loss: 0.2739 (diff=0.1589, repa=0.2301, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:48:08[0m] (step=0027100) Loss: 0.2697 (diff=0.1550, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:48:45[0m] (step=0027200) Loss: 0.2725 (diff=0.1578, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:49:22[0m] (step=0027300) Loss: 0.2718 (diff=0.1570, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:50:00[0m] (step=0027400) Loss: 0.2767 (diff=0.1622, repa=0.2290, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:50:37[0m] (step=0027500) Loss: 0.2738 (diff=0.1595, repa=0.2287, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:51:14[0m] (step=0027600) Loss: 0.2719 (diff=0.1573, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 13:51:52[0m] (step=0027700) Loss: 0.2751 (diff=0.1607, repa=0.2289, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:52:29[0m] (step=0027800) Loss: 0.2746 (diff=0.1599, repa=0.2292, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:53:06[0m] (step=0027900) Loss: 0.2778 (diff=0.1634, repa=0.2287, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:53:44[0m] (step=0028000) Loss: 0.2741 (diff=0.1595, repa=0.2292, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:54:21[0m] (step=0028100) Loss: 0.2715 (diff=0.1569, repa=0.2291, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:54:59[0m] (step=0028200) Loss: 0.2712 (diff=0.1566, repa=0.2292, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:55:36[0m] (step=0028300) Loss: 0.2753 (diff=0.1608, repa=0.2290, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:56:13[0m] (step=0028400) Loss: 0.2747 (diff=0.1602, repa=0.2290, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:56:51[0m] (step=0028500) Loss: 0.2752 (diff=0.1604, repa=0.2296, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:57:28[0m] (step=0028600) Loss: 0.2731 (diff=0.1588, repa=0.2286, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:58:06[0m] (step=0028700) Loss: 0.2699 (diff=0.1553, repa=0.2293, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:58:43[0m] (step=0028800) Loss: 0.2756 (diff=0.1612, repa=0.2289, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:59:20[0m] (step=0028900) Loss: 0.2699 (diff=0.1550, repa=0.2298, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 13:59:58[0m] (step=0029000) Loss: 0.2682 (diff=0.1532, repa=0.2299, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:00:35[0m] (step=0029100) Loss: 0.2733 (diff=0.1585, repa=0.2295, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:01:13[0m] (step=0029200) Loss: 0.2721 (diff=0.1572, repa=0.2298, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:01:50[0m] (step=0029300) Loss: 0.2757 (diff=0.1611, repa=0.2293, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:02:27[0m] (step=0029400) Loss: 0.2809 (diff=0.1668, repa=0.2282, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:03:05[0m] (step=0029500) Loss: 0.2735 (diff=0.1589, repa=0.2291, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:03:42[0m] (step=0029600) Loss: 0.2730 (diff=0.1585, repa=0.2291, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:04:20[0m] (step=0029700) Loss: 0.2729 (diff=0.1581, repa=0.2295, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:04:57[0m] (step=0029800) Loss: 0.2719 (diff=0.1573, repa=0.2293, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:05:34[0m] (step=0029900) Loss: 0.2729 (diff=0.1586, repa=0.2287, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:06:12[0m] (step=0030000) Loss: 0.2713 (diff=0.1564, repa=0.2297, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:06:49[0m] (step=0030100) Loss: 0.2756 (diff=0.1617, repa=0.2279, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:07:26[0m] (step=0030200) Loss: 0.2731 (diff=0.1589, repa=0.2285, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:08:04[0m] (step=0030300) Loss: 0.2729 (diff=0.1584, repa=0.2290, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:08:41[0m] (step=0030400) Loss: 0.2716 (diff=0.1567, repa=0.2298, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:09:19[0m] (step=0030500) Loss: 0.2734 (diff=0.1589, repa=0.2290, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:09:56[0m] (step=0030600) Loss: 0.2754 (diff=0.1609, repa=0.2289, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:10:33[0m] (step=0030700) Loss: 0.2720 (diff=0.1572, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:11:11[0m] (step=0030800) Loss: 0.2639 (diff=0.1485, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:11:48[0m] (step=0030900) Loss: 0.2743 (diff=0.1599, repa=0.2289, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:12:25[0m] (step=0031000) Loss: 0.2757 (diff=0.1614, repa=0.2284, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:13:03[0m] (step=0031100) Loss: 0.2694 (diff=0.1546, repa=0.2295, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:13:40[0m] (step=0031200) Loss: 0.2759 (diff=0.1614, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:14:18[0m] (step=0031300) Loss: 0.2724 (diff=0.1579, repa=0.2289, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:14:55[0m] (step=0031400) Loss: 0.2759 (diff=0.1617, repa=0.2283, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:15:32[0m] (step=0031500) Loss: 0.2739 (diff=0.1593, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:16:10[0m] (step=0031600) Loss: 0.2713 (diff=0.1568, repa=0.2288, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:16:47[0m] (step=0031700) Loss: 0.2730 (diff=0.1585, repa=0.2290, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:17:24[0m] (step=0031800) Loss: 0.2747 (diff=0.1601, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:18:02[0m] (step=0031900) Loss: 0.2766 (diff=0.1625, repa=0.2283, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:18:39[0m] (step=0032000) Loss: 0.2729 (diff=0.1585, repa=0.2289, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:19:16[0m] (step=0032100) Loss: 0.2754 (diff=0.1610, repa=0.2289, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:19:54[0m] (step=0032200) Loss: 0.2729 (diff=0.1586, repa=0.2288, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:20:31[0m] (step=0032300) Loss: 0.2779 (diff=0.1634, repa=0.2290, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:21:09[0m] (step=0032400) Loss: 0.2759 (diff=0.1617, repa=0.2286, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:21:46[0m] (step=0032500) Loss: 0.2728 (diff=0.1584, repa=0.2288, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:22:23[0m] (step=0032600) Loss: 0.2762 (diff=0.1622, repa=0.2280, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:23:01[0m] (step=0032700) Loss: 0.2738 (diff=0.1596, repa=0.2285, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:23:38[0m] (step=0032800) Loss: 0.2761 (diff=0.1616, repa=0.2288, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:24:15[0m] (step=0032900) Loss: 0.2752 (diff=0.1611, repa=0.2282, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:24:53[0m] (step=0033000) Loss: 0.2717 (diff=0.1570, repa=0.2294, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:25:30[0m] (step=0033100) Loss: 0.2710 (diff=0.1564, repa=0.2292, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:26:08[0m] (step=0033200) Loss: 0.2698 (diff=0.1550, repa=0.2295, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:26:45[0m] (step=0033300) Loss: 0.2719 (diff=0.1575, repa=0.2288, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:27:22[0m] (step=0033400) Loss: 0.2763 (diff=0.1622, repa=0.2282, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:28:00[0m] (step=0033500) Loss: 0.2682 (diff=0.1535, repa=0.2294, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:28:37[0m] (step=0033600) Loss: 0.2714 (diff=0.1568, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:29:15[0m] (step=0033700) Loss: 0.2739 (diff=0.1594, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:29:52[0m] (step=0033800) Loss: 0.2730 (diff=0.1587, repa=0.2286, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:30:29[0m] (step=0033900) Loss: 0.2727 (diff=0.1584, repa=0.2286, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:31:07[0m] (step=0034000) Loss: 0.2768 (diff=0.1622, repa=0.2290, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:31:44[0m] (step=0034100) Loss: 0.2714 (diff=0.1571, repa=0.2286, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:32:21[0m] (step=0034200) Loss: 0.2705 (diff=0.1560, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:32:59[0m] (step=0034300) Loss: 0.2682 (diff=0.1536, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:33:36[0m] (step=0034400) Loss: 0.2727 (diff=0.1580, repa=0.2294, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:34:14[0m] (step=0034500) Loss: 0.2729 (diff=0.1582, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:34:51[0m] (step=0034600) Loss: 0.2790 (diff=0.1645, repa=0.2289, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:35:28[0m] (step=0034700) Loss: 0.2749 (diff=0.1610, repa=0.2278, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:36:06[0m] (step=0034800) Loss: 0.2760 (diff=0.1616, repa=0.2287, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:36:43[0m] (step=0034900) Loss: 0.2729 (diff=0.1584, repa=0.2290, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:37:20[0m] (step=0035000) Loss: 0.2717 (diff=0.1575, repa=0.2284, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:37:58[0m] (step=0035100) Loss: 0.2762 (diff=0.1620, repa=0.2284, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:38:35[0m] (step=0035200) Loss: 0.2756 (diff=0.1613, repa=0.2286, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:39:13[0m] (step=0035300) Loss: 0.2719 (diff=0.1575, repa=0.2288, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:39:50[0m] (step=0035400) Loss: 0.2758 (diff=0.1616, repa=0.2283, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:40:27[0m] (step=0035500) Loss: 0.2777 (diff=0.1632, repa=0.2289, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:41:05[0m] (step=0035600) Loss: 0.2710 (diff=0.1563, repa=0.2294, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:41:42[0m] (step=0035700) Loss: 0.2741 (diff=0.1599, repa=0.2285, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:42:19[0m] (step=0035800) Loss: 0.2754 (diff=0.1614, repa=0.2281, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:42:57[0m] (step=0035900) Loss: 0.2720 (diff=0.1576, repa=0.2288, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:43:34[0m] (step=0036000) Loss: 0.2715 (diff=0.1571, repa=0.2288, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:44:12[0m] (step=0036100) Loss: 0.2718 (diff=0.1575, repa=0.2287, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:44:49[0m] (step=0036200) Loss: 0.2731 (diff=0.1587, repa=0.2287, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:45:26[0m] (step=0036300) Loss: 0.2724 (diff=0.1581, repa=0.2285, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:46:04[0m] (step=0036400) Loss: 0.2698 (diff=0.1551, repa=0.2293, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:46:41[0m] (step=0036500) Loss: 0.2747 (diff=0.1606, repa=0.2281, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:47:19[0m] (step=0036600) Loss: 0.2796 (diff=0.1660, repa=0.2271, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:47:56[0m] (step=0036700) Loss: 0.2721 (diff=0.1579, repa=0.2284, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:48:33[0m] (step=0036800) Loss: 0.2768 (diff=0.1629, repa=0.2280, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:49:11[0m] (step=0036900) Loss: 0.2794 (diff=0.1653, repa=0.2283, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:49:48[0m] (step=0037000) Loss: 0.2690 (diff=0.1545, repa=0.2291, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:50:25[0m] (step=0037100) Loss: 0.2655 (diff=0.1505, repa=0.2300, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-08 14:51:03[0m] (step=0037200) Loss: 0.2725 (diff=0.1579, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:51:40[0m] (step=0037300) Loss: 0.2758 (diff=0.1621, repa=0.2275, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:52:18[0m] (step=0037400) Loss: 0.2730 (diff=0.1588, repa=0.2286, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:52:55[0m] (step=0037500) Loss: 0.2687 (diff=0.1539, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:53:32[0m] (step=0037600) Loss: 0.2735 (diff=0.1594, repa=0.2282, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:54:10[0m] (step=0037700) Loss: 0.2776 (diff=0.1634, repa=0.2282, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:54:47[0m] (step=0037800) Loss: 0.2822 (diff=0.1685, repa=0.2273, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:55:24[0m] (step=0037900) Loss: 0.2709 (diff=0.1563, repa=0.2292, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:56:02[0m] (step=0038000) Loss: 0.2737 (diff=0.1596, repa=0.2283, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-08 14:56:39[0m] (step=0038100) Loss: 0.2705 (diff=0.1560, repa=0.2290, λ=0.5) Steps/Sec: 2.68
W0208 14:57:06.025000 469907 site-packages/torch/distributed/elastic/agent/server/api.py:739] Received 1 death signal, shutting down workers
W0208 14:57:06.027000 469907 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 469999 closing signal SIGHUP
W0208 14:57:06.029000 469907 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 470000 closing signal SIGHUP
W0208 14:57:06.030000 469907 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 470001 closing signal SIGHUP
W0208 14:57:06.031000 469907 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 470002 closing signal SIGHUP
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 995, in <module>
    main()
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 991, in main
    run(args)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 982, in run
    elastic_launch(
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 170, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 308, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 134, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 731, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 908, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 86, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 469907 got signal: 1

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Starting rank=2, seed=2, world_size=4.
Starting rank=1, seed=1, world_size=4.
Starting rank=0, seed=0, world_size=4.
[[34m2026-02-08 22:01:41[0m] Experiment directory created at /data4/haksoo/trm_repa/001-DiT-XL-2
Starting rank=3, seed=3, world_size=4.
[[34m2026-02-08 22:01:41[0m] Loading REPA teacher via torch.hub: facebookresearch/dinov2::dinov2_vitb14
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
[[34m2026-02-08 22:01:42[0m] using MLP layer as FFN
[[34m2026-02-08 22:01:44[0m] Attached REPA projector: student_dim=1152 -> teacher_dim=768
[[34m2026-02-08 22:01:44[0m] Resumed from /data4/haksoo/trm_repa/000-DiT-XL-2/checkpoints/0020000.pt at step=20000
[[34m2026-02-08 22:01:44[0m] Registered REPA forward hooks on student blocks.
[[34m2026-02-08 22:01:45[0m] DiT Parameters: 30,578,338
[[34m2026-02-08 22:01:47[0m] Dataset contains 1,281,167 images (/data/ImageNet1k/train)
[[34m2026-02-08 22:01:47[0m] Training for 1400 epochs...
[[34m2026-02-08 22:01:47[0m] Beginning epoch 0...
[[34m2026-02-08 22:10:56[0m] Beginning epoch 1...
[[34m2026-02-08 22:11:27[0m] (step=0020100) Loss: 0.2820 (diff=0.1653, repa=0.2334, λ=0.5) Steps/Sec: 0.17
[[34m2026-02-08 22:12:04[0m] (step=0020200) Loss: 0.2785 (diff=0.1618, repa=0.2334, λ=0.5) Steps/Sec: 2.71
[[34m2026-02-08 22:12:41[0m] (step=0020300) Loss: 0.2836 (diff=0.1668, repa=0.2335, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:13:18[0m] (step=0020400) Loss: 0.2811 (diff=0.1644, repa=0.2334, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:13:55[0m] (step=0020500) Loss: 0.2777 (diff=0.1606, repa=0.2343, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:14:32[0m] (step=0020600) Loss: 0.2808 (diff=0.1642, repa=0.2332, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:15:09[0m] (step=0020700) Loss: 0.2815 (diff=0.1650, repa=0.2330, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:15:46[0m] (step=0020800) Loss: 0.2768 (diff=0.1600, repa=0.2335, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:16:23[0m] (step=0020900) Loss: 0.2754 (diff=0.1582, repa=0.2344, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:17:00[0m] (step=0021000) Loss: 0.2817 (diff=0.1651, repa=0.2333, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:17:37[0m] (step=0021100) Loss: 0.2780 (diff=0.1612, repa=0.2336, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:18:14[0m] (step=0021200) Loss: 0.2769 (diff=0.1601, repa=0.2336, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:18:51[0m] (step=0021300) Loss: 0.2826 (diff=0.1661, repa=0.2330, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:19:28[0m] (step=0021400) Loss: 0.2803 (diff=0.1636, repa=0.2334, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:20:05[0m] (step=0021500) Loss: 0.2843 (diff=0.1674, repa=0.2337, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:20:42[0m] (step=0021600) Loss: 0.2797 (diff=0.1632, repa=0.2330, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:21:19[0m] (step=0021700) Loss: 0.2822 (diff=0.1657, repa=0.2331, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:21:56[0m] (step=0021800) Loss: 0.2839 (diff=0.1675, repa=0.2327, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:22:33[0m] (step=0021900) Loss: 0.2773 (diff=0.1607, repa=0.2333, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:23:10[0m] (step=0022000) Loss: 0.2828 (diff=0.1661, repa=0.2334, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:23:47[0m] (step=0022100) Loss: 0.2817 (diff=0.1652, repa=0.2329, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:24:24[0m] (step=0022200) Loss: 0.2741 (diff=0.1571, repa=0.2340, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:25:01[0m] (step=0022300) Loss: 0.2806 (diff=0.1640, repa=0.2331, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:25:38[0m] (step=0022400) Loss: 0.2768 (diff=0.1602, repa=0.2333, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:26:15[0m] (step=0022500) Loss: 0.2805 (diff=0.1640, repa=0.2330, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:26:52[0m] (step=0022600) Loss: 0.2793 (diff=0.1624, repa=0.2338, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:27:29[0m] (step=0022700) Loss: 0.2774 (diff=0.1606, repa=0.2336, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:28:06[0m] (step=0022800) Loss: 0.2744 (diff=0.1574, repa=0.2341, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:28:43[0m] (step=0022900) Loss: 0.2810 (diff=0.1645, repa=0.2332, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:29:20[0m] (step=0023000) Loss: 0.2828 (diff=0.1666, repa=0.2324, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:29:57[0m] (step=0023100) Loss: 0.2815 (diff=0.1653, repa=0.2323, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:30:34[0m] (step=0023200) Loss: 0.2808 (diff=0.1642, repa=0.2331, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:31:11[0m] (step=0023300) Loss: 0.2817 (diff=0.1657, repa=0.2322, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:31:48[0m] (step=0023400) Loss: 0.2819 (diff=0.1654, repa=0.2330, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:32:25[0m] (step=0023500) Loss: 0.2749 (diff=0.1586, repa=0.2326, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:33:02[0m] (step=0023600) Loss: 0.2821 (diff=0.1655, repa=0.2332, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:33:39[0m] (step=0023700) Loss: 0.2844 (diff=0.1683, repa=0.2321, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:34:16[0m] (step=0023800) Loss: 0.2724 (diff=0.1558, repa=0.2332, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:34:53[0m] (step=0023900) Loss: 0.2786 (diff=0.1625, repa=0.2323, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:35:30[0m] (step=0024000) Loss: 0.2812 (diff=0.1655, repa=0.2315, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:36:07[0m] (step=0024100) Loss: 0.2785 (diff=0.1622, repa=0.2326, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:36:44[0m] (step=0024200) Loss: 0.2771 (diff=0.1607, repa=0.2329, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:37:21[0m] (step=0024300) Loss: 0.2827 (diff=0.1668, repa=0.2319, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:37:59[0m] (step=0024400) Loss: 0.2814 (diff=0.1653, repa=0.2322, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:38:36[0m] (step=0024500) Loss: 0.2826 (diff=0.1666, repa=0.2320, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:39:13[0m] (step=0024600) Loss: 0.2874 (diff=0.1715, repa=0.2319, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-08 22:39:50[0m] (step=0024700) Loss: 0.2837 (diff=0.1681, repa=0.2313, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:40:27[0m] (step=0024800) Loss: 0.2790 (diff=0.1627, repa=0.2325, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:41:04[0m] (step=0024900) Loss: 0.2742 (diff=0.1576, repa=0.2332, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:41:41[0m] (step=0025000) Loss: 0.2812 (diff=0.1649, repa=0.2325, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:42:18[0m] (step=0025100) Loss: 0.2833 (diff=0.1677, repa=0.2311, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:42:55[0m] (step=0025200) Loss: 0.2792 (diff=0.1627, repa=0.2328, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:43:32[0m] (step=0025300) Loss: 0.2697 (diff=0.1529, repa=0.2336, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:44:09[0m] (step=0025400) Loss: 0.2755 (diff=0.1590, repa=0.2330, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:44:46[0m] (step=0025500) Loss: 0.2810 (diff=0.1653, repa=0.2314, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:45:23[0m] (step=0025600) Loss: 0.2837 (diff=0.1679, repa=0.2317, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:46:00[0m] (step=0025700) Loss: 0.2819 (diff=0.1663, repa=0.2312, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:46:37[0m] (step=0025800) Loss: 0.2756 (diff=0.1589, repa=0.2334, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:47:14[0m] (step=0025900) Loss: 0.2750 (diff=0.1586, repa=0.2328, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:47:51[0m] (step=0026000) Loss: 0.2791 (diff=0.1633, repa=0.2316, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:48:28[0m] (step=0026100) Loss: 0.2778 (diff=0.1622, repa=0.2312, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:49:05[0m] (step=0026200) Loss: 0.2778 (diff=0.1617, repa=0.2322, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:49:42[0m] (step=0026300) Loss: 0.2825 (diff=0.1668, repa=0.2315, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:50:19[0m] (step=0026400) Loss: 0.2733 (diff=0.1570, repa=0.2326, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:50:56[0m] (step=0026500) Loss: 0.2772 (diff=0.1611, repa=0.2322, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:51:33[0m] (step=0026600) Loss: 0.2849 (diff=0.1690, repa=0.2318, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:52:10[0m] (step=0026700) Loss: 0.2811 (diff=0.1651, repa=0.2319, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:52:47[0m] (step=0026800) Loss: 0.2813 (diff=0.1657, repa=0.2313, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:53:24[0m] (step=0026900) Loss: 0.2779 (diff=0.1616, repa=0.2325, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:54:01[0m] (step=0027000) Loss: 0.2818 (diff=0.1658, repa=0.2320, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:54:38[0m] (step=0027100) Loss: 0.2774 (diff=0.1617, repa=0.2315, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:55:15[0m] (step=0027200) Loss: 0.2802 (diff=0.1643, repa=0.2317, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:55:52[0m] (step=0027300) Loss: 0.2765 (diff=0.1604, repa=0.2321, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:56:29[0m] (step=0027400) Loss: 0.2773 (diff=0.1610, repa=0.2327, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:57:06[0m] (step=0027500) Loss: 0.2776 (diff=0.1617, repa=0.2317, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:57:43[0m] (step=0027600) Loss: 0.2765 (diff=0.1606, repa=0.2319, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:58:20[0m] (step=0027700) Loss: 0.2790 (diff=0.1633, repa=0.2313, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:58:57[0m] (step=0027800) Loss: 0.2727 (diff=0.1565, repa=0.2324, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 22:59:34[0m] (step=0027900) Loss: 0.2778 (diff=0.1619, repa=0.2319, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:00:11[0m] (step=0028000) Loss: 0.2839 (diff=0.1686, repa=0.2306, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:00:48[0m] (step=0028100) Loss: 0.2773 (diff=0.1618, repa=0.2310, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:01:25[0m] (step=0028200) Loss: 0.2790 (diff=0.1633, repa=0.2315, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:02:02[0m] (step=0028300) Loss: 0.2773 (diff=0.1613, repa=0.2319, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:02:39[0m] (step=0028400) Loss: 0.2778 (diff=0.1618, repa=0.2320, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:03:16[0m] (step=0028500) Loss: 0.2741 (diff=0.1581, repa=0.2320, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:03:53[0m] (step=0028600) Loss: 0.2741 (diff=0.1585, repa=0.2312, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:04:30[0m] (step=0028700) Loss: 0.2801 (diff=0.1647, repa=0.2308, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:05:07[0m] (step=0028800) Loss: 0.2816 (diff=0.1659, repa=0.2314, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-08 23:05:44[0m] (step=0028900) Loss: 0.2778 (diff=0.1619, repa=0.2318, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:06:21[0m] (step=0029000) Loss: 0.2786 (diff=0.1629, repa=0.2313, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:06:58[0m] (step=0029100) Loss: 0.2777 (diff=0.1617, repa=0.2321, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:07:35[0m] (step=0029200) Loss: 0.2816 (diff=0.1662, repa=0.2309, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:08:13[0m] (step=0029300) Loss: 0.2744 (diff=0.1584, repa=0.2321, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:08:50[0m] (step=0029400) Loss: 0.2709 (diff=0.1549, repa=0.2320, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:09:27[0m] (step=0029500) Loss: 0.2713 (diff=0.1553, repa=0.2319, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:10:04[0m] (step=0029600) Loss: 0.2753 (diff=0.1597, repa=0.2313, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:10:41[0m] (step=0029700) Loss: 0.2793 (diff=0.1636, repa=0.2314, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:11:18[0m] (step=0029800) Loss: 0.2775 (diff=0.1616, repa=0.2317, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:11:55[0m] (step=0029900) Loss: 0.2747 (diff=0.1589, repa=0.2315, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:12:32[0m] (step=0030000) Loss: 0.2735 (diff=0.1578, repa=0.2315, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:13:09[0m] (step=0030100) Loss: 0.2818 (diff=0.1668, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:13:46[0m] (step=0030200) Loss: 0.2782 (diff=0.1629, repa=0.2305, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:14:23[0m] (step=0030300) Loss: 0.2753 (diff=0.1594, repa=0.2319, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:15:00[0m] (step=0030400) Loss: 0.2788 (diff=0.1630, repa=0.2315, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:15:37[0m] (step=0030500) Loss: 0.2752 (diff=0.1597, repa=0.2311, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:16:14[0m] (step=0030600) Loss: 0.2811 (diff=0.1654, repa=0.2313, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:16:51[0m] (step=0030700) Loss: 0.2743 (diff=0.1584, repa=0.2317, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:17:28[0m] (step=0030800) Loss: 0.2802 (diff=0.1647, repa=0.2310, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:18:05[0m] (step=0030900) Loss: 0.2814 (diff=0.1660, repa=0.2308, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:18:42[0m] (step=0031000) Loss: 0.2795 (diff=0.1640, repa=0.2310, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:19:19[0m] (step=0031100) Loss: 0.2741 (diff=0.1582, repa=0.2317, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:19:56[0m] (step=0031200) Loss: 0.2728 (diff=0.1569, repa=0.2319, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:20:33[0m] (step=0031300) Loss: 0.2758 (diff=0.1600, repa=0.2316, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:21:10[0m] (step=0031400) Loss: 0.2708 (diff=0.1546, repa=0.2324, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:21:47[0m] (step=0031500) Loss: 0.2767 (diff=0.1611, repa=0.2313, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:22:24[0m] (step=0031600) Loss: 0.2801 (diff=0.1647, repa=0.2308, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:23:01[0m] (step=0031700) Loss: 0.2734 (diff=0.1576, repa=0.2315, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:23:38[0m] (step=0031800) Loss: 0.2731 (diff=0.1573, repa=0.2316, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:24:15[0m] (step=0031900) Loss: 0.2774 (diff=0.1620, repa=0.2308, λ=0.5) Steps/Sec: 2.71
[[34m2026-02-08 23:24:52[0m] (step=0032000) Loss: 0.2797 (diff=0.1641, repa=0.2312, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:25:29[0m] (step=0032100) Loss: 0.2791 (diff=0.1637, repa=0.2309, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:26:06[0m] (step=0032200) Loss: 0.2727 (diff=0.1569, repa=0.2316, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:26:43[0m] (step=0032300) Loss: 0.2765 (diff=0.1610, repa=0.2310, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:27:20[0m] (step=0032400) Loss: 0.2745 (diff=0.1589, repa=0.2311, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:27:57[0m] (step=0032500) Loss: 0.2774 (diff=0.1620, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:28:34[0m] (step=0032600) Loss: 0.2764 (diff=0.1612, repa=0.2304, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:29:11[0m] (step=0032700) Loss: 0.2790 (diff=0.1637, repa=0.2306, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:29:48[0m] (step=0032800) Loss: 0.2785 (diff=0.1632, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:30:26[0m] (step=0032900) Loss: 0.2756 (diff=0.1599, repa=0.2314, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:31:03[0m] (step=0033000) Loss: 0.2733 (diff=0.1576, repa=0.2313, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-08 23:31:40[0m] (step=0033100) Loss: 0.2768 (diff=0.1612, repa=0.2312, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:32:17[0m] (step=0033200) Loss: 0.2733 (diff=0.1576, repa=0.2315, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-08 23:32:54[0m] (step=0033300) Loss: 0.2807 (diff=0.1655, repa=0.2305, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:33:31[0m] (step=0033400) Loss: 0.2759 (diff=0.1605, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:34:08[0m] (step=0033500) Loss: 0.2809 (diff=0.1660, repa=0.2298, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:34:45[0m] (step=0033600) Loss: 0.2735 (diff=0.1581, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:35:22[0m] (step=0033700) Loss: 0.2791 (diff=0.1639, repa=0.2303, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:35:59[0m] (step=0033800) Loss: 0.2716 (diff=0.1559, repa=0.2314, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:36:36[0m] (step=0033900) Loss: 0.2719 (diff=0.1564, repa=0.2309, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:37:13[0m] (step=0034000) Loss: 0.2820 (diff=0.1667, repa=0.2305, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:37:50[0m] (step=0034100) Loss: 0.2815 (diff=0.1665, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:38:27[0m] (step=0034200) Loss: 0.2758 (diff=0.1602, repa=0.2310, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:39:04[0m] (step=0034300) Loss: 0.2780 (diff=0.1626, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:39:41[0m] (step=0034400) Loss: 0.2833 (diff=0.1680, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:40:18[0m] (step=0034500) Loss: 0.2785 (diff=0.1634, repa=0.2302, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:40:56[0m] (step=0034600) Loss: 0.2778 (diff=0.1622, repa=0.2311, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:41:33[0m] (step=0034700) Loss: 0.2775 (diff=0.1625, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:42:10[0m] (step=0034800) Loss: 0.2749 (diff=0.1594, repa=0.2310, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:42:47[0m] (step=0034900) Loss: 0.2759 (diff=0.1604, repa=0.2311, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:43:24[0m] (step=0035000) Loss: 0.2799 (diff=0.1650, repa=0.2298, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:44:01[0m] (step=0035100) Loss: 0.2775 (diff=0.1625, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:44:38[0m] (step=0035200) Loss: 0.2782 (diff=0.1630, repa=0.2305, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:45:15[0m] (step=0035300) Loss: 0.2843 (diff=0.1696, repa=0.2294, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:45:52[0m] (step=0035400) Loss: 0.2736 (diff=0.1581, repa=0.2309, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:46:29[0m] (step=0035500) Loss: 0.2760 (diff=0.1606, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:47:06[0m] (step=0035600) Loss: 0.2819 (diff=0.1668, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:47:43[0m] (step=0035700) Loss: 0.2766 (diff=0.1613, repa=0.2305, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:48:20[0m] (step=0035800) Loss: 0.2662 (diff=0.1505, repa=0.2314, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:48:57[0m] (step=0035900) Loss: 0.2768 (diff=0.1614, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:49:34[0m] (step=0036000) Loss: 0.2814 (diff=0.1663, repa=0.2303, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:50:11[0m] (step=0036100) Loss: 0.2713 (diff=0.1560, repa=0.2305, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:50:48[0m] (step=0036200) Loss: 0.2768 (diff=0.1613, repa=0.2309, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:51:25[0m] (step=0036300) Loss: 0.2776 (diff=0.1629, repa=0.2296, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:52:02[0m] (step=0036400) Loss: 0.2721 (diff=0.1567, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:52:39[0m] (step=0036500) Loss: 0.2747 (diff=0.1596, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:53:16[0m] (step=0036600) Loss: 0.2720 (diff=0.1567, repa=0.2306, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:53:53[0m] (step=0036700) Loss: 0.2720 (diff=0.1567, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:54:30[0m] (step=0036800) Loss: 0.2786 (diff=0.1636, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:55:08[0m] (step=0036900) Loss: 0.2832 (diff=0.1683, repa=0.2297, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:55:45[0m] (step=0037000) Loss: 0.2726 (diff=0.1573, repa=0.2306, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:56:22[0m] (step=0037100) Loss: 0.2746 (diff=0.1593, repa=0.2306, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:56:59[0m] (step=0037200) Loss: 0.2752 (diff=0.1601, repa=0.2302, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:57:36[0m] (step=0037300) Loss: 0.2742 (diff=0.1590, repa=0.2304, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:58:13[0m] (step=0037400) Loss: 0.2758 (diff=0.1604, repa=0.2308, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:58:50[0m] (step=0037500) Loss: 0.2787 (diff=0.1636, repa=0.2302, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-08 23:59:27[0m] (step=0037600) Loss: 0.2749 (diff=0.1595, repa=0.2308, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 00:00:04[0m] (step=0037700) Loss: 0.2710 (diff=0.1557, repa=0.2306, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 00:00:41[0m] (step=0037800) Loss: 0.2717 (diff=0.1565, repa=0.2304, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:01:18[0m] (step=0037900) Loss: 0.2706 (diff=0.1550, repa=0.2311, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:01:55[0m] (step=0038000) Loss: 0.2770 (diff=0.1620, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:02:32[0m] (step=0038100) Loss: 0.2718 (diff=0.1564, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:03:09[0m] (step=0038200) Loss: 0.2713 (diff=0.1560, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:03:46[0m] (step=0038300) Loss: 0.2733 (diff=0.1584, repa=0.2297, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:04:24[0m] (step=0038400) Loss: 0.2763 (diff=0.1613, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:05:01[0m] (step=0038500) Loss: 0.2746 (diff=0.1597, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:05:38[0m] (step=0038600) Loss: 0.2759 (diff=0.1608, repa=0.2303, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:06:15[0m] (step=0038700) Loss: 0.2687 (diff=0.1533, repa=0.2308, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:06:52[0m] (step=0038800) Loss: 0.2802 (diff=0.1651, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:07:29[0m] (step=0038900) Loss: 0.2743 (diff=0.1592, repa=0.2302, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:08:06[0m] (step=0039000) Loss: 0.2763 (diff=0.1618, repa=0.2289, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:08:43[0m] (step=0039100) Loss: 0.2771 (diff=0.1622, repa=0.2298, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:09:20[0m] (step=0039200) Loss: 0.2754 (diff=0.1605, repa=0.2297, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:09:57[0m] (step=0039300) Loss: 0.2756 (diff=0.1606, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:10:34[0m] (step=0039400) Loss: 0.2757 (diff=0.1606, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:11:11[0m] (step=0039500) Loss: 0.2779 (diff=0.1634, repa=0.2289, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:11:48[0m] (step=0039600) Loss: 0.2762 (diff=0.1612, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:12:25[0m] (step=0039700) Loss: 0.2761 (diff=0.1613, repa=0.2296, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:13:02[0m] (step=0039800) Loss: 0.2755 (diff=0.1607, repa=0.2296, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:13:39[0m] (step=0039900) Loss: 0.2703 (diff=0.1551, repa=0.2304, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:14:16[0m] (step=0040000) Loss: 0.2774 (diff=0.1624, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:14:17[0m] Saved checkpoint to /data4/haksoo/trm_repa/001-DiT-XL-2/checkpoints/0040000.pt
/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  return func(*args, **kwargs)
[[34m2026-02-09 00:14:30[0m] Beginning epoch 2...
[[34m2026-02-09 00:14:54[0m] (step=0040100) Loss: 0.2770 (diff=0.1626, repa=0.2287, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 00:15:31[0m] (step=0040200) Loss: 0.2764 (diff=0.1613, repa=0.2302, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:16:08[0m] (step=0040300) Loss: 0.2752 (diff=0.1604, repa=0.2296, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:16:45[0m] (step=0040400) Loss: 0.2725 (diff=0.1578, repa=0.2293, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:17:22[0m] (step=0040500) Loss: 0.2770 (diff=0.1623, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:17:59[0m] (step=0040600) Loss: 0.2697 (diff=0.1546, repa=0.2303, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:18:36[0m] (step=0040700) Loss: 0.2747 (diff=0.1597, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:19:13[0m] (step=0040800) Loss: 0.2745 (diff=0.1596, repa=0.2298, λ=0.5) Steps/Sec: 2.71
[[34m2026-02-09 00:19:50[0m] (step=0040900) Loss: 0.2735 (diff=0.1588, repa=0.2293, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:20:27[0m] (step=0041000) Loss: 0.2743 (diff=0.1597, repa=0.2293, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:21:04[0m] (step=0041100) Loss: 0.2750 (diff=0.1598, repa=0.2305, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:21:41[0m] (step=0041200) Loss: 0.2721 (diff=0.1568, repa=0.2307, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:22:18[0m] (step=0041300) Loss: 0.2719 (diff=0.1565, repa=0.2306, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:22:55[0m] (step=0041400) Loss: 0.2722 (diff=0.1572, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:23:33[0m] (step=0041500) Loss: 0.2753 (diff=0.1603, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:24:10[0m] (step=0041600) Loss: 0.2673 (diff=0.1519, repa=0.2308, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:24:47[0m] (step=0041700) Loss: 0.2698 (diff=0.1545, repa=0.2306, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:25:24[0m] (step=0041800) Loss: 0.2744 (diff=0.1593, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:26:01[0m] (step=0041900) Loss: 0.2725 (diff=0.1574, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:26:38[0m] (step=0042000) Loss: 0.2760 (diff=0.1610, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:27:15[0m] (step=0042100) Loss: 0.2785 (diff=0.1639, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:27:52[0m] (step=0042200) Loss: 0.2739 (diff=0.1587, repa=0.2303, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:28:29[0m] (step=0042300) Loss: 0.2723 (diff=0.1577, repa=0.2293, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 00:29:06[0m] (step=0042400) Loss: 0.2712 (diff=0.1561, repa=0.2302, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:29:43[0m] (step=0042500) Loss: 0.2747 (diff=0.1601, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:30:20[0m] (step=0042600) Loss: 0.2718 (diff=0.1568, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:30:57[0m] (step=0042700) Loss: 0.2718 (diff=0.1567, repa=0.2303, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:31:34[0m] (step=0042800) Loss: 0.2763 (diff=0.1620, repa=0.2287, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:32:11[0m] (step=0042900) Loss: 0.2741 (diff=0.1592, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:32:48[0m] (step=0043000) Loss: 0.2766 (diff=0.1617, repa=0.2298, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:33:25[0m] (step=0043100) Loss: 0.2734 (diff=0.1584, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:34:02[0m] (step=0043200) Loss: 0.2732 (diff=0.1583, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:34:39[0m] (step=0043300) Loss: 0.2755 (diff=0.1609, repa=0.2293, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 00:35:16[0m] (step=0043400) Loss: 0.2737 (diff=0.1587, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:35:53[0m] (step=0043500) Loss: 0.2720 (diff=0.1572, repa=0.2295, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:36:30[0m] (step=0043600) Loss: 0.2827 (diff=0.1684, repa=0.2287, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:37:07[0m] (step=0043700) Loss: 0.2750 (diff=0.1598, repa=0.2303, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:37:44[0m] (step=0043800) Loss: 0.2753 (diff=0.1608, repa=0.2288, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:38:21[0m] (step=0043900) Loss: 0.2779 (diff=0.1634, repa=0.2291, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:38:59[0m] (step=0044000) Loss: 0.2707 (diff=0.1558, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:39:36[0m] (step=0044100) Loss: 0.2734 (diff=0.1583, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:40:13[0m] (step=0044200) Loss: 0.2736 (diff=0.1585, repa=0.2302, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:40:50[0m] (step=0044300) Loss: 0.2750 (diff=0.1605, repa=0.2290, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:41:27[0m] (step=0044400) Loss: 0.2721 (diff=0.1572, repa=0.2298, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:42:04[0m] (step=0044500) Loss: 0.2697 (diff=0.1548, repa=0.2297, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:42:41[0m] (step=0044600) Loss: 0.2725 (diff=0.1579, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:43:18[0m] (step=0044700) Loss: 0.2695 (diff=0.1546, repa=0.2297, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:43:55[0m] (step=0044800) Loss: 0.2741 (diff=0.1595, repa=0.2290, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:44:32[0m] (step=0044900) Loss: 0.2675 (diff=0.1523, repa=0.2304, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 00:45:09[0m] (step=0045000) Loss: 0.2732 (diff=0.1581, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:45:46[0m] (step=0045100) Loss: 0.2733 (diff=0.1587, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:46:23[0m] (step=0045200) Loss: 0.2749 (diff=0.1604, repa=0.2289, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:47:00[0m] (step=0045300) Loss: 0.2746 (diff=0.1599, repa=0.2294, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:47:37[0m] (step=0045400) Loss: 0.2710 (diff=0.1565, repa=0.2290, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:48:14[0m] (step=0045500) Loss: 0.2712 (diff=0.1563, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:48:51[0m] (step=0045600) Loss: 0.2705 (diff=0.1558, repa=0.2295, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:49:28[0m] (step=0045700) Loss: 0.2705 (diff=0.1556, repa=0.2298, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:50:05[0m] (step=0045800) Loss: 0.2750 (diff=0.1605, repa=0.2289, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:50:42[0m] (step=0045900) Loss: 0.2783 (diff=0.1641, repa=0.2282, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:51:19[0m] (step=0046000) Loss: 0.2761 (diff=0.1611, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:51:56[0m] (step=0046100) Loss: 0.2768 (diff=0.1624, repa=0.2286, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:52:34[0m] (step=0046200) Loss: 0.2729 (diff=0.1580, repa=0.2298, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:53:11[0m] (step=0046300) Loss: 0.2718 (diff=0.1569, repa=0.2299, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 00:53:48[0m] (step=0046400) Loss: 0.2697 (diff=0.1548, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:54:25[0m] (step=0046500) Loss: 0.2738 (diff=0.1589, repa=0.2298, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 00:55:02[0m] (step=0046600) Loss: 0.2680 (diff=0.1532, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 00:55:39[0m] (step=0046700) Loss: 0.2746 (diff=0.1601, repa=0.2289, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:56:16[0m] (step=0046800) Loss: 0.2704 (diff=0.1555, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:56:53[0m] (step=0046900) Loss: 0.2751 (diff=0.1605, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:57:30[0m] (step=0047000) Loss: 0.2746 (diff=0.1597, repa=0.2297, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:58:07[0m] (step=0047100) Loss: 0.2695 (diff=0.1544, repa=0.2302, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:58:44[0m] (step=0047200) Loss: 0.2713 (diff=0.1567, repa=0.2293, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:59:21[0m] (step=0047300) Loss: 0.2712 (diff=0.1563, repa=0.2299, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 00:59:58[0m] (step=0047400) Loss: 0.2773 (diff=0.1629, repa=0.2288, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:00:35[0m] (step=0047500) Loss: 0.2749 (diff=0.1607, repa=0.2286, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:01:12[0m] (step=0047600) Loss: 0.2727 (diff=0.1579, repa=0.2295, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:01:49[0m] (step=0047700) Loss: 0.2745 (diff=0.1599, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:02:26[0m] (step=0047800) Loss: 0.2742 (diff=0.1596, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:03:03[0m] (step=0047900) Loss: 0.2782 (diff=0.1640, repa=0.2284, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:03:40[0m] (step=0048000) Loss: 0.2733 (diff=0.1590, repa=0.2286, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:04:18[0m] (step=0048100) Loss: 0.2732 (diff=0.1585, repa=0.2294, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:04:55[0m] (step=0048200) Loss: 0.2714 (diff=0.1571, repa=0.2288, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:05:32[0m] (step=0048300) Loss: 0.2742 (diff=0.1599, repa=0.2286, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:06:09[0m] (step=0048400) Loss: 0.2749 (diff=0.1605, repa=0.2288, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:06:46[0m] (step=0048500) Loss: 0.2735 (diff=0.1591, repa=0.2289, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:07:23[0m] (step=0048600) Loss: 0.2743 (diff=0.1597, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:08:00[0m] (step=0048700) Loss: 0.2705 (diff=0.1559, repa=0.2291, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:08:37[0m] (step=0048800) Loss: 0.2751 (diff=0.1609, repa=0.2284, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:09:14[0m] (step=0048900) Loss: 0.2704 (diff=0.1554, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:09:51[0m] (step=0049000) Loss: 0.2684 (diff=0.1534, repa=0.2300, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:10:28[0m] (step=0049100) Loss: 0.2728 (diff=0.1583, repa=0.2290, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:11:05[0m] (step=0049200) Loss: 0.2705 (diff=0.1559, repa=0.2293, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:11:42[0m] (step=0049300) Loss: 0.2759 (diff=0.1612, repa=0.2294, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:12:19[0m] (step=0049400) Loss: 0.2806 (diff=0.1665, repa=0.2281, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:12:56[0m] (step=0049500) Loss: 0.2736 (diff=0.1585, repa=0.2301, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:13:33[0m] (step=0049600) Loss: 0.2716 (diff=0.1567, repa=0.2297, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:14:10[0m] (step=0049700) Loss: 0.2729 (diff=0.1583, repa=0.2292, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:14:47[0m] (step=0049800) Loss: 0.2719 (diff=0.1575, repa=0.2288, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:15:24[0m] (step=0049900) Loss: 0.2729 (diff=0.1584, repa=0.2289, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 01:16:01[0m] (step=0050000) Loss: 0.2718 (diff=0.1571, repa=0.2295, λ=0.5) Steps/Sec: 2.70
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/haksoo/DiT/train_repa_flash.py", line 767, in <module>
[rank3]:     main(args)
[rank3]:   File "/home/haksoo/DiT/train_repa_flash.py", line 611, in main
[rank3]:     loss_dict = diffusion.training_losses(model, x_lat, t, model_kwargs)
[rank3]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/haksoo/DiT/diffusion/respace.py", line 97, in training_losses
[rank3]:     return super().training_losses(self._wrap_model(model), *args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/haksoo/DiT/diffusion/gaussian_diffusion.py", line 747, in training_losses
[rank3]:     model_output = model(x_t, t, **model_kwargs)
[rank3]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/haksoo/DiT/diffusion/respace.py", line 129, in __call__
[rank3]:     return self.model(x, new_ts, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1662, in forward
[rank3]:     inputs, kwargs = self._pre_forward(*inputs, **kwargs)
[rank3]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1551, in _pre_forward
[rank3]:     if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
[rank3]:                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
[rank3]: making sure all `forward` function outputs participate in calculating loss. 
[rank3]: If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
[rank3]: Parameter indices which did not receive grad for rank 3: 23 24 25 26
[rank3]:  In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/haksoo/DiT/train_repa_flash.py", line 767, in <module>
[rank0]:     main(args)
[rank0]:   File "/home/haksoo/DiT/train_repa_flash.py", line 611, in main
[rank0]:     loss_dict = diffusion.training_losses(model, x_lat, t, model_kwargs)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/haksoo/DiT/diffusion/respace.py", line 97, in training_losses
[rank0]:     return super().training_losses(self._wrap_model(model), *args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/haksoo/DiT/diffusion/gaussian_diffusion.py", line 747, in training_losses
[rank0]:     model_output = model(x_t, t, **model_kwargs)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/haksoo/DiT/diffusion/respace.py", line 129, in __call__
[rank0]:     return self.model(x, new_ts, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1662, in forward
[rank0]:     inputs, kwargs = self._pre_forward(*inputs, **kwargs)
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1551, in _pre_forward
[rank0]:     if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
[rank0]:                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
[rank0]: making sure all `forward` function outputs participate in calculating loss. 
[rank0]: If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
[rank0]: Parameter indices which did not receive grad for rank 0: 23 24 25 26
[rank0]:  In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/haksoo/DiT/train_repa_flash.py", line 767, in <module>
[rank2]:     main(args)
[rank2]:   File "/home/haksoo/DiT/train_repa_flash.py", line 611, in main
[rank2]:     loss_dict = diffusion.training_losses(model, x_lat, t, model_kwargs)
[rank2]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/haksoo/DiT/diffusion/respace.py", line 97, in training_losses
[rank2]:     return super().training_losses(self._wrap_model(model), *args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/haksoo/DiT/diffusion/gaussian_diffusion.py", line 747, in training_losses
[rank2]:     model_output = model(x_t, t, **model_kwargs)
[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/haksoo/DiT/diffusion/respace.py", line 129, in __call__
[rank2]:     return self.model(x, new_ts, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1662, in forward
[rank2]:     inputs, kwargs = self._pre_forward(*inputs, **kwargs)
[rank2]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1551, in _pre_forward
[rank2]:     if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
[rank2]:                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
[rank2]: making sure all `forward` function outputs participate in calculating loss. 
[rank2]: If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
[rank2]: Parameter indices which did not receive grad for rank 2: 23 24 25 26
[rank2]:  In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/haksoo/DiT/train_repa_flash.py", line 767, in <module>
[rank1]:     main(args)
[rank1]:   File "/home/haksoo/DiT/train_repa_flash.py", line 611, in main
[rank1]:     loss_dict = diffusion.training_losses(model, x_lat, t, model_kwargs)
[rank1]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/haksoo/DiT/diffusion/respace.py", line 97, in training_losses
[rank1]:     return super().training_losses(self._wrap_model(model), *args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/haksoo/DiT/diffusion/gaussian_diffusion.py", line 747, in training_losses
[rank1]:     model_output = model(x_t, t, **model_kwargs)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/haksoo/DiT/diffusion/respace.py", line 129, in __call__
[rank1]:     return self.model(x, new_ts, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1662, in forward
[rank1]:     inputs, kwargs = self._pre_forward(*inputs, **kwargs)
[rank1]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1551, in _pre_forward
[rank1]:     if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
[rank1]:                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
[rank1]: making sure all `forward` function outputs participate in calculating loss. 
[rank1]: If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
[rank1]: Parameter indices which did not receive grad for rank 1: 23 24 25 26
[rank1]:  In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
[rank0]:[W209 01:16:02.843932615 ProcessGroupNCCL.cpp:1553] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W0209 01:16:03.702000 483415 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 483507 closing signal SIGTERM
W0209 01:16:03.703000 483415 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 483508 closing signal SIGTERM
W0209 01:16:03.704000 483415 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 483509 closing signal SIGTERM
E0209 01:16:04.320000 483415 site-packages/torch/distributed/elastic/multiprocessing/api.py:984] failed (exitcode: 1) local_rank: 3 (pid: 483510) of binary: /home/haksoo/anaconda3/envs/DiT_cu128/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 995, in <module>
    main()
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 991, in main
    run(args)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 982, in run
    elastic_launch(
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 170, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 317, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_repa_flash.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2026-02-09_01:16:04
  host      : Hinton
  rank      : 0 (local_rank: 0)
  exitcode  : -15 (pid: 483507)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 483507
[2]:
  time      : 2026-02-09_01:16:04
  host      : Hinton
  rank      : 1 (local_rank: 1)
  exitcode  : -15 (pid: 483508)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 483508
[3]:
  time      : 2026-02-09_01:16:04
  host      : Hinton
  rank      : 2 (local_rank: 2)
  exitcode  : -15 (pid: 483509)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 483509
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-02-09_01:16:03
  host      : Hinton
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 483510)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
  File "/home/haksoo/DiT/train_repa_flash.py", line 646
    if loss_repa is not None and lam > 0:
IndentationError: unexpected indent
  File "/home/haksoo/DiT/train_repa_flash.py", line 646
    if loss_repa is not None and lam > 0:
IndentationError: unexpected indent
  File "/home/haksoo/DiT/train_repa_flash.py", line 646
    if loss_repa is not None and lam > 0:
IndentationError: unexpected indent
  File "/home/haksoo/DiT/train_repa_flash.py", line 646
    if loss_repa is not None and lam > 0:
IndentationError: unexpected indent
E0209 01:56:54.346000 496561 site-packages/torch/distributed/elastic/multiprocessing/api.py:984] failed (exitcode: 1) local_rank: 0 (pid: 496653) of binary: /home/haksoo/anaconda3/envs/DiT_cu128/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 995, in <module>
    main()
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 991, in main
    run(args)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 982, in run
    elastic_launch(
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 170, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 317, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_repa_flash.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2026-02-09_01:56:54
  host      : Hinton
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 496654)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2026-02-09_01:56:54
  host      : Hinton
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 496655)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2026-02-09_01:56:54
  host      : Hinton
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 496656)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-02-09_01:56:54
  host      : Hinton
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 496653)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Starting rank=1, seed=1, world_size=4.
Starting rank=2, seed=2, world_size=4.
Starting rank=3, seed=3, world_size=4.
Starting rank=0, seed=0, world_size=4.
[[34m2026-02-09 01:58:29[0m] Experiment directory created at /data4/haksoo/trm_repa/002-DiT-XL-2
[[34m2026-02-09 01:58:30[0m] Loading REPA teacher via torch.hub: facebookresearch/dinov2::dinov2_vitb14
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
[[34m2026-02-09 01:58:30[0m] using MLP layer as FFN
[[34m2026-02-09 01:58:32[0m] Attached REPA projector: student_dim=1152 -> teacher_dim=768
[[34m2026-02-09 01:58:33[0m] Resumed from /data4/haksoo/trm_repa/001-DiT-XL-2/checkpoints/0040000.pt at step=40000
[[34m2026-02-09 01:58:33[0m] Registered REPA forward hooks on student blocks.
[[34m2026-02-09 01:58:33[0m] DiT Parameters: 30,578,338
[[34m2026-02-09 01:58:36[0m] Dataset contains 1,281,167 images (/data/ImageNet1k/train)
[[34m2026-02-09 01:58:36[0m] Training for 1400 epochs...
[[34m2026-02-09 01:58:36[0m] Beginning epoch 1...
[[34m2026-02-09 02:06:54[0m] Beginning epoch 2...
[[34m2026-02-09 02:07:18[0m] (step=0040100) Loss: 0.2760 (diff=0.1614, repa=0.2291, λ=0.5) Steps/Sec: 0.19
[[34m2026-02-09 02:07:55[0m] (step=0040200) Loss: 0.2731 (diff=0.1580, repa=0.2301, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 02:08:33[0m] (step=0040300) Loss: 0.2781 (diff=0.1632, repa=0.2297, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:09:11[0m] (step=0040400) Loss: 0.2748 (diff=0.1601, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:09:48[0m] (step=0040500) Loss: 0.2722 (diff=0.1570, repa=0.2304, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:10:26[0m] (step=0040600) Loss: 0.2754 (diff=0.1605, repa=0.2298, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:11:03[0m] (step=0040700) Loss: 0.2752 (diff=0.1604, repa=0.2297, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:11:41[0m] (step=0040800) Loss: 0.2725 (diff=0.1575, repa=0.2299, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:12:19[0m] (step=0040900) Loss: 0.2694 (diff=0.1543, repa=0.2300, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 02:12:56[0m] (step=0041000) Loss: 0.2760 (diff=0.1615, repa=0.2291, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 02:13:34[0m] (step=0041100) Loss: 0.2735 (diff=0.1585, repa=0.2299, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 02:14:12[0m] (step=0041200) Loss: 0.2721 (diff=0.1571, repa=0.2301, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 02:14:50[0m] (step=0041300) Loss: 0.2779 (diff=0.1627, repa=0.2305, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:15:27[0m] (step=0041400) Loss: 0.2751 (diff=0.1603, repa=0.2296, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:16:05[0m] (step=0041500) Loss: 0.2780 (diff=0.1631, repa=0.2299, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:16:43[0m] (step=0041600) Loss: 0.2753 (diff=0.1605, repa=0.2297, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:17:20[0m] (step=0041700) Loss: 0.2767 (diff=0.1620, repa=0.2294, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:17:58[0m] (step=0041800) Loss: 0.2785 (diff=0.1636, repa=0.2299, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:18:35[0m] (step=0041900) Loss: 0.2712 (diff=0.1565, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:19:13[0m] (step=0042000) Loss: 0.2771 (diff=0.1620, repa=0.2302, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:19:51[0m] (step=0042100) Loss: 0.2756 (diff=0.1609, repa=0.2294, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:20:28[0m] (step=0042200) Loss: 0.2687 (diff=0.1532, repa=0.2310, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:21:06[0m] (step=0042300) Loss: 0.2737 (diff=0.1592, repa=0.2289, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:21:44[0m] (step=0042400) Loss: 0.2714 (diff=0.1567, repa=0.2294, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:22:21[0m] (step=0042500) Loss: 0.2763 (diff=0.1617, repa=0.2292, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:22:59[0m] (step=0042600) Loss: 0.2745 (diff=0.1594, repa=0.2301, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:23:36[0m] (step=0042700) Loss: 0.2724 (diff=0.1574, repa=0.2301, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:24:14[0m] (step=0042800) Loss: 0.2683 (diff=0.1533, repa=0.2301, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:24:52[0m] (step=0042900) Loss: 0.2750 (diff=0.1602, repa=0.2296, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:25:29[0m] (step=0043000) Loss: 0.2780 (diff=0.1636, repa=0.2288, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:26:07[0m] (step=0043100) Loss: 0.2764 (diff=0.1617, repa=0.2296, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:26:45[0m] (step=0043200) Loss: 0.2758 (diff=0.1608, repa=0.2300, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:27:22[0m] (step=0043300) Loss: 0.2777 (diff=0.1629, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:28:00[0m] (step=0043400) Loss: 0.2779 (diff=0.1629, repa=0.2298, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:28:37[0m] (step=0043500) Loss: 0.2704 (diff=0.1557, repa=0.2294, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:29:15[0m] (step=0043600) Loss: 0.2764 (diff=0.1617, repa=0.2293, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:29:53[0m] (step=0043700) Loss: 0.2793 (diff=0.1649, repa=0.2289, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:30:30[0m] (step=0043800) Loss: 0.2681 (diff=0.1531, repa=0.2299, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:31:08[0m] (step=0043900) Loss: 0.2739 (diff=0.1591, repa=0.2297, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:31:45[0m] (step=0044000) Loss: 0.2767 (diff=0.1623, repa=0.2288, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:32:23[0m] (step=0044100) Loss: 0.2734 (diff=0.1585, repa=0.2299, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:33:01[0m] (step=0044200) Loss: 0.2724 (diff=0.1573, repa=0.2302, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:33:38[0m] (step=0044300) Loss: 0.2762 (diff=0.1619, repa=0.2286, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:34:16[0m] (step=0044400) Loss: 0.2773 (diff=0.1627, repa=0.2292, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:34:54[0m] (step=0044500) Loss: 0.2783 (diff=0.1639, repa=0.2288, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:35:31[0m] (step=0044600) Loss: 0.2822 (diff=0.1677, repa=0.2290, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:36:09[0m] (step=0044700) Loss: 0.2805 (diff=0.1664, repa=0.2283, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:36:46[0m] (step=0044800) Loss: 0.2747 (diff=0.1600, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:37:24[0m] (step=0044900) Loss: 0.2699 (diff=0.1547, repa=0.2305, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:38:02[0m] (step=0045000) Loss: 0.2783 (diff=0.1635, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:38:39[0m] (step=0045100) Loss: 0.2798 (diff=0.1654, repa=0.2288, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 02:39:17[0m] (step=0045200) Loss: 0.2745 (diff=0.1599, repa=0.2291, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:39:55[0m] (step=0045300) Loss: 0.2655 (diff=0.1502, repa=0.2306, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:40:32[0m] (step=0045400) Loss: 0.2713 (diff=0.1565, repa=0.2296, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 02:41:10[0m] (step=0045500) Loss: 0.2777 (diff=0.1631, repa=0.2292, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 02:41:48[0m] (step=0045600) Loss: 0.2788 (diff=0.1644, repa=0.2287, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 02:42:25[0m] (step=0045700) Loss: 0.2772 (diff=0.1628, repa=0.2289, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:43:03[0m] (step=0045800) Loss: 0.2699 (diff=0.1548, repa=0.2302, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:43:41[0m] (step=0045900) Loss: 0.2711 (diff=0.1563, repa=0.2295, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 02:44:18[0m] (step=0046000) Loss: 0.2755 (diff=0.1606, repa=0.2299, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:44:56[0m] (step=0046100) Loss: 0.2741 (diff=0.1597, repa=0.2288, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:45:34[0m] (step=0046200) Loss: 0.2726 (diff=0.1580, repa=0.2290, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:46:11[0m] (step=0046300) Loss: 0.2784 (diff=0.1640, repa=0.2288, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:46:49[0m] (step=0046400) Loss: 0.2690 (diff=0.1543, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:47:27[0m] (step=0046500) Loss: 0.2722 (diff=0.1576, repa=0.2293, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:48:04[0m] (step=0046600) Loss: 0.2791 (diff=0.1649, repa=0.2284, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:48:42[0m] (step=0046700) Loss: 0.2765 (diff=0.1620, repa=0.2288, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:49:20[0m] (step=0046800) Loss: 0.2757 (diff=0.1612, repa=0.2289, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:49:57[0m] (step=0046900) Loss: 0.2740 (diff=0.1591, repa=0.2297, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:50:35[0m] (step=0047000) Loss: 0.2779 (diff=0.1634, repa=0.2291, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 02:51:13[0m] (step=0047100) Loss: 0.2748 (diff=0.1601, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:51:50[0m] (step=0047200) Loss: 0.2763 (diff=0.1615, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:52:28[0m] (step=0047300) Loss: 0.2720 (diff=0.1573, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:53:05[0m] (step=0047400) Loss: 0.2731 (diff=0.1580, repa=0.2302, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:53:43[0m] (step=0047500) Loss: 0.2741 (diff=0.1598, repa=0.2287, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:54:21[0m] (step=0047600) Loss: 0.2728 (diff=0.1582, repa=0.2291, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:54:58[0m] (step=0047700) Loss: 0.2745 (diff=0.1603, repa=0.2284, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:55:36[0m] (step=0047800) Loss: 0.2681 (diff=0.1532, repa=0.2297, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:56:14[0m] (step=0047900) Loss: 0.2736 (diff=0.1591, repa=0.2290, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:56:51[0m] (step=0048000) Loss: 0.2792 (diff=0.1653, repa=0.2277, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:57:29[0m] (step=0048100) Loss: 0.2745 (diff=0.1601, repa=0.2288, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:58:07[0m] (step=0048200) Loss: 0.2753 (diff=0.1611, repa=0.2284, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:58:44[0m] (step=0048300) Loss: 0.2730 (diff=0.1584, repa=0.2292, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 02:59:22[0m] (step=0048400) Loss: 0.2736 (diff=0.1590, repa=0.2293, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 03:00:00[0m] (step=0048500) Loss: 0.2695 (diff=0.1549, repa=0.2293, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 03:00:38[0m] (step=0048600) Loss: 0.2717 (diff=0.1569, repa=0.2296, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 03:01:15[0m] (step=0048700) Loss: 0.2761 (diff=0.1619, repa=0.2283, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:01:53[0m] (step=0048800) Loss: 0.2778 (diff=0.1636, repa=0.2286, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:02:30[0m] (step=0048900) Loss: 0.2730 (diff=0.1582, repa=0.2296, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 03:03:08[0m] (step=0049000) Loss: 0.2739 (diff=0.1593, repa=0.2291, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:03:46[0m] (step=0049100) Loss: 0.2741 (diff=0.1593, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:04:23[0m] (step=0049200) Loss: 0.2780 (diff=0.1638, repa=0.2284, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:05:01[0m] (step=0049300) Loss: 0.2706 (diff=0.1557, repa=0.2297, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:05:39[0m] (step=0049400) Loss: 0.2671 (diff=0.1523, repa=0.2296, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:06:16[0m] (step=0049500) Loss: 0.2678 (diff=0.1525, repa=0.2306, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:06:54[0m] (step=0049600) Loss: 0.2716 (diff=0.1567, repa=0.2298, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:07:32[0m] (step=0049700) Loss: 0.2748 (diff=0.1604, repa=0.2289, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:08:09[0m] (step=0049800) Loss: 0.2726 (diff=0.1580, repa=0.2291, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:08:47[0m] (step=0049900) Loss: 0.2714 (diff=0.1566, repa=0.2295, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 03:09:25[0m] (step=0050000) Loss: 0.2708 (diff=0.1561, repa=0.2294, λ=0.5) Steps/Sec: 2.65
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/haksoo/DiT/train_repa_flash.py", line 781, in <module>
[rank0]:     main(args)
[rank0]:   File "/home/haksoo/DiT/train_repa_flash.py", line 663, in main
[rank0]:     scaler.scale(loss).backward()
[rank0]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/_tensor.py", line 630, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/autograd/__init__.py", line 364, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/autograd/graph.py", line 865, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/haksoo/DiT/train_repa_flash.py", line 781, in <module>
[rank1]:     main(args)
[rank1]:   File "/home/haksoo/DiT/train_repa_flash.py", line 663, in main
[rank1]:     scaler.scale(loss).backward()
[rank1]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/_tensor.py", line 630, in backward
[rank1]:     torch.autograd.backward(
[rank1]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/autograd/__init__.py", line 364, in backward
[rank1]:     _engine_run_backward(
[rank1]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/autograd/graph.py", line 865, in _engine_run_backward
[rank1]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]: RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/haksoo/DiT/train_repa_flash.py", line 781, in <module>
[rank2]:     main(args)
[rank2]:   File "/home/haksoo/DiT/train_repa_flash.py", line 663, in main
[rank2]:     scaler.scale(loss).backward()
[rank2]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/_tensor.py", line 630, in backward
[rank2]:     torch.autograd.backward(
[rank2]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/autograd/__init__.py", line 364, in backward
[rank2]:     _engine_run_backward(
[rank2]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/autograd/graph.py", line 865, in _engine_run_backward
[rank2]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]: RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/haksoo/DiT/train_repa_flash.py", line 781, in <module>
[rank3]:     main(args)
[rank3]:   File "/home/haksoo/DiT/train_repa_flash.py", line 663, in main
[rank3]:     scaler.scale(loss).backward()
[rank3]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/_tensor.py", line 630, in backward
[rank3]:     torch.autograd.backward(
[rank3]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/autograd/__init__.py", line 364, in backward
[rank3]:     _engine_run_backward(
[rank3]:   File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/autograd/graph.py", line 865, in _engine_run_backward
[rank3]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]: RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
[rank0]:[W209 03:09:25.753733219 ProcessGroupNCCL.cpp:1553] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W0209 03:09:27.169000 496726 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 496810 closing signal SIGTERM
W0209 03:09:27.172000 496726 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 496812 closing signal SIGTERM
W0209 03:09:27.173000 496726 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 496813 closing signal SIGTERM
E0209 03:09:27.716000 496726 site-packages/torch/distributed/elastic/multiprocessing/api.py:984] failed (exitcode: 1) local_rank: 1 (pid: 496811) of binary: /home/haksoo/anaconda3/envs/DiT_cu128/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 995, in <module>
    main()
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 991, in main
    run(args)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 982, in run
    elastic_launch(
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 170, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 317, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_repa_flash.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2026-02-09_03:09:27
  host      : Hinton
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 496810)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2026-02-09_03:09:27
  host      : Hinton
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 496812)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2026-02-09_03:09:27
  host      : Hinton
  rank      : 3 (local_rank: 3)
  exitcode  : -15 (pid: 496813)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 496813
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-02-09_03:09:27
  host      : Hinton
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 496811)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Starting rank=1, seed=1, world_size=4.
Starting rank=2, seed=2, world_size=4.
Starting rank=0, seed=0, world_size=4.
[[34m2026-02-09 16:05:16[0m] Experiment directory created at /data4/haksoo/trm_repa/004-DiT-XL-2
Starting rank=3, seed=3, world_size=4.
[[34m2026-02-09 16:05:16[0m] Loading REPA teacher via torch.hub: facebookresearch/dinov2::dinov2_vitb14
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
[[34m2026-02-09 16:05:17[0m] using MLP layer as FFN
[[34m2026-02-09 16:05:19[0m] Attached REPA projector: student_dim=1152 -> teacher_dim=768
[[34m2026-02-09 16:05:20[0m] Resumed from /data4/haksoo/trm_repa/001-DiT-XL-2/checkpoints/0040000.pt at step=40000
[[34m2026-02-09 16:05:20[0m] Registered REPA forward hooks on student blocks.
[[34m2026-02-09 16:05:21[0m] DiT Parameters: 30,578,338
[[34m2026-02-09 16:05:23[0m] Dataset contains 1,281,167 images (/data/ImageNet1k/train)
[[34m2026-02-09 16:05:23[0m] Training for 1400 epochs...
[[34m2026-02-09 16:05:23[0m] Beginning epoch 1...
[[34m2026-02-09 16:13:45[0m] Beginning epoch 2...
[[34m2026-02-09 16:14:10[0m] (step=0040100) Loss: 0.2760 (diff=0.1614, repa=0.2291, λ=0.5) Steps/Sec: 0.19
[[34m2026-02-09 16:14:47[0m] (step=0040200) Loss: 0.2731 (diff=0.1580, repa=0.2301, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 16:15:25[0m] (step=0040300) Loss: 0.2781 (diff=0.1632, repa=0.2297, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 16:16:03[0m] (step=0040400) Loss: 0.2748 (diff=0.1601, repa=0.2295, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 16:16:40[0m] (step=0040500) Loss: 0.2722 (diff=0.1570, repa=0.2304, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:17:18[0m] (step=0040600) Loss: 0.2754 (diff=0.1605, repa=0.2298, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 16:17:56[0m] (step=0040700) Loss: 0.2752 (diff=0.1604, repa=0.2297, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:18:34[0m] (step=0040800) Loss: 0.2725 (diff=0.1575, repa=0.2299, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 16:19:11[0m] (step=0040900) Loss: 0.2694 (diff=0.1543, repa=0.2300, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 16:19:49[0m] (step=0041000) Loss: 0.2760 (diff=0.1615, repa=0.2291, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 16:20:26[0m] (step=0041100) Loss: 0.2734 (diff=0.1585, repa=0.2299, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 16:21:04[0m] (step=0041200) Loss: 0.2721 (diff=0.1571, repa=0.2301, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 16:21:41[0m] (step=0041300) Loss: 0.2779 (diff=0.1627, repa=0.2305, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 16:22:18[0m] (step=0041400) Loss: 0.2751 (diff=0.1603, repa=0.2296, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 16:22:56[0m] (step=0041500) Loss: 0.2780 (diff=0.1631, repa=0.2299, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 16:23:34[0m] (step=0041600) Loss: 0.2753 (diff=0.1605, repa=0.2297, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:24:11[0m] (step=0041700) Loss: 0.2767 (diff=0.1620, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:24:49[0m] (step=0041800) Loss: 0.2785 (diff=0.1636, repa=0.2299, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:25:27[0m] (step=0041900) Loss: 0.2712 (diff=0.1565, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:26:05[0m] (step=0042000) Loss: 0.2771 (diff=0.1620, repa=0.2302, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:26:43[0m] (step=0042100) Loss: 0.2756 (diff=0.1609, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:27:21[0m] (step=0042200) Loss: 0.2687 (diff=0.1532, repa=0.2310, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:27:59[0m] (step=0042300) Loss: 0.2737 (diff=0.1592, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:28:37[0m] (step=0042400) Loss: 0.2714 (diff=0.1567, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:29:15[0m] (step=0042500) Loss: 0.2763 (diff=0.1617, repa=0.2292, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:29:53[0m] (step=0042600) Loss: 0.2745 (diff=0.1594, repa=0.2301, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:30:31[0m] (step=0042700) Loss: 0.2724 (diff=0.1574, repa=0.2301, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:31:09[0m] (step=0042800) Loss: 0.2683 (diff=0.1533, repa=0.2301, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:31:47[0m] (step=0042900) Loss: 0.2750 (diff=0.1602, repa=0.2296, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:32:24[0m] (step=0043000) Loss: 0.2780 (diff=0.1636, repa=0.2288, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:33:02[0m] (step=0043100) Loss: 0.2764 (diff=0.1617, repa=0.2296, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 16:33:40[0m] (step=0043200) Loss: 0.2758 (diff=0.1608, repa=0.2300, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:34:18[0m] (step=0043300) Loss: 0.2777 (diff=0.1629, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:34:56[0m] (step=0043400) Loss: 0.2779 (diff=0.1629, repa=0.2298, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:35:34[0m] (step=0043500) Loss: 0.2704 (diff=0.1557, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:36:12[0m] (step=0043600) Loss: 0.2764 (diff=0.1617, repa=0.2293, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:36:50[0m] (step=0043700) Loss: 0.2793 (diff=0.1649, repa=0.2289, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 16:37:28[0m] (step=0043800) Loss: 0.2681 (diff=0.1531, repa=0.2299, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:38:05[0m] (step=0043900) Loss: 0.2739 (diff=0.1591, repa=0.2297, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:38:43[0m] (step=0044000) Loss: 0.2767 (diff=0.1623, repa=0.2288, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:39:21[0m] (step=0044100) Loss: 0.2734 (diff=0.1585, repa=0.2299, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:39:59[0m] (step=0044200) Loss: 0.2724 (diff=0.1573, repa=0.2302, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:40:37[0m] (step=0044300) Loss: 0.2762 (diff=0.1619, repa=0.2286, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:41:15[0m] (step=0044400) Loss: 0.2773 (diff=0.1627, repa=0.2292, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:41:53[0m] (step=0044500) Loss: 0.2784 (diff=0.1639, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:42:31[0m] (step=0044600) Loss: 0.2822 (diff=0.1678, repa=0.2290, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:43:09[0m] (step=0044700) Loss: 0.2805 (diff=0.1664, repa=0.2283, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:43:46[0m] (step=0044800) Loss: 0.2747 (diff=0.1600, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:44:24[0m] (step=0044900) Loss: 0.2700 (diff=0.1547, repa=0.2305, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:45:02[0m] (step=0045000) Loss: 0.2783 (diff=0.1635, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:45:40[0m] (step=0045100) Loss: 0.2798 (diff=0.1654, repa=0.2288, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:46:18[0m] (step=0045200) Loss: 0.2745 (diff=0.1599, repa=0.2291, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:46:56[0m] (step=0045300) Loss: 0.2655 (diff=0.1502, repa=0.2306, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:47:34[0m] (step=0045400) Loss: 0.2713 (diff=0.1565, repa=0.2296, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:48:12[0m] (step=0045500) Loss: 0.2777 (diff=0.1631, repa=0.2292, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:48:50[0m] (step=0045600) Loss: 0.2788 (diff=0.1644, repa=0.2287, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:49:28[0m] (step=0045700) Loss: 0.2772 (diff=0.1628, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:50:06[0m] (step=0045800) Loss: 0.2699 (diff=0.1548, repa=0.2302, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:50:44[0m] (step=0045900) Loss: 0.2711 (diff=0.1563, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:51:22[0m] (step=0046000) Loss: 0.2755 (diff=0.1606, repa=0.2299, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:52:00[0m] (step=0046100) Loss: 0.2741 (diff=0.1597, repa=0.2288, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:52:38[0m] (step=0046200) Loss: 0.2726 (diff=0.1580, repa=0.2290, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:53:16[0m] (step=0046300) Loss: 0.2784 (diff=0.1640, repa=0.2288, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:53:54[0m] (step=0046400) Loss: 0.2690 (diff=0.1543, repa=0.2295, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:54:32[0m] (step=0046500) Loss: 0.2722 (diff=0.1575, repa=0.2293, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:55:10[0m] (step=0046600) Loss: 0.2791 (diff=0.1649, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:55:48[0m] (step=0046700) Loss: 0.2765 (diff=0.1620, repa=0.2288, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:56:26[0m] (step=0046800) Loss: 0.2757 (diff=0.1612, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:57:04[0m] (step=0046900) Loss: 0.2740 (diff=0.1591, repa=0.2297, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:57:42[0m] (step=0047000) Loss: 0.2779 (diff=0.1634, repa=0.2291, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:58:20[0m] (step=0047100) Loss: 0.2748 (diff=0.1601, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 16:58:58[0m] (step=0047200) Loss: 0.2763 (diff=0.1615, repa=0.2295, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 16:59:35[0m] (step=0047300) Loss: 0.2720 (diff=0.1573, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:00:14[0m] (step=0047400) Loss: 0.2731 (diff=0.1580, repa=0.2302, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:00:51[0m] (step=0047500) Loss: 0.2741 (diff=0.1598, repa=0.2287, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 17:01:29[0m] (step=0047600) Loss: 0.2728 (diff=0.1582, repa=0.2291, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:02:07[0m] (step=0047700) Loss: 0.2745 (diff=0.1603, repa=0.2284, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:02:45[0m] (step=0047800) Loss: 0.2681 (diff=0.1532, repa=0.2297, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:03:23[0m] (step=0047900) Loss: 0.2736 (diff=0.1591, repa=0.2290, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:04:01[0m] (step=0048000) Loss: 0.2792 (diff=0.1653, repa=0.2277, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:04:39[0m] (step=0048100) Loss: 0.2745 (diff=0.1601, repa=0.2288, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:05:17[0m] (step=0048200) Loss: 0.2753 (diff=0.1611, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:05:55[0m] (step=0048300) Loss: 0.2730 (diff=0.1584, repa=0.2292, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:06:33[0m] (step=0048400) Loss: 0.2736 (diff=0.1590, repa=0.2293, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:07:11[0m] (step=0048500) Loss: 0.2695 (diff=0.1549, repa=0.2293, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:07:49[0m] (step=0048600) Loss: 0.2717 (diff=0.1569, repa=0.2296, λ=0.5) Steps/Sec: 2.62
[[34m2026-02-09 17:08:27[0m] (step=0048700) Loss: 0.2761 (diff=0.1619, repa=0.2283, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:09:05[0m] (step=0048800) Loss: 0.2778 (diff=0.1636, repa=0.2286, λ=0.5) Steps/Sec: 2.62
[[34m2026-02-09 17:09:43[0m] (step=0048900) Loss: 0.2730 (diff=0.1582, repa=0.2296, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:10:21[0m] (step=0049000) Loss: 0.2739 (diff=0.1593, repa=0.2291, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:10:59[0m] (step=0049100) Loss: 0.2741 (diff=0.1593, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:11:37[0m] (step=0049200) Loss: 0.2780 (diff=0.1638, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:12:15[0m] (step=0049300) Loss: 0.2706 (diff=0.1557, repa=0.2297, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:12:53[0m] (step=0049400) Loss: 0.2671 (diff=0.1523, repa=0.2296, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:13:31[0m] (step=0049500) Loss: 0.2678 (diff=0.1525, repa=0.2306, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:14:09[0m] (step=0049600) Loss: 0.2716 (diff=0.1567, repa=0.2298, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:14:47[0m] (step=0049700) Loss: 0.2748 (diff=0.1604, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:15:25[0m] (step=0049800) Loss: 0.2726 (diff=0.1580, repa=0.2291, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:16:03[0m] (step=0049900) Loss: 0.2714 (diff=0.1566, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:16:40[0m] (step=0050000) Loss: 0.2708 (diff=0.1561, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:17:18[0m] (step=0050100) Loss: 0.2770 (diff=0.1631, repa=0.2278, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:17:56[0m] (step=0050200) Loss: 0.2751 (diff=0.1608, repa=0.2286, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:18:34[0m] (step=0050300) Loss: 0.2725 (diff=0.1575, repa=0.2298, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 17:19:12[0m] (step=0050400) Loss: 0.2741 (diff=0.1598, repa=0.2286, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:19:50[0m] (step=0050500) Loss: 0.2718 (diff=0.1573, repa=0.2290, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:20:28[0m] (step=0050600) Loss: 0.2775 (diff=0.1628, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:21:06[0m] (step=0050700) Loss: 0.2700 (diff=0.1555, repa=0.2290, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:21:44[0m] (step=0050800) Loss: 0.2762 (diff=0.1620, repa=0.2285, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:22:22[0m] (step=0050900) Loss: 0.2785 (diff=0.1639, repa=0.2290, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:22:59[0m] (step=0051000) Loss: 0.2756 (diff=0.1612, repa=0.2289, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:23:37[0m] (step=0051100) Loss: 0.2704 (diff=0.1558, repa=0.2293, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:24:15[0m] (step=0051200) Loss: 0.2689 (diff=0.1540, repa=0.2297, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:24:53[0m] (step=0051300) Loss: 0.2709 (diff=0.1563, repa=0.2292, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:25:31[0m] (step=0051400) Loss: 0.2679 (diff=0.1525, repa=0.2308, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:26:09[0m] (step=0051500) Loss: 0.2726 (diff=0.1581, repa=0.2290, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:26:47[0m] (step=0051600) Loss: 0.2766 (diff=0.1623, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:27:25[0m] (step=0051700) Loss: 0.2705 (diff=0.1556, repa=0.2298, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:28:03[0m] (step=0051800) Loss: 0.2706 (diff=0.1559, repa=0.2295, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:28:41[0m] (step=0051900) Loss: 0.2731 (diff=0.1587, repa=0.2288, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:29:18[0m] (step=0052000) Loss: 0.2758 (diff=0.1612, repa=0.2294, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:29:56[0m] (step=0052100) Loss: 0.2757 (diff=0.1615, repa=0.2284, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:30:34[0m] (step=0052200) Loss: 0.2687 (diff=0.1539, repa=0.2296, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:31:12[0m] (step=0052300) Loss: 0.2731 (diff=0.1584, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:31:50[0m] (step=0052400) Loss: 0.2708 (diff=0.1561, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:32:28[0m] (step=0052500) Loss: 0.2758 (diff=0.1614, repa=0.2286, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:33:06[0m] (step=0052600) Loss: 0.2736 (diff=0.1593, repa=0.2287, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:33:44[0m] (step=0052700) Loss: 0.2754 (diff=0.1610, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:34:22[0m] (step=0052800) Loss: 0.2741 (diff=0.1597, repa=0.2288, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:35:00[0m] (step=0052900) Loss: 0.2724 (diff=0.1575, repa=0.2297, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:35:38[0m] (step=0053000) Loss: 0.2696 (diff=0.1552, repa=0.2288, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:36:16[0m] (step=0053100) Loss: 0.2721 (diff=0.1581, repa=0.2279, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:36:54[0m] (step=0053200) Loss: 0.2701 (diff=0.1554, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:37:32[0m] (step=0053300) Loss: 0.2767 (diff=0.1626, repa=0.2282, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:38:09[0m] (step=0053400) Loss: 0.2742 (diff=0.1598, repa=0.2287, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:38:47[0m] (step=0053500) Loss: 0.2786 (diff=0.1645, repa=0.2283, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:39:25[0m] (step=0053600) Loss: 0.2708 (diff=0.1567, repa=0.2282, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:40:03[0m] (step=0053700) Loss: 0.2757 (diff=0.1615, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:40:41[0m] (step=0053800) Loss: 0.2690 (diff=0.1546, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:41:19[0m] (step=0053900) Loss: 0.2701 (diff=0.1552, repa=0.2298, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:41:57[0m] (step=0054000) Loss: 0.2785 (diff=0.1645, repa=0.2280, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:42:35[0m] (step=0054100) Loss: 0.2776 (diff=0.1637, repa=0.2280, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:43:13[0m] (step=0054200) Loss: 0.2721 (diff=0.1578, repa=0.2285, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:43:51[0m] (step=0054300) Loss: 0.2744 (diff=0.1599, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:44:29[0m] (step=0054400) Loss: 0.2819 (diff=0.1674, repa=0.2288, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:45:07[0m] (step=0054500) Loss: 0.2756 (diff=0.1612, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:45:45[0m] (step=0054600) Loss: 0.2751 (diff=0.1608, repa=0.2286, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:46:23[0m] (step=0054700) Loss: 0.2742 (diff=0.1598, repa=0.2288, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:47:01[0m] (step=0054800) Loss: 0.2730 (diff=0.1588, repa=0.2285, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:47:39[0m] (step=0054900) Loss: 0.2728 (diff=0.1584, repa=0.2288, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:48:17[0m] (step=0055000) Loss: 0.2774 (diff=0.1632, repa=0.2283, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:48:55[0m] (step=0055100) Loss: 0.2745 (diff=0.1602, repa=0.2285, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:49:33[0m] (step=0055200) Loss: 0.2743 (diff=0.1601, repa=0.2283, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:50:11[0m] (step=0055300) Loss: 0.2817 (diff=0.1676, repa=0.2280, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:50:49[0m] (step=0055400) Loss: 0.2708 (diff=0.1564, repa=0.2288, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:51:27[0m] (step=0055500) Loss: 0.2725 (diff=0.1583, repa=0.2283, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:52:05[0m] (step=0055600) Loss: 0.2788 (diff=0.1649, repa=0.2278, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:52:43[0m] (step=0055700) Loss: 0.2740 (diff=0.1597, repa=0.2287, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:53:21[0m] (step=0055800) Loss: 0.2642 (diff=0.1494, repa=0.2296, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:53:59[0m] (step=0055900) Loss: 0.2736 (diff=0.1595, repa=0.2282, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:54:37[0m] (step=0056000) Loss: 0.2780 (diff=0.1637, repa=0.2285, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:55:14[0m] (step=0056100) Loss: 0.2686 (diff=0.1541, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:55:52[0m] (step=0056200) Loss: 0.2745 (diff=0.1602, repa=0.2287, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:56:30[0m] (step=0056300) Loss: 0.2743 (diff=0.1602, repa=0.2283, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:57:09[0m] (step=0056400) Loss: 0.2681 (diff=0.1540, repa=0.2283, λ=0.5) Steps/Sec: 2.61
[[34m2026-02-09 17:57:47[0m] (step=0056500) Loss: 0.2720 (diff=0.1578, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:58:25[0m] (step=0056600) Loss: 0.2695 (diff=0.1549, repa=0.2291, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 17:59:03[0m] (step=0056700) Loss: 0.2695 (diff=0.1551, repa=0.2290, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 17:59:40[0m] (step=0056800) Loss: 0.2746 (diff=0.1603, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:00:18[0m] (step=0056900) Loss: 0.2788 (diff=0.1650, repa=0.2277, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:00:56[0m] (step=0057000) Loss: 0.2704 (diff=0.1561, repa=0.2286, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:01:34[0m] (step=0057100) Loss: 0.2705 (diff=0.1562, repa=0.2286, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:02:12[0m] (step=0057200) Loss: 0.2731 (diff=0.1587, repa=0.2287, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:02:50[0m] (step=0057300) Loss: 0.2713 (diff=0.1570, repa=0.2286, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:03:28[0m] (step=0057400) Loss: 0.2722 (diff=0.1578, repa=0.2287, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:04:06[0m] (step=0057500) Loss: 0.2768 (diff=0.1626, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:04:44[0m] (step=0057600) Loss: 0.2711 (diff=0.1569, repa=0.2285, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:05:22[0m] (step=0057700) Loss: 0.2691 (diff=0.1545, repa=0.2292, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:06:00[0m] (step=0057800) Loss: 0.2698 (diff=0.1554, repa=0.2287, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:06:38[0m] (step=0057900) Loss: 0.2682 (diff=0.1536, repa=0.2292, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:07:16[0m] (step=0058000) Loss: 0.2729 (diff=0.1589, repa=0.2279, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:07:54[0m] (step=0058100) Loss: 0.2700 (diff=0.1557, repa=0.2287, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:08:32[0m] (step=0058200) Loss: 0.2680 (diff=0.1536, repa=0.2289, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:09:10[0m] (step=0058300) Loss: 0.2706 (diff=0.1564, repa=0.2283, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:09:48[0m] (step=0058400) Loss: 0.2734 (diff=0.1594, repa=0.2279, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:10:26[0m] (step=0058500) Loss: 0.2717 (diff=0.1575, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:11:04[0m] (step=0058600) Loss: 0.2726 (diff=0.1584, repa=0.2284, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:11:42[0m] (step=0058700) Loss: 0.2663 (diff=0.1517, repa=0.2292, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:12:20[0m] (step=0058800) Loss: 0.2772 (diff=0.1630, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:12:58[0m] (step=0058900) Loss: 0.2710 (diff=0.1568, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:13:36[0m] (step=0059000) Loss: 0.2732 (diff=0.1593, repa=0.2279, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:14:14[0m] (step=0059100) Loss: 0.2748 (diff=0.1609, repa=0.2278, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:14:51[0m] (step=0059200) Loss: 0.2721 (diff=0.1578, repa=0.2286, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:15:29[0m] (step=0059300) Loss: 0.2731 (diff=0.1589, repa=0.2282, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:16:07[0m] (step=0059400) Loss: 0.2729 (diff=0.1589, repa=0.2281, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:16:45[0m] (step=0059500) Loss: 0.2748 (diff=0.1612, repa=0.2273, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:17:23[0m] (step=0059600) Loss: 0.2733 (diff=0.1589, repa=0.2289, λ=0.5) Steps/Sec: 2.62
[[34m2026-02-09 18:18:01[0m] (step=0059700) Loss: 0.2737 (diff=0.1596, repa=0.2282, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:18:39[0m] (step=0059800) Loss: 0.2732 (diff=0.1591, repa=0.2282, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:19:17[0m] (step=0059900) Loss: 0.2673 (diff=0.1530, repa=0.2286, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:19:55[0m] (step=0060000) Loss: 0.2744 (diff=0.1605, repa=0.2278, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:19:56[0m] Saved checkpoint to /data4/haksoo/trm_repa/004-DiT-XL-2/checkpoints/0060000.pt
/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  return func(*args, **kwargs)
[[34m2026-02-09 18:20:16[0m] Beginning epoch 3...
[[34m2026-02-09 18:20:34[0m] (step=0060100) Loss: 0.2737 (diff=0.1598, repa=0.2278, λ=0.5) Steps/Sec: 2.56
[[34m2026-02-09 18:21:12[0m] (step=0060200) Loss: 0.2734 (diff=0.1593, repa=0.2282, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:21:50[0m] (step=0060300) Loss: 0.2732 (diff=0.1592, repa=0.2282, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:22:28[0m] (step=0060400) Loss: 0.2710 (diff=0.1569, repa=0.2282, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:23:06[0m] (step=0060500) Loss: 0.2744 (diff=0.1606, repa=0.2277, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:23:44[0m] (step=0060600) Loss: 0.2681 (diff=0.1536, repa=0.2289, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:24:22[0m] (step=0060700) Loss: 0.2719 (diff=0.1578, repa=0.2282, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:25:00[0m] (step=0060800) Loss: 0.2724 (diff=0.1582, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:25:38[0m] (step=0060900) Loss: 0.2719 (diff=0.1577, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:26:16[0m] (step=0061000) Loss: 0.2712 (diff=0.1574, repa=0.2276, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:26:54[0m] (step=0061100) Loss: 0.2717 (diff=0.1577, repa=0.2282, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:27:32[0m] (step=0061200) Loss: 0.2700 (diff=0.1555, repa=0.2290, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:28:09[0m] (step=0061300) Loss: 0.2690 (diff=0.1544, repa=0.2292, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:28:47[0m] (step=0061400) Loss: 0.2688 (diff=0.1545, repa=0.2286, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:29:25[0m] (step=0061500) Loss: 0.2726 (diff=0.1583, repa=0.2287, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:30:03[0m] (step=0061600) Loss: 0.2643 (diff=0.1496, repa=0.2294, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:30:41[0m] (step=0061700) Loss: 0.2664 (diff=0.1521, repa=0.2287, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:31:19[0m] (step=0061800) Loss: 0.2732 (diff=0.1589, repa=0.2287, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:31:57[0m] (step=0061900) Loss: 0.2687 (diff=0.1546, repa=0.2283, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:32:35[0m] (step=0062000) Loss: 0.2733 (diff=0.1591, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:33:13[0m] (step=0062100) Loss: 0.2760 (diff=0.1620, repa=0.2280, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:33:51[0m] (step=0062200) Loss: 0.2725 (diff=0.1584, repa=0.2281, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:34:29[0m] (step=0062300) Loss: 0.2706 (diff=0.1565, repa=0.2282, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:35:06[0m] (step=0062400) Loss: 0.2690 (diff=0.1546, repa=0.2288, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:35:44[0m] (step=0062500) Loss: 0.2734 (diff=0.1592, repa=0.2283, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:36:22[0m] (step=0062600) Loss: 0.2688 (diff=0.1546, repa=0.2284, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:37:00[0m] (step=0062700) Loss: 0.2700 (diff=0.1555, repa=0.2290, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:37:38[0m] (step=0062800) Loss: 0.2744 (diff=0.1606, repa=0.2276, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:38:16[0m] (step=0062900) Loss: 0.2715 (diff=0.1573, repa=0.2283, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:38:54[0m] (step=0063000) Loss: 0.2741 (diff=0.1601, repa=0.2280, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:39:32[0m] (step=0063100) Loss: 0.2698 (diff=0.1559, repa=0.2279, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:40:10[0m] (step=0063200) Loss: 0.2708 (diff=0.1566, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:40:48[0m] (step=0063300) Loss: 0.2728 (diff=0.1593, repa=0.2270, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:41:26[0m] (step=0063400) Loss: 0.2704 (diff=0.1565, repa=0.2278, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:42:04[0m] (step=0063500) Loss: 0.2686 (diff=0.1545, repa=0.2281, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:42:42[0m] (step=0063600) Loss: 0.2811 (diff=0.1676, repa=0.2272, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:43:20[0m] (step=0063700) Loss: 0.2721 (diff=0.1579, repa=0.2285, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:43:58[0m] (step=0063800) Loss: 0.2735 (diff=0.1598, repa=0.2275, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:44:36[0m] (step=0063900) Loss: 0.2742 (diff=0.1607, repa=0.2270, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:45:14[0m] (step=0064000) Loss: 0.2696 (diff=0.1553, repa=0.2287, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:45:52[0m] (step=0064100) Loss: 0.2713 (diff=0.1575, repa=0.2275, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:46:30[0m] (step=0064200) Loss: 0.2712 (diff=0.1569, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:47:08[0m] (step=0064300) Loss: 0.2721 (diff=0.1585, repa=0.2272, λ=0.5) Steps/Sec: 2.62
[[34m2026-02-09 18:47:46[0m] (step=0064400) Loss: 0.2700 (diff=0.1558, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:48:24[0m] (step=0064500) Loss: 0.2681 (diff=0.1538, repa=0.2286, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:49:02[0m] (step=0064600) Loss: 0.2703 (diff=0.1565, repa=0.2276, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:49:40[0m] (step=0064700) Loss: 0.2675 (diff=0.1533, repa=0.2283, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:50:18[0m] (step=0064800) Loss: 0.2714 (diff=0.1576, repa=0.2276, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:50:56[0m] (step=0064900) Loss: 0.2643 (diff=0.1501, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:51:34[0m] (step=0065000) Loss: 0.2710 (diff=0.1569, repa=0.2282, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:52:12[0m] (step=0065100) Loss: 0.2716 (diff=0.1576, repa=0.2280, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:52:50[0m] (step=0065200) Loss: 0.2731 (diff=0.1591, repa=0.2280, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:53:28[0m] (step=0065300) Loss: 0.2715 (diff=0.1578, repa=0.2273, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 18:54:06[0m] (step=0065400) Loss: 0.2693 (diff=0.1554, repa=0.2279, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:54:43[0m] (step=0065500) Loss: 0.2683 (diff=0.1541, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:55:21[0m] (step=0065600) Loss: 0.2680 (diff=0.1540, repa=0.2282, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:55:59[0m] (step=0065700) Loss: 0.2688 (diff=0.1544, repa=0.2289, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:56:37[0m] (step=0065800) Loss: 0.2731 (diff=0.1591, repa=0.2279, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:57:15[0m] (step=0065900) Loss: 0.2754 (diff=0.1617, repa=0.2273, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:57:53[0m] (step=0066000) Loss: 0.2739 (diff=0.1598, repa=0.2283, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:58:31[0m] (step=0066100) Loss: 0.2741 (diff=0.1602, repa=0.2280, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:59:09[0m] (step=0066200) Loss: 0.2707 (diff=0.1565, repa=0.2283, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 18:59:46[0m] (step=0066300) Loss: 0.2690 (diff=0.1550, repa=0.2281, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:00:24[0m] (step=0066400) Loss: 0.2675 (diff=0.1536, repa=0.2278, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:01:02[0m] (step=0066500) Loss: 0.2719 (diff=0.1576, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:01:40[0m] (step=0066600) Loss: 0.2661 (diff=0.1518, repa=0.2287, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:02:18[0m] (step=0066700) Loss: 0.2736 (diff=0.1596, repa=0.2280, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:02:56[0m] (step=0066800) Loss: 0.2691 (diff=0.1549, repa=0.2283, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:03:34[0m] (step=0066900) Loss: 0.2728 (diff=0.1588, repa=0.2281, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:04:12[0m] (step=0067000) Loss: 0.2707 (diff=0.1568, repa=0.2279, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 19:04:50[0m] (step=0067100) Loss: 0.2668 (diff=0.1528, repa=0.2280, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:05:27[0m] (step=0067200) Loss: 0.2701 (diff=0.1559, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:06:05[0m] (step=0067300) Loss: 0.2702 (diff=0.1560, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 19:06:43[0m] (step=0067400) Loss: 0.2740 (diff=0.1604, repa=0.2273, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:07:21[0m] (step=0067500) Loss: 0.2721 (diff=0.1583, repa=0.2276, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 19:07:59[0m] (step=0067600) Loss: 0.2692 (diff=0.1551, repa=0.2281, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:08:37[0m] (step=0067700) Loss: 0.2728 (diff=0.1588, repa=0.2279, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 19:09:15[0m] (step=0067800) Loss: 0.2717 (diff=0.1579, repa=0.2277, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:09:53[0m] (step=0067900) Loss: 0.2754 (diff=0.1621, repa=0.2267, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 19:10:31[0m] (step=0068000) Loss: 0.2725 (diff=0.1583, repa=0.2284, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:11:09[0m] (step=0068100) Loss: 0.2704 (diff=0.1563, repa=0.2282, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:11:47[0m] (step=0068200) Loss: 0.2703 (diff=0.1561, repa=0.2285, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:12:25[0m] (step=0068300) Loss: 0.2743 (diff=0.1603, repa=0.2280, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 19:13:02[0m] (step=0068400) Loss: 0.2731 (diff=0.1592, repa=0.2277, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:13:40[0m] (step=0068500) Loss: 0.2727 (diff=0.1586, repa=0.2284, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 19:14:18[0m] (step=0068600) Loss: 0.2709 (diff=0.1569, repa=0.2279, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:14:56[0m] (step=0068700) Loss: 0.2679 (diff=0.1538, repa=0.2282, λ=0.5) Steps/Sec: 2.63
[[34m2026-02-09 19:15:34[0m] (step=0068800) Loss: 0.2732 (diff=0.1596, repa=0.2274, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:16:12[0m] (step=0068900) Loss: 0.2685 (diff=0.1541, repa=0.2287, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-09 19:16:50[0m] (step=0069000) Loss: 0.2670 (diff=0.1528, repa=0.2286, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-09 19:17:27[0m] (step=0069100) Loss: 0.2711 (diff=0.1572, repa=0.2278, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:18:05[0m] (step=0069200) Loss: 0.2690 (diff=0.1545, repa=0.2291, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:18:42[0m] (step=0069300) Loss: 0.2735 (diff=0.1597, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:19:20[0m] (step=0069400) Loss: 0.2791 (diff=0.1655, repa=0.2272, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:19:57[0m] (step=0069500) Loss: 0.2728 (diff=0.1589, repa=0.2277, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:20:34[0m] (step=0069600) Loss: 0.2704 (diff=0.1564, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:21:12[0m] (step=0069700) Loss: 0.2706 (diff=0.1569, repa=0.2273, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:21:49[0m] (step=0069800) Loss: 0.2713 (diff=0.1569, repa=0.2288, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:22:27[0m] (step=0069900) Loss: 0.2716 (diff=0.1577, repa=0.2278, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:23:04[0m] (step=0070000) Loss: 0.2700 (diff=0.1557, repa=0.2285, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:23:42[0m] (step=0070100) Loss: 0.2742 (diff=0.1609, repa=0.2266, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:24:19[0m] (step=0070200) Loss: 0.2727 (diff=0.1587, repa=0.2279, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:24:56[0m] (step=0070300) Loss: 0.2713 (diff=0.1573, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:25:34[0m] (step=0070400) Loss: 0.2699 (diff=0.1559, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:26:11[0m] (step=0070500) Loss: 0.2720 (diff=0.1580, repa=0.2279, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:26:49[0m] (step=0070600) Loss: 0.2736 (diff=0.1595, repa=0.2283, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:27:26[0m] (step=0070700) Loss: 0.2713 (diff=0.1573, repa=0.2281, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:28:04[0m] (step=0070800) Loss: 0.2621 (diff=0.1472, repa=0.2298, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:28:41[0m] (step=0070900) Loss: 0.2736 (diff=0.1599, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:29:18[0m] (step=0071000) Loss: 0.2741 (diff=0.1601, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:29:56[0m] (step=0071100) Loss: 0.2677 (diff=0.1535, repa=0.2285, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:30:33[0m] (step=0071200) Loss: 0.2740 (diff=0.1602, repa=0.2277, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:31:11[0m] (step=0071300) Loss: 0.2704 (diff=0.1566, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:31:48[0m] (step=0071400) Loss: 0.2741 (diff=0.1603, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:32:26[0m] (step=0071500) Loss: 0.2708 (diff=0.1568, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:33:03[0m] (step=0071600) Loss: 0.2695 (diff=0.1559, repa=0.2271, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:33:41[0m] (step=0071700) Loss: 0.2701 (diff=0.1562, repa=0.2278, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:34:18[0m] (step=0071800) Loss: 0.2733 (diff=0.1593, repa=0.2279, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:34:55[0m] (step=0071900) Loss: 0.2741 (diff=0.1604, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:35:33[0m] (step=0072000) Loss: 0.2717 (diff=0.1575, repa=0.2284, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:36:10[0m] (step=0072100) Loss: 0.2729 (diff=0.1591, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:36:48[0m] (step=0072200) Loss: 0.2688 (diff=0.1553, repa=0.2272, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:37:25[0m] (step=0072300) Loss: 0.2768 (diff=0.1630, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:38:03[0m] (step=0072400) Loss: 0.2741 (diff=0.1603, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:38:40[0m] (step=0072500) Loss: 0.2721 (diff=0.1580, repa=0.2282, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:39:18[0m] (step=0072600) Loss: 0.2749 (diff=0.1609, repa=0.2279, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:39:55[0m] (step=0072700) Loss: 0.2713 (diff=0.1576, repa=0.2273, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:40:33[0m] (step=0072800) Loss: 0.2747 (diff=0.1609, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:41:10[0m] (step=0072900) Loss: 0.2738 (diff=0.1599, repa=0.2279, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:41:47[0m] (step=0073000) Loss: 0.2692 (diff=0.1553, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:42:25[0m] (step=0073100) Loss: 0.2697 (diff=0.1556, repa=0.2283, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 19:43:02[0m] (step=0073200) Loss: 0.2679 (diff=0.1538, repa=0.2282, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:43:40[0m] (step=0073300) Loss: 0.2705 (diff=0.1568, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:44:17[0m] (step=0073400) Loss: 0.2750 (diff=0.1615, repa=0.2269, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:44:54[0m] (step=0073500) Loss: 0.2659 (diff=0.1515, repa=0.2288, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:45:32[0m] (step=0073600) Loss: 0.2699 (diff=0.1562, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:46:09[0m] (step=0073700) Loss: 0.2722 (diff=0.1582, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:46:47[0m] (step=0073800) Loss: 0.2722 (diff=0.1585, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:47:24[0m] (step=0073900) Loss: 0.2716 (diff=0.1577, repa=0.2277, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:48:02[0m] (step=0074000) Loss: 0.2747 (diff=0.1607, repa=0.2279, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:48:39[0m] (step=0074100) Loss: 0.2702 (diff=0.1564, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:49:17[0m] (step=0074200) Loss: 0.2695 (diff=0.1555, repa=0.2282, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:49:54[0m] (step=0074300) Loss: 0.2661 (diff=0.1519, repa=0.2283, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:50:31[0m] (step=0074400) Loss: 0.2702 (diff=0.1564, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:51:09[0m] (step=0074500) Loss: 0.2706 (diff=0.1566, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:51:46[0m] (step=0074600) Loss: 0.2753 (diff=0.1618, repa=0.2271, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:52:24[0m] (step=0074700) Loss: 0.2729 (diff=0.1595, repa=0.2268, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:53:01[0m] (step=0074800) Loss: 0.2748 (diff=0.1609, repa=0.2277, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 19:53:39[0m] (step=0074900) Loss: 0.2712 (diff=0.1571, repa=0.2283, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 19:54:16[0m] (step=0075000) Loss: 0.2700 (diff=0.1563, repa=0.2274, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 19:54:53[0m] (step=0075100) Loss: 0.2743 (diff=0.1606, repa=0.2274, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 19:55:31[0m] (step=0075200) Loss: 0.2737 (diff=0.1600, repa=0.2273, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:56:08[0m] (step=0075300) Loss: 0.2698 (diff=0.1559, repa=0.2279, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:56:46[0m] (step=0075400) Loss: 0.2732 (diff=0.1597, repa=0.2271, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:57:23[0m] (step=0075500) Loss: 0.2759 (diff=0.1624, repa=0.2270, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:58:00[0m] (step=0075600) Loss: 0.2698 (diff=0.1557, repa=0.2281, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:58:38[0m] (step=0075700) Loss: 0.2714 (diff=0.1578, repa=0.2273, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:59:15[0m] (step=0075800) Loss: 0.2730 (diff=0.1592, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 19:59:53[0m] (step=0075900) Loss: 0.2715 (diff=0.1575, repa=0.2281, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:00:30[0m] (step=0076000) Loss: 0.2695 (diff=0.1557, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:01:08[0m] (step=0076100) Loss: 0.2700 (diff=0.1562, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:01:45[0m] (step=0076200) Loss: 0.2709 (diff=0.1570, repa=0.2278, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:02:22[0m] (step=0076300) Loss: 0.2717 (diff=0.1577, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:03:00[0m] (step=0076400) Loss: 0.2666 (diff=0.1526, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:03:37[0m] (step=0076500) Loss: 0.2733 (diff=0.1595, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:04:15[0m] (step=0076600) Loss: 0.2785 (diff=0.1650, repa=0.2269, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:04:52[0m] (step=0076700) Loss: 0.2703 (diff=0.1569, repa=0.2268, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:05:29[0m] (step=0076800) Loss: 0.2752 (diff=0.1617, repa=0.2270, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:06:07[0m] (step=0076900) Loss: 0.2763 (diff=0.1630, repa=0.2265, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:06:44[0m] (step=0077000) Loss: 0.2675 (diff=0.1537, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:07:22[0m] (step=0077100) Loss: 0.2631 (diff=0.1489, repa=0.2284, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:07:59[0m] (step=0077200) Loss: 0.2703 (diff=0.1569, repa=0.2269, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:08:37[0m] (step=0077300) Loss: 0.2733 (diff=0.1602, repa=0.2263, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:09:14[0m] (step=0077400) Loss: 0.2700 (diff=0.1567, repa=0.2266, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:09:51[0m] (step=0077500) Loss: 0.2668 (diff=0.1527, repa=0.2282, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:10:29[0m] (step=0077600) Loss: 0.2718 (diff=0.1582, repa=0.2271, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:11:06[0m] (step=0077700) Loss: 0.2760 (diff=0.1624, repa=0.2271, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:11:44[0m] (step=0077800) Loss: 0.2798 (diff=0.1665, repa=0.2265, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:12:21[0m] (step=0077900) Loss: 0.2694 (diff=0.1552, repa=0.2284, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:12:58[0m] (step=0078000) Loss: 0.2718 (diff=0.1580, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:13:36[0m] (step=0078100) Loss: 0.2689 (diff=0.1551, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:14:13[0m] (step=0078200) Loss: 0.2692 (diff=0.1550, repa=0.2284, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:14:51[0m] (step=0078300) Loss: 0.2711 (diff=0.1574, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:15:28[0m] (step=0078400) Loss: 0.2695 (diff=0.1557, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:16:06[0m] (step=0078500) Loss: 0.2707 (diff=0.1569, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:16:43[0m] (step=0078600) Loss: 0.2671 (diff=0.1532, repa=0.2278, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:17:21[0m] (step=0078700) Loss: 0.2748 (diff=0.1615, repa=0.2266, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:17:58[0m] (step=0078800) Loss: 0.2699 (diff=0.1563, repa=0.2272, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:18:35[0m] (step=0078900) Loss: 0.2706 (diff=0.1571, repa=0.2270, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:19:13[0m] (step=0079000) Loss: 0.2740 (diff=0.1604, repa=0.2271, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:19:50[0m] (step=0079100) Loss: 0.2743 (diff=0.1606, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:20:28[0m] (step=0079200) Loss: 0.2747 (diff=0.1609, repa=0.2277, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:21:05[0m] (step=0079300) Loss: 0.2676 (diff=0.1535, repa=0.2281, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:21:43[0m] (step=0079400) Loss: 0.2700 (diff=0.1562, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:22:20[0m] (step=0079500) Loss: 0.2685 (diff=0.1547, repa=0.2277, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:22:57[0m] (step=0079600) Loss: 0.2700 (diff=0.1563, repa=0.2272, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:23:35[0m] (step=0079700) Loss: 0.2717 (diff=0.1581, repa=0.2273, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:24:12[0m] (step=0079800) Loss: 0.2740 (diff=0.1605, repa=0.2269, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:24:50[0m] (step=0079900) Loss: 0.2754 (diff=0.1618, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:25:27[0m] (step=0080000) Loss: 0.2716 (diff=0.1579, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:25:28[0m] Saved checkpoint to /data4/haksoo/trm_repa/004-DiT-XL-2/checkpoints/0080000.pt
[[34m2026-02-09 20:25:55[0m] Beginning epoch 4...
[[34m2026-02-09 20:26:06[0m] (step=0080100) Loss: 0.2684 (diff=0.1546, repa=0.2276, λ=0.5) Steps/Sec: 2.59
[[34m2026-02-09 20:26:43[0m] (step=0080200) Loss: 0.2786 (diff=0.1653, repa=0.2265, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:27:21[0m] (step=0080300) Loss: 0.2750 (diff=0.1615, repa=0.2269, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:27:58[0m] (step=0080400) Loss: 0.2750 (diff=0.1617, repa=0.2266, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:28:36[0m] (step=0080500) Loss: 0.2724 (diff=0.1586, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:29:13[0m] (step=0080600) Loss: 0.2749 (diff=0.1618, repa=0.2262, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:29:50[0m] (step=0080700) Loss: 0.2716 (diff=0.1579, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:30:28[0m] (step=0080800) Loss: 0.2718 (diff=0.1584, repa=0.2270, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:31:05[0m] (step=0080900) Loss: 0.2718 (diff=0.1585, repa=0.2265, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:31:43[0m] (step=0081000) Loss: 0.2709 (diff=0.1571, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:32:20[0m] (step=0081100) Loss: 0.2697 (diff=0.1561, repa=0.2272, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:32:58[0m] (step=0081200) Loss: 0.2779 (diff=0.1650, repa=0.2258, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:33:35[0m] (step=0081300) Loss: 0.2729 (diff=0.1594, repa=0.2269, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:34:12[0m] (step=0081400) Loss: 0.2727 (diff=0.1588, repa=0.2277, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:34:50[0m] (step=0081500) Loss: 0.2742 (diff=0.1604, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:35:27[0m] (step=0081600) Loss: 0.2652 (diff=0.1510, repa=0.2284, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:36:05[0m] (step=0081700) Loss: 0.2693 (diff=0.1553, repa=0.2280, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:36:42[0m] (step=0081800) Loss: 0.2728 (diff=0.1593, repa=0.2269, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:37:20[0m] (step=0081900) Loss: 0.2687 (diff=0.1549, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:37:57[0m] (step=0082000) Loss: 0.2727 (diff=0.1589, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:38:34[0m] (step=0082100) Loss: 0.2654 (diff=0.1515, repa=0.2279, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:39:12[0m] (step=0082200) Loss: 0.2642 (diff=0.1503, repa=0.2278, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:39:49[0m] (step=0082300) Loss: 0.2737 (diff=0.1601, repa=0.2271, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:40:27[0m] (step=0082400) Loss: 0.2729 (diff=0.1593, repa=0.2272, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:41:04[0m] (step=0082500) Loss: 0.2708 (diff=0.1571, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:41:42[0m] (step=0082600) Loss: 0.2718 (diff=0.1580, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:42:19[0m] (step=0082700) Loss: 0.2720 (diff=0.1584, repa=0.2272, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:42:57[0m] (step=0082800) Loss: 0.2739 (diff=0.1602, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:43:34[0m] (step=0082900) Loss: 0.2728 (diff=0.1593, repa=0.2270, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:44:12[0m] (step=0083000) Loss: 0.2691 (diff=0.1558, repa=0.2266, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 20:44:50[0m] (step=0083100) Loss: 0.2663 (diff=0.1523, repa=0.2280, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-09 20:45:27[0m] (step=0083200) Loss: 0.2721 (diff=0.1584, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:46:04[0m] (step=0083300) Loss: 0.2688 (diff=0.1550, repa=0.2276, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:46:42[0m] (step=0083400) Loss: 0.2739 (diff=0.1604, repa=0.2270, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:47:19[0m] (step=0083500) Loss: 0.2661 (diff=0.1523, repa=0.2277, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:47:57[0m] (step=0083600) Loss: 0.2711 (diff=0.1575, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:48:34[0m] (step=0083700) Loss: 0.2700 (diff=0.1563, repa=0.2275, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:49:12[0m] (step=0083800) Loss: 0.2722 (diff=0.1585, repa=0.2274, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-09 20:49:49[0m] (step=0083900) Loss: 0.2727 (diff=0.1592, repa=0.2270, λ=0.5) Steps/Sec: 2.67
W0209 20:50:25.804000 613972 site-packages/torch/distributed/elastic/agent/server/api.py:739] Received 1 death signal, shutting down workers
W0209 20:50:25.808000 613972 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 614044 closing signal SIGHUP
W0209 20:50:25.809000 613972 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 614045 closing signal SIGHUP
W0209 20:50:25.814000 613972 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 614046 closing signal SIGHUP
W0209 20:50:25.818000 613972 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 614047 closing signal SIGHUP
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 995, in <module>
    main()
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 991, in main
    run(args)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 982, in run
    elastic_launch(
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 170, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 308, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 134, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 731, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 908, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 86, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 613972 got signal: 1

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Starting rank=0, seed=0, world_size=4.
[[34m2026-02-09 21:21:27[0m] Experiment directory created at /data4/haksoo/trm_repa/003-DiT-XL-2
Starting rank=3, seed=3, world_size=4.
Starting rank=1, seed=1, world_size=4.
Starting rank=2, seed=2, world_size=4.
[[34m2026-02-09 21:21:27[0m] Loading REPA teacher via torch.hub: facebookresearch/dinov2::dinov2_vitb14
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
[[34m2026-02-09 21:21:27[0m] using MLP layer as FFN
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
[[34m2026-02-09 21:21:29[0m] Attached REPA projector: student_dim=1152 -> teacher_dim=768
[[34m2026-02-09 21:21:29[0m] Resumed from /data4/haksoo/trm_repa/002-DiT-XL-2/checkpoints/0080000.pt at step=80000
[[34m2026-02-09 21:21:29[0m] Registered REPA forward hooks on student blocks.
[[34m2026-02-09 21:21:30[0m] DiT Parameters: 30,578,338
[[34m2026-02-09 21:21:32[0m] Dataset contains 1,281,167 images (/data/ImageNet1k/train)
[[34m2026-02-09 21:21:32[0m] Training for 1400 epochs...
[[34m2026-02-09 21:21:32[0m] Beginning epoch 3...
[[34m2026-02-09 21:29:58[0m] Beginning epoch 4...
[[34m2026-02-09 21:30:09[0m] (step=0080100) Loss: 0.2723 (diff=0.1587, repa=0.2272, λ=0.5) Steps/Sec: 0.19
[[34m2026-02-09 21:30:46[0m] (step=0080200) Loss: 0.2692 (diff=0.1553, repa=0.2278, λ=0.5) Steps/Sec: 2.71
[[34m2026-02-09 21:31:23[0m] (step=0080300) Loss: 0.2739 (diff=0.1605, repa=0.2267, λ=0.5) Steps/Sec: 2.70
[[34m2026-02-09 21:32:00[0m] (step=0080400) Loss: 0.2700 (diff=0.1566, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:32:37[0m] (step=0080500) Loss: 0.2682 (diff=0.1541, repa=0.2281, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:33:14[0m] (step=0080600) Loss: 0.2714 (diff=0.1581, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:33:51[0m] (step=0080700) Loss: 0.2726 (diff=0.1591, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:34:29[0m] (step=0080800) Loss: 0.2684 (diff=0.1547, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:35:06[0m] (step=0080900) Loss: 0.2658 (diff=0.1519, repa=0.2279, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:35:43[0m] (step=0081000) Loss: 0.2729 (diff=0.1595, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:36:20[0m] (step=0081100) Loss: 0.2682 (diff=0.1545, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:36:57[0m] (step=0081200) Loss: 0.2675 (diff=0.1539, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:37:34[0m] (step=0081300) Loss: 0.2729 (diff=0.1594, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:38:12[0m] (step=0081400) Loss: 0.2706 (diff=0.1571, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:38:49[0m] (step=0081500) Loss: 0.2753 (diff=0.1615, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:39:26[0m] (step=0081600) Loss: 0.2714 (diff=0.1577, repa=0.2274, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:40:03[0m] (step=0081700) Loss: 0.2731 (diff=0.1596, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:40:40[0m] (step=0081800) Loss: 0.2751 (diff=0.1616, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:41:18[0m] (step=0081900) Loss: 0.2684 (diff=0.1546, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:41:55[0m] (step=0082000) Loss: 0.2733 (diff=0.1595, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:42:32[0m] (step=0082100) Loss: 0.2725 (diff=0.1590, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:43:09[0m] (step=0082200) Loss: 0.2652 (diff=0.1514, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:43:46[0m] (step=0082300) Loss: 0.2711 (diff=0.1574, repa=0.2274, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:44:24[0m] (step=0082400) Loss: 0.2687 (diff=0.1551, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:45:01[0m] (step=0082500) Loss: 0.2714 (diff=0.1576, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:45:38[0m] (step=0082600) Loss: 0.2710 (diff=0.1571, repa=0.2279, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:46:15[0m] (step=0082700) Loss: 0.2689 (diff=0.1550, repa=0.2278, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:46:52[0m] (step=0082800) Loss: 0.2659 (diff=0.1517, repa=0.2284, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:47:29[0m] (step=0082900) Loss: 0.2717 (diff=0.1580, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:48:07[0m] (step=0083000) Loss: 0.2734 (diff=0.1605, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:48:44[0m] (step=0083100) Loss: 0.2726 (diff=0.1591, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:49:21[0m] (step=0083200) Loss: 0.2712 (diff=0.1573, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:49:58[0m] (step=0083300) Loss: 0.2731 (diff=0.1597, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:50:35[0m] (step=0083400) Loss: 0.2734 (diff=0.1598, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:51:13[0m] (step=0083500) Loss: 0.2680 (diff=0.1542, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:51:50[0m] (step=0083600) Loss: 0.2724 (diff=0.1589, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:52:27[0m] (step=0083700) Loss: 0.2763 (diff=0.1627, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:53:04[0m] (step=0083800) Loss: 0.2646 (diff=0.1509, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:53:41[0m] (step=0083900) Loss: 0.2700 (diff=0.1564, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:54:19[0m] (step=0084000) Loss: 0.2725 (diff=0.1592, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:54:56[0m] (step=0084100) Loss: 0.2698 (diff=0.1561, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:55:33[0m] (step=0084200) Loss: 0.2680 (diff=0.1542, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:56:10[0m] (step=0084300) Loss: 0.2736 (diff=0.1601, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:56:47[0m] (step=0084400) Loss: 0.2731 (diff=0.1597, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:57:24[0m] (step=0084500) Loss: 0.2752 (diff=0.1618, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:58:02[0m] (step=0084600) Loss: 0.2794 (diff=0.1658, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:58:39[0m] (step=0084700) Loss: 0.2765 (diff=0.1633, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:59:16[0m] (step=0084800) Loss: 0.2720 (diff=0.1583, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 21:59:53[0m] (step=0084900) Loss: 0.2658 (diff=0.1518, repa=0.2280, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:00:30[0m] (step=0085000) Loss: 0.2737 (diff=0.1602, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:01:07[0m] (step=0085100) Loss: 0.2755 (diff=0.1624, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:01:45[0m] (step=0085200) Loss: 0.2709 (diff=0.1574, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:02:22[0m] (step=0085300) Loss: 0.2624 (diff=0.1485, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:02:59[0m] (step=0085400) Loss: 0.2683 (diff=0.1545, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:03:36[0m] (step=0085500) Loss: 0.2742 (diff=0.1607, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:04:13[0m] (step=0085600) Loss: 0.2756 (diff=0.1624, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:04:50[0m] (step=0085700) Loss: 0.2739 (diff=0.1607, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:05:28[0m] (step=0085800) Loss: 0.2671 (diff=0.1530, repa=0.2280, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:06:05[0m] (step=0085900) Loss: 0.2677 (diff=0.1539, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:06:42[0m] (step=0086000) Loss: 0.2707 (diff=0.1572, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:07:19[0m] (step=0086100) Loss: 0.2710 (diff=0.1577, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:07:56[0m] (step=0086200) Loss: 0.2699 (diff=0.1566, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:08:34[0m] (step=0086300) Loss: 0.2743 (diff=0.1613, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:09:11[0m] (step=0086400) Loss: 0.2648 (diff=0.1511, repa=0.2274, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:09:48[0m] (step=0086500) Loss: 0.2687 (diff=0.1550, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:10:25[0m] (step=0086600) Loss: 0.2758 (diff=0.1625, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:11:02[0m] (step=0086700) Loss: 0.2727 (diff=0.1595, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:11:39[0m] (step=0086800) Loss: 0.2735 (diff=0.1600, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:12:17[0m] (step=0086900) Loss: 0.2712 (diff=0.1573, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:12:54[0m] (step=0087000) Loss: 0.2733 (diff=0.1599, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:13:31[0m] (step=0087100) Loss: 0.2704 (diff=0.1570, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:14:08[0m] (step=0087200) Loss: 0.2731 (diff=0.1594, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:14:45[0m] (step=0087300) Loss: 0.2681 (diff=0.1544, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:15:23[0m] (step=0087400) Loss: 0.2705 (diff=0.1566, repa=0.2278, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:16:00[0m] (step=0087500) Loss: 0.2710 (diff=0.1573, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:16:37[0m] (step=0087600) Loss: 0.2693 (diff=0.1558, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:17:14[0m] (step=0087700) Loss: 0.2700 (diff=0.1568, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:17:51[0m] (step=0087800) Loss: 0.2645 (diff=0.1507, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:18:28[0m] (step=0087900) Loss: 0.2706 (diff=0.1571, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:19:06[0m] (step=0088000) Loss: 0.2758 (diff=0.1627, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:19:43[0m] (step=0088100) Loss: 0.2698 (diff=0.1566, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:20:20[0m] (step=0088200) Loss: 0.2725 (diff=0.1587, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:20:57[0m] (step=0088300) Loss: 0.2716 (diff=0.1578, repa=0.2278, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:21:34[0m] (step=0088400) Loss: 0.2711 (diff=0.1574, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:22:11[0m] (step=0088500) Loss: 0.2664 (diff=0.1528, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:22:49[0m] (step=0088600) Loss: 0.2686 (diff=0.1548, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:23:26[0m] (step=0088700) Loss: 0.2724 (diff=0.1592, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:24:03[0m] (step=0088800) Loss: 0.2740 (diff=0.1606, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:24:40[0m] (step=0088900) Loss: 0.2697 (diff=0.1563, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:25:17[0m] (step=0089000) Loss: 0.2719 (diff=0.1583, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:25:54[0m] (step=0089100) Loss: 0.2708 (diff=0.1572, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:26:32[0m] (step=0089200) Loss: 0.2739 (diff=0.1608, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:27:09[0m] (step=0089300) Loss: 0.2670 (diff=0.1536, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:27:46[0m] (step=0089400) Loss: 0.2643 (diff=0.1503, repa=0.2279, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:28:23[0m] (step=0089500) Loss: 0.2654 (diff=0.1514, repa=0.2279, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:29:00[0m] (step=0089600) Loss: 0.2675 (diff=0.1536, repa=0.2278, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:29:37[0m] (step=0089700) Loss: 0.2713 (diff=0.1579, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:30:15[0m] (step=0089800) Loss: 0.2689 (diff=0.1556, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:30:52[0m] (step=0089900) Loss: 0.2676 (diff=0.1538, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:31:29[0m] (step=0090000) Loss: 0.2664 (diff=0.1529, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:32:06[0m] (step=0090100) Loss: 0.2745 (diff=0.1615, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:32:43[0m] (step=0090200) Loss: 0.2711 (diff=0.1580, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:33:20[0m] (step=0090300) Loss: 0.2674 (diff=0.1536, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:33:58[0m] (step=0090400) Loss: 0.2708 (diff=0.1576, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:34:35[0m] (step=0090500) Loss: 0.2692 (diff=0.1556, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:35:12[0m] (step=0090600) Loss: 0.2743 (diff=0.1606, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:35:49[0m] (step=0090700) Loss: 0.2672 (diff=0.1536, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:36:26[0m] (step=0090800) Loss: 0.2730 (diff=0.1597, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:37:04[0m] (step=0090900) Loss: 0.2742 (diff=0.1609, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:37:41[0m] (step=0091000) Loss: 0.2719 (diff=0.1582, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:38:18[0m] (step=0091100) Loss: 0.2680 (diff=0.1541, repa=0.2278, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:38:55[0m] (step=0091200) Loss: 0.2661 (diff=0.1524, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:39:32[0m] (step=0091300) Loss: 0.2688 (diff=0.1555, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:40:09[0m] (step=0091400) Loss: 0.2648 (diff=0.1504, repa=0.2286, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:40:47[0m] (step=0091500) Loss: 0.2700 (diff=0.1562, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:41:24[0m] (step=0091600) Loss: 0.2736 (diff=0.1602, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:42:01[0m] (step=0091700) Loss: 0.2667 (diff=0.1529, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:42:38[0m] (step=0091800) Loss: 0.2669 (diff=0.1533, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:43:15[0m] (step=0091900) Loss: 0.2707 (diff=0.1569, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:43:53[0m] (step=0092000) Loss: 0.2727 (diff=0.1593, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:44:30[0m] (step=0092100) Loss: 0.2717 (diff=0.1585, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:45:07[0m] (step=0092200) Loss: 0.2663 (diff=0.1522, repa=0.2283, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:45:44[0m] (step=0092300) Loss: 0.2694 (diff=0.1561, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:46:21[0m] (step=0092400) Loss: 0.2672 (diff=0.1536, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:46:58[0m] (step=0092500) Loss: 0.2721 (diff=0.1588, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:47:36[0m] (step=0092600) Loss: 0.2699 (diff=0.1564, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:48:13[0m] (step=0092700) Loss: 0.2732 (diff=0.1594, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:48:50[0m] (step=0092800) Loss: 0.2712 (diff=0.1577, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:49:27[0m] (step=0092900) Loss: 0.2687 (diff=0.1551, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:50:04[0m] (step=0093000) Loss: 0.2671 (diff=0.1535, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:50:42[0m] (step=0093100) Loss: 0.2712 (diff=0.1574, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:51:19[0m] (step=0093200) Loss: 0.2677 (diff=0.1536, repa=0.2281, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:51:56[0m] (step=0093300) Loss: 0.2743 (diff=0.1610, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:52:33[0m] (step=0093400) Loss: 0.2718 (diff=0.1580, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:53:10[0m] (step=0093500) Loss: 0.2750 (diff=0.1619, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:53:47[0m] (step=0093600) Loss: 0.2685 (diff=0.1550, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:54:25[0m] (step=0093700) Loss: 0.2724 (diff=0.1593, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:55:02[0m] (step=0093800) Loss: 0.2658 (diff=0.1520, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:55:39[0m] (step=0093900) Loss: 0.2671 (diff=0.1534, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:56:16[0m] (step=0094000) Loss: 0.2759 (diff=0.1627, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:56:53[0m] (step=0094100) Loss: 0.2748 (diff=0.1620, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:57:30[0m] (step=0094200) Loss: 0.2699 (diff=0.1564, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:58:08[0m] (step=0094300) Loss: 0.2722 (diff=0.1585, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:58:45[0m] (step=0094400) Loss: 0.2781 (diff=0.1648, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:59:22[0m] (step=0094500) Loss: 0.2723 (diff=0.1589, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 22:59:59[0m] (step=0094600) Loss: 0.2713 (diff=0.1579, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:00:36[0m] (step=0094700) Loss: 0.2717 (diff=0.1585, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:01:13[0m] (step=0094800) Loss: 0.2695 (diff=0.1561, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:01:51[0m] (step=0094900) Loss: 0.2699 (diff=0.1565, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:02:28[0m] (step=0095000) Loss: 0.2743 (diff=0.1613, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:03:05[0m] (step=0095100) Loss: 0.2698 (diff=0.1570, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:03:42[0m] (step=0095200) Loss: 0.2723 (diff=0.1589, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:04:19[0m] (step=0095300) Loss: 0.2775 (diff=0.1647, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:04:56[0m] (step=0095400) Loss: 0.2690 (diff=0.1555, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:05:34[0m] (step=0095500) Loss: 0.2697 (diff=0.1561, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:06:11[0m] (step=0095600) Loss: 0.2746 (diff=0.1618, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:06:48[0m] (step=0095700) Loss: 0.2700 (diff=0.1566, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:07:25[0m] (step=0095800) Loss: 0.2607 (diff=0.1468, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:08:02[0m] (step=0095900) Loss: 0.2716 (diff=0.1580, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:08:39[0m] (step=0096000) Loss: 0.2748 (diff=0.1617, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:09:17[0m] (step=0096100) Loss: 0.2656 (diff=0.1520, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:09:54[0m] (step=0096200) Loss: 0.2705 (diff=0.1573, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:10:31[0m] (step=0096300) Loss: 0.2714 (diff=0.1583, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:11:08[0m] (step=0096400) Loss: 0.2658 (diff=0.1523, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:11:45[0m] (step=0096500) Loss: 0.2698 (diff=0.1565, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:12:23[0m] (step=0096600) Loss: 0.2663 (diff=0.1527, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:13:00[0m] (step=0096700) Loss: 0.2660 (diff=0.1523, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:13:37[0m] (step=0096800) Loss: 0.2725 (diff=0.1592, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:14:14[0m] (step=0096900) Loss: 0.2756 (diff=0.1627, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:14:51[0m] (step=0097000) Loss: 0.2681 (diff=0.1550, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:15:28[0m] (step=0097100) Loss: 0.2682 (diff=0.1548, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:16:06[0m] (step=0097200) Loss: 0.2697 (diff=0.1564, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:16:43[0m] (step=0097300) Loss: 0.2685 (diff=0.1548, repa=0.2274, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:17:20[0m] (step=0097400) Loss: 0.2687 (diff=0.1552, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:17:57[0m] (step=0097500) Loss: 0.2740 (diff=0.1608, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:18:34[0m] (step=0097600) Loss: 0.2687 (diff=0.1553, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:19:11[0m] (step=0097700) Loss: 0.2662 (diff=0.1527, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:19:49[0m] (step=0097800) Loss: 0.2662 (diff=0.1526, repa=0.2274, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:20:26[0m] (step=0097900) Loss: 0.2657 (diff=0.1519, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:21:03[0m] (step=0098000) Loss: 0.2711 (diff=0.1577, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:21:40[0m] (step=0098100) Loss: 0.2666 (diff=0.1531, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:22:17[0m] (step=0098200) Loss: 0.2662 (diff=0.1525, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:22:54[0m] (step=0098300) Loss: 0.2679 (diff=0.1547, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:23:32[0m] (step=0098400) Loss: 0.2709 (diff=0.1576, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:24:09[0m] (step=0098500) Loss: 0.2683 (diff=0.1552, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:24:46[0m] (step=0098600) Loss: 0.2704 (diff=0.1569, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:25:23[0m] (step=0098700) Loss: 0.2642 (diff=0.1501, repa=0.2283, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:26:00[0m] (step=0098800) Loss: 0.2745 (diff=0.1612, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:26:38[0m] (step=0098900) Loss: 0.2692 (diff=0.1558, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:27:15[0m] (step=0099000) Loss: 0.2703 (diff=0.1573, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:27:52[0m] (step=0099100) Loss: 0.2730 (diff=0.1597, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:28:29[0m] (step=0099200) Loss: 0.2705 (diff=0.1571, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:29:06[0m] (step=0099300) Loss: 0.2711 (diff=0.1581, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:29:44[0m] (step=0099400) Loss: 0.2710 (diff=0.1575, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:30:21[0m] (step=0099500) Loss: 0.2726 (diff=0.1592, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:30:58[0m] (step=0099600) Loss: 0.2705 (diff=0.1570, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:31:35[0m] (step=0099700) Loss: 0.2713 (diff=0.1577, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:32:12[0m] (step=0099800) Loss: 0.2705 (diff=0.1571, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:32:49[0m] (step=0099900) Loss: 0.2647 (diff=0.1511, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:33:27[0m] (step=0100000) Loss: 0.2728 (diff=0.1597, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:33:27[0m] Saved checkpoint to /data4/haksoo/trm_repa/003-DiT-XL-2/checkpoints/0100000.pt
/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  return func(*args, **kwargs)
[[34m2026-02-09 23:34:01[0m] Beginning epoch 5...
[[34m2026-02-09 23:34:05[0m] (step=0100100) Loss: 0.2713 (diff=0.1584, repa=0.2259, λ=0.5) Steps/Sec: 2.60
[[34m2026-02-09 23:34:42[0m] (step=0100200) Loss: 0.2705 (diff=0.1570, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:35:19[0m] (step=0100300) Loss: 0.2692 (diff=0.1562, repa=0.2262, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 23:35:57[0m] (step=0100400) Loss: 0.2680 (diff=0.1547, repa=0.2265, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 23:36:34[0m] (step=0100500) Loss: 0.2722 (diff=0.1593, repa=0.2259, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 23:37:11[0m] (step=0100600) Loss: 0.2646 (diff=0.1512, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:37:48[0m] (step=0100700) Loss: 0.2697 (diff=0.1565, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:38:26[0m] (step=0100800) Loss: 0.2704 (diff=0.1569, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:39:03[0m] (step=0100900) Loss: 0.2691 (diff=0.1556, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:39:40[0m] (step=0101000) Loss: 0.2701 (diff=0.1568, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:40:17[0m] (step=0101100) Loss: 0.2701 (diff=0.1562, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:40:55[0m] (step=0101200) Loss: 0.2674 (diff=0.1536, repa=0.2274, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:41:32[0m] (step=0101300) Loss: 0.2675 (diff=0.1535, repa=0.2281, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:42:09[0m] (step=0101400) Loss: 0.2668 (diff=0.1532, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:42:46[0m] (step=0101500) Loss: 0.2698 (diff=0.1562, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:43:23[0m] (step=0101600) Loss: 0.2632 (diff=0.1492, repa=0.2280, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:44:01[0m] (step=0101700) Loss: 0.2651 (diff=0.1511, repa=0.2279, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:44:38[0m] (step=0101800) Loss: 0.2701 (diff=0.1571, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:45:15[0m] (step=0101900) Loss: 0.2682 (diff=0.1546, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:45:52[0m] (step=0102000) Loss: 0.2710 (diff=0.1575, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:46:30[0m] (step=0102100) Loss: 0.2734 (diff=0.1608, repa=0.2252, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 23:47:07[0m] (step=0102200) Loss: 0.2685 (diff=0.1553, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:47:44[0m] (step=0102300) Loss: 0.2680 (diff=0.1549, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:48:21[0m] (step=0102400) Loss: 0.2661 (diff=0.1524, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:48:58[0m] (step=0102500) Loss: 0.2718 (diff=0.1582, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:49:36[0m] (step=0102600) Loss: 0.2651 (diff=0.1519, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:50:13[0m] (step=0102700) Loss: 0.2659 (diff=0.1526, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:50:50[0m] (step=0102800) Loss: 0.2723 (diff=0.1592, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:51:27[0m] (step=0102900) Loss: 0.2691 (diff=0.1555, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:52:05[0m] (step=0103000) Loss: 0.2716 (diff=0.1582, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:52:42[0m] (step=0103100) Loss: 0.2691 (diff=0.1556, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:53:19[0m] (step=0103200) Loss: 0.2683 (diff=0.1548, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:53:56[0m] (step=0103300) Loss: 0.2718 (diff=0.1585, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:54:33[0m] (step=0103400) Loss: 0.2682 (diff=0.1552, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:55:11[0m] (step=0103500) Loss: 0.2677 (diff=0.1541, repa=0.2272, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 23:55:48[0m] (step=0103600) Loss: 0.2790 (diff=0.1661, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:56:25[0m] (step=0103700) Loss: 0.2709 (diff=0.1572, repa=0.2275, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-09 23:57:02[0m] (step=0103800) Loss: 0.2712 (diff=0.1582, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:57:40[0m] (step=0103900) Loss: 0.2730 (diff=0.1599, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:58:17[0m] (step=0104000) Loss: 0.2665 (diff=0.1529, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:58:54[0m] (step=0104100) Loss: 0.2697 (diff=0.1563, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-09 23:59:31[0m] (step=0104200) Loss: 0.2697 (diff=0.1560, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:00:08[0m] (step=0104300) Loss: 0.2702 (diff=0.1570, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:00:46[0m] (step=0104400) Loss: 0.2685 (diff=0.1548, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:01:23[0m] (step=0104500) Loss: 0.2657 (diff=0.1520, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:02:00[0m] (step=0104600) Loss: 0.2669 (diff=0.1541, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:02:37[0m] (step=0104700) Loss: 0.2637 (diff=0.1503, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:03:15[0m] (step=0104800) Loss: 0.2697 (diff=0.1564, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:03:52[0m] (step=0104900) Loss: 0.2619 (diff=0.1482, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:04:29[0m] (step=0105000) Loss: 0.2693 (diff=0.1557, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:05:06[0m] (step=0105100) Loss: 0.2681 (diff=0.1548, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:05:44[0m] (step=0105200) Loss: 0.2702 (diff=0.1566, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:06:21[0m] (step=0105300) Loss: 0.2706 (diff=0.1573, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:06:58[0m] (step=0105400) Loss: 0.2662 (diff=0.1533, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:07:35[0m] (step=0105500) Loss: 0.2654 (diff=0.1519, repa=0.2271, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 00:08:12[0m] (step=0105600) Loss: 0.2661 (diff=0.1529, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:08:50[0m] (step=0105700) Loss: 0.2665 (diff=0.1529, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:09:27[0m] (step=0105800) Loss: 0.2713 (diff=0.1582, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:10:04[0m] (step=0105900) Loss: 0.2728 (diff=0.1602, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:10:41[0m] (step=0106000) Loss: 0.2711 (diff=0.1580, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:11:19[0m] (step=0106100) Loss: 0.2724 (diff=0.1594, repa=0.2262, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 00:11:56[0m] (step=0106200) Loss: 0.2680 (diff=0.1547, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:12:33[0m] (step=0106300) Loss: 0.2673 (diff=0.1539, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:13:10[0m] (step=0106400) Loss: 0.2646 (diff=0.1511, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:13:48[0m] (step=0106500) Loss: 0.2692 (diff=0.1558, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:14:25[0m] (step=0106600) Loss: 0.2642 (diff=0.1506, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:15:02[0m] (step=0106700) Loss: 0.2704 (diff=0.1574, repa=0.2262, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 00:15:39[0m] (step=0106800) Loss: 0.2667 (diff=0.1531, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:16:16[0m] (step=0106900) Loss: 0.2707 (diff=0.1574, repa=0.2266, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 00:16:54[0m] (step=0107000) Loss: 0.2690 (diff=0.1555, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:17:31[0m] (step=0107100) Loss: 0.2646 (diff=0.1512, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:18:08[0m] (step=0107200) Loss: 0.2683 (diff=0.1550, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:18:45[0m] (step=0107300) Loss: 0.2682 (diff=0.1548, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:19:23[0m] (step=0107400) Loss: 0.2722 (diff=0.1593, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:20:00[0m] (step=0107500) Loss: 0.2706 (diff=0.1571, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:20:37[0m] (step=0107600) Loss: 0.2667 (diff=0.1534, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:21:14[0m] (step=0107700) Loss: 0.2700 (diff=0.1568, repa=0.2264, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 00:21:52[0m] (step=0107800) Loss: 0.2699 (diff=0.1565, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:22:29[0m] (step=0107900) Loss: 0.2738 (diff=0.1609, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:23:06[0m] (step=0108000) Loss: 0.2696 (diff=0.1563, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:23:43[0m] (step=0108100) Loss: 0.2686 (diff=0.1551, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:24:20[0m] (step=0108200) Loss: 0.2671 (diff=0.1540, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:24:58[0m] (step=0108300) Loss: 0.2712 (diff=0.1581, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:25:35[0m] (step=0108400) Loss: 0.2713 (diff=0.1582, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:26:12[0m] (step=0108500) Loss: 0.2702 (diff=0.1570, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:26:49[0m] (step=0108600) Loss: 0.2703 (diff=0.1569, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:27:26[0m] (step=0108700) Loss: 0.2648 (diff=0.1513, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:28:04[0m] (step=0108800) Loss: 0.2701 (diff=0.1572, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:28:41[0m] (step=0108900) Loss: 0.2660 (diff=0.1524, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:29:18[0m] (step=0109000) Loss: 0.2640 (diff=0.1505, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:29:55[0m] (step=0109100) Loss: 0.2688 (diff=0.1557, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:30:32[0m] (step=0109200) Loss: 0.2683 (diff=0.1545, repa=0.2276, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:31:10[0m] (step=0109300) Loss: 0.2720 (diff=0.1588, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:31:47[0m] (step=0109400) Loss: 0.2759 (diff=0.1631, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:32:24[0m] (step=0109500) Loss: 0.2695 (diff=0.1563, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:33:01[0m] (step=0109600) Loss: 0.2692 (diff=0.1557, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:33:38[0m] (step=0109700) Loss: 0.2675 (diff=0.1544, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:34:16[0m] (step=0109800) Loss: 0.2682 (diff=0.1548, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:34:53[0m] (step=0109900) Loss: 0.2694 (diff=0.1560, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:35:30[0m] (step=0110000) Loss: 0.2676 (diff=0.1541, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:36:07[0m] (step=0110100) Loss: 0.2717 (diff=0.1588, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:36:44[0m] (step=0110200) Loss: 0.2702 (diff=0.1571, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:37:22[0m] (step=0110300) Loss: 0.2695 (diff=0.1560, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:37:59[0m] (step=0110400) Loss: 0.2672 (diff=0.1540, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:38:36[0m] (step=0110500) Loss: 0.2705 (diff=0.1569, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:39:13[0m] (step=0110600) Loss: 0.2718 (diff=0.1583, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:39:50[0m] (step=0110700) Loss: 0.2676 (diff=0.1544, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:40:28[0m] (step=0110800) Loss: 0.2593 (diff=0.1455, repa=0.2277, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:41:05[0m] (step=0110900) Loss: 0.2700 (diff=0.1571, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:41:42[0m] (step=0111000) Loss: 0.2710 (diff=0.1580, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:42:19[0m] (step=0111100) Loss: 0.2645 (diff=0.1510, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:42:56[0m] (step=0111200) Loss: 0.2724 (diff=0.1595, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:43:34[0m] (step=0111300) Loss: 0.2683 (diff=0.1550, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:44:11[0m] (step=0111400) Loss: 0.2719 (diff=0.1591, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:44:48[0m] (step=0111500) Loss: 0.2686 (diff=0.1554, repa=0.2263, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 00:45:25[0m] (step=0111600) Loss: 0.2664 (diff=0.1533, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:46:03[0m] (step=0111700) Loss: 0.2691 (diff=0.1557, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:46:40[0m] (step=0111800) Loss: 0.2712 (diff=0.1579, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:47:17[0m] (step=0111900) Loss: 0.2722 (diff=0.1592, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:47:54[0m] (step=0112000) Loss: 0.2674 (diff=0.1542, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:48:31[0m] (step=0112100) Loss: 0.2719 (diff=0.1588, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:49:09[0m] (step=0112200) Loss: 0.2669 (diff=0.1536, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:49:46[0m] (step=0112300) Loss: 0.2735 (diff=0.1604, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:50:23[0m] (step=0112400) Loss: 0.2724 (diff=0.1595, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:51:00[0m] (step=0112500) Loss: 0.2692 (diff=0.1560, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:51:37[0m] (step=0112600) Loss: 0.2739 (diff=0.1609, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:52:14[0m] (step=0112700) Loss: 0.2691 (diff=0.1560, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:52:51[0m] (step=0112800) Loss: 0.2717 (diff=0.1585, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:53:29[0m] (step=0112900) Loss: 0.2706 (diff=0.1577, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:54:06[0m] (step=0113000) Loss: 0.2677 (diff=0.1545, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:54:43[0m] (step=0113100) Loss: 0.2673 (diff=0.1538, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:55:20[0m] (step=0113200) Loss: 0.2659 (diff=0.1525, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:55:57[0m] (step=0113300) Loss: 0.2677 (diff=0.1543, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:56:34[0m] (step=0113400) Loss: 0.2717 (diff=0.1587, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:57:12[0m] (step=0113500) Loss: 0.2638 (diff=0.1503, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:57:49[0m] (step=0113600) Loss: 0.2681 (diff=0.1547, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:58:26[0m] (step=0113700) Loss: 0.2704 (diff=0.1573, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:59:03[0m] (step=0113800) Loss: 0.2706 (diff=0.1572, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 00:59:40[0m] (step=0113900) Loss: 0.2707 (diff=0.1573, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:00:17[0m] (step=0114000) Loss: 0.2719 (diff=0.1586, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:00:55[0m] (step=0114100) Loss: 0.2671 (diff=0.1540, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:01:32[0m] (step=0114200) Loss: 0.2673 (diff=0.1536, repa=0.2274, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:02:09[0m] (step=0114300) Loss: 0.2651 (diff=0.1516, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:02:46[0m] (step=0114400) Loss: 0.2694 (diff=0.1565, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:03:23[0m] (step=0114500) Loss: 0.2676 (diff=0.1542, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:04:00[0m] (step=0114600) Loss: 0.2736 (diff=0.1604, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:04:38[0m] (step=0114700) Loss: 0.2722 (diff=0.1592, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:05:15[0m] (step=0114800) Loss: 0.2717 (diff=0.1590, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:05:52[0m] (step=0114900) Loss: 0.2698 (diff=0.1564, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:06:29[0m] (step=0115000) Loss: 0.2678 (diff=0.1547, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:07:06[0m] (step=0115100) Loss: 0.2713 (diff=0.1582, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:07:43[0m] (step=0115200) Loss: 0.2712 (diff=0.1581, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:08:20[0m] (step=0115300) Loss: 0.2676 (diff=0.1543, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:08:58[0m] (step=0115400) Loss: 0.2716 (diff=0.1584, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:09:35[0m] (step=0115500) Loss: 0.2736 (diff=0.1607, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:10:12[0m] (step=0115600) Loss: 0.2672 (diff=0.1538, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:10:49[0m] (step=0115700) Loss: 0.2686 (diff=0.1557, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:11:26[0m] (step=0115800) Loss: 0.2712 (diff=0.1584, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:12:03[0m] (step=0115900) Loss: 0.2682 (diff=0.1550, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:12:41[0m] (step=0116000) Loss: 0.2681 (diff=0.1548, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:13:18[0m] (step=0116100) Loss: 0.2689 (diff=0.1558, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:13:55[0m] (step=0116200) Loss: 0.2695 (diff=0.1566, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:14:32[0m] (step=0116300) Loss: 0.2683 (diff=0.1552, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:15:09[0m] (step=0116400) Loss: 0.2656 (diff=0.1519, repa=0.2274, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:15:46[0m] (step=0116500) Loss: 0.2702 (diff=0.1575, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:16:24[0m] (step=0116600) Loss: 0.2757 (diff=0.1632, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:17:01[0m] (step=0116700) Loss: 0.2686 (diff=0.1552, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:17:38[0m] (step=0116800) Loss: 0.2735 (diff=0.1606, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:18:15[0m] (step=0116900) Loss: 0.2750 (diff=0.1620, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:18:52[0m] (step=0117000) Loss: 0.2653 (diff=0.1520, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:19:29[0m] (step=0117100) Loss: 0.2615 (diff=0.1478, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:20:07[0m] (step=0117200) Loss: 0.2689 (diff=0.1556, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:20:44[0m] (step=0117300) Loss: 0.2726 (diff=0.1597, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:21:21[0m] (step=0117400) Loss: 0.2697 (diff=0.1566, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:21:58[0m] (step=0117500) Loss: 0.2651 (diff=0.1517, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:22:35[0m] (step=0117600) Loss: 0.2699 (diff=0.1567, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:23:12[0m] (step=0117700) Loss: 0.2739 (diff=0.1610, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:23:50[0m] (step=0117800) Loss: 0.2781 (diff=0.1657, repa=0.2248, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:24:27[0m] (step=0117900) Loss: 0.2671 (diff=0.1538, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:25:04[0m] (step=0118000) Loss: 0.2684 (diff=0.1554, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:25:41[0m] (step=0118100) Loss: 0.2665 (diff=0.1532, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:26:18[0m] (step=0118200) Loss: 0.2666 (diff=0.1534, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:26:56[0m] (step=0118300) Loss: 0.2686 (diff=0.1555, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:27:33[0m] (step=0118400) Loss: 0.2657 (diff=0.1529, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:28:10[0m] (step=0118500) Loss: 0.2679 (diff=0.1548, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:28:47[0m] (step=0118600) Loss: 0.2647 (diff=0.1517, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:29:24[0m] (step=0118700) Loss: 0.2737 (diff=0.1607, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:30:01[0m] (step=0118800) Loss: 0.2673 (diff=0.1542, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:30:39[0m] (step=0118900) Loss: 0.2688 (diff=0.1556, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:31:16[0m] (step=0119000) Loss: 0.2719 (diff=0.1587, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:31:53[0m] (step=0119100) Loss: 0.2713 (diff=0.1585, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:32:30[0m] (step=0119200) Loss: 0.2719 (diff=0.1588, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:33:07[0m] (step=0119300) Loss: 0.2662 (diff=0.1529, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:33:44[0m] (step=0119400) Loss: 0.2682 (diff=0.1551, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:34:22[0m] (step=0119500) Loss: 0.2662 (diff=0.1530, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:34:59[0m] (step=0119600) Loss: 0.2694 (diff=0.1562, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:35:36[0m] (step=0119700) Loss: 0.2698 (diff=0.1565, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:36:13[0m] (step=0119800) Loss: 0.2727 (diff=0.1600, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:36:50[0m] (step=0119900) Loss: 0.2736 (diff=0.1607, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:37:28[0m] (step=0120000) Loss: 0.2704 (diff=0.1572, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:37:28[0m] Saved checkpoint to /data4/haksoo/trm_repa/003-DiT-XL-2/checkpoints/0120000.pt
[[34m2026-02-10 01:38:05[0m] (step=0120100) Loss: 0.2656 (diff=0.1527, repa=0.2258, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 01:38:09[0m] Beginning epoch 6...
[[34m2026-02-10 01:38:43[0m] (step=0120200) Loss: 0.2766 (diff=0.1640, repa=0.2253, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-10 01:39:20[0m] (step=0120300) Loss: 0.2734 (diff=0.1605, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:39:58[0m] (step=0120400) Loss: 0.2721 (diff=0.1594, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:40:35[0m] (step=0120500) Loss: 0.2712 (diff=0.1580, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:41:12[0m] (step=0120600) Loss: 0.2716 (diff=0.1589, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:41:49[0m] (step=0120700) Loss: 0.2690 (diff=0.1559, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:42:27[0m] (step=0120800) Loss: 0.2709 (diff=0.1577, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:43:04[0m] (step=0120900) Loss: 0.2718 (diff=0.1587, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:43:41[0m] (step=0121000) Loss: 0.2699 (diff=0.1564, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:44:18[0m] (step=0121100) Loss: 0.2678 (diff=0.1550, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:44:56[0m] (step=0121200) Loss: 0.2742 (diff=0.1616, repa=0.2252, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 01:45:33[0m] (step=0121300) Loss: 0.2716 (diff=0.1585, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:46:10[0m] (step=0121400) Loss: 0.2690 (diff=0.1557, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:46:47[0m] (step=0121500) Loss: 0.2712 (diff=0.1582, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:47:24[0m] (step=0121600) Loss: 0.2641 (diff=0.1508, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:48:02[0m] (step=0121700) Loss: 0.2668 (diff=0.1534, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:48:39[0m] (step=0121800) Loss: 0.2701 (diff=0.1572, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:49:16[0m] (step=0121900) Loss: 0.2664 (diff=0.1531, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:49:53[0m] (step=0122000) Loss: 0.2692 (diff=0.1563, repa=0.2259, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 01:50:31[0m] (step=0122100) Loss: 0.2636 (diff=0.1499, repa=0.2275, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:51:08[0m] (step=0122200) Loss: 0.2620 (diff=0.1485, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:51:45[0m] (step=0122300) Loss: 0.2718 (diff=0.1590, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:52:22[0m] (step=0122400) Loss: 0.2714 (diff=0.1583, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:52:59[0m] (step=0122500) Loss: 0.2683 (diff=0.1551, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:53:37[0m] (step=0122600) Loss: 0.2702 (diff=0.1573, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:54:14[0m] (step=0122700) Loss: 0.2695 (diff=0.1564, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:54:51[0m] (step=0122800) Loss: 0.2712 (diff=0.1584, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:55:28[0m] (step=0122900) Loss: 0.2704 (diff=0.1575, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:56:06[0m] (step=0123000) Loss: 0.2688 (diff=0.1559, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:56:43[0m] (step=0123100) Loss: 0.2646 (diff=0.1512, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:57:20[0m] (step=0123200) Loss: 0.2708 (diff=0.1578, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:57:57[0m] (step=0123300) Loss: 0.2663 (diff=0.1531, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:58:34[0m] (step=0123400) Loss: 0.2709 (diff=0.1581, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:59:12[0m] (step=0123500) Loss: 0.2642 (diff=0.1510, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 01:59:49[0m] (step=0123600) Loss: 0.2684 (diff=0.1557, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:00:26[0m] (step=0123700) Loss: 0.2680 (diff=0.1547, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:01:03[0m] (step=0123800) Loss: 0.2720 (diff=0.1587, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:01:41[0m] (step=0123900) Loss: 0.2713 (diff=0.1582, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:02:18[0m] (step=0124000) Loss: 0.2674 (diff=0.1544, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:02:55[0m] (step=0124100) Loss: 0.2643 (diff=0.1507, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:03:32[0m] (step=0124200) Loss: 0.2675 (diff=0.1548, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:04:09[0m] (step=0124300) Loss: 0.2702 (diff=0.1571, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:04:47[0m] (step=0124400) Loss: 0.2692 (diff=0.1560, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:05:24[0m] (step=0124500) Loss: 0.2734 (diff=0.1607, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:06:01[0m] (step=0124600) Loss: 0.2729 (diff=0.1598, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:06:38[0m] (step=0124700) Loss: 0.2699 (diff=0.1570, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:07:15[0m] (step=0124800) Loss: 0.2657 (diff=0.1523, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:07:53[0m] (step=0124900) Loss: 0.2717 (diff=0.1592, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:08:30[0m] (step=0125000) Loss: 0.2710 (diff=0.1580, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:09:07[0m] (step=0125100) Loss: 0.2689 (diff=0.1558, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:09:44[0m] (step=0125200) Loss: 0.2782 (diff=0.1655, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:10:21[0m] (step=0125300) Loss: 0.2647 (diff=0.1517, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:10:59[0m] (step=0125400) Loss: 0.2654 (diff=0.1520, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:11:36[0m] (step=0125500) Loss: 0.2718 (diff=0.1588, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:12:13[0m] (step=0125600) Loss: 0.2693 (diff=0.1563, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:12:50[0m] (step=0125700) Loss: 0.2710 (diff=0.1583, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:13:27[0m] (step=0125800) Loss: 0.2703 (diff=0.1574, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:14:05[0m] (step=0125900) Loss: 0.2732 (diff=0.1606, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:14:42[0m] (step=0126000) Loss: 0.2701 (diff=0.1573, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:15:19[0m] (step=0126100) Loss: 0.2669 (diff=0.1536, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:15:56[0m] (step=0126200) Loss: 0.2700 (diff=0.1571, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:16:33[0m] (step=0126300) Loss: 0.2659 (diff=0.1527, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:17:11[0m] (step=0126400) Loss: 0.2642 (diff=0.1506, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:17:48[0m] (step=0126500) Loss: 0.2705 (diff=0.1577, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:18:25[0m] (step=0126600) Loss: 0.2689 (diff=0.1558, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:19:02[0m] (step=0126700) Loss: 0.2729 (diff=0.1604, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:19:39[0m] (step=0126800) Loss: 0.2717 (diff=0.1587, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:20:16[0m] (step=0126900) Loss: 0.2661 (diff=0.1530, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:20:54[0m] (step=0127000) Loss: 0.2678 (diff=0.1547, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:21:31[0m] (step=0127100) Loss: 0.2717 (diff=0.1586, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:22:08[0m] (step=0127200) Loss: 0.2684 (diff=0.1556, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:22:45[0m] (step=0127300) Loss: 0.2749 (diff=0.1624, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:23:22[0m] (step=0127400) Loss: 0.2663 (diff=0.1529, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:24:00[0m] (step=0127500) Loss: 0.2774 (diff=0.1649, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:24:37[0m] (step=0127600) Loss: 0.2694 (diff=0.1562, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:25:14[0m] (step=0127700) Loss: 0.2683 (diff=0.1548, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:25:51[0m] (step=0127800) Loss: 0.2706 (diff=0.1577, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:26:28[0m] (step=0127900) Loss: 0.2667 (diff=0.1533, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:27:06[0m] (step=0128000) Loss: 0.2770 (diff=0.1641, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:27:43[0m] (step=0128100) Loss: 0.2696 (diff=0.1566, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:28:20[0m] (step=0128200) Loss: 0.2691 (diff=0.1559, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:28:57[0m] (step=0128300) Loss: 0.2682 (diff=0.1552, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:29:34[0m] (step=0128400) Loss: 0.2718 (diff=0.1591, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:30:12[0m] (step=0128500) Loss: 0.2694 (diff=0.1565, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:30:49[0m] (step=0128600) Loss: 0.2692 (diff=0.1563, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:31:26[0m] (step=0128700) Loss: 0.2729 (diff=0.1604, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:32:03[0m] (step=0128800) Loss: 0.2662 (diff=0.1534, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:32:40[0m] (step=0128900) Loss: 0.2665 (diff=0.1535, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:33:18[0m] (step=0129000) Loss: 0.2709 (diff=0.1578, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:33:55[0m] (step=0129100) Loss: 0.2701 (diff=0.1575, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:34:32[0m] (step=0129200) Loss: 0.2693 (diff=0.1564, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:35:09[0m] (step=0129300) Loss: 0.2706 (diff=0.1575, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:35:47[0m] (step=0129400) Loss: 0.2719 (diff=0.1595, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:36:24[0m] (step=0129500) Loss: 0.2642 (diff=0.1506, repa=0.2270, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:37:01[0m] (step=0129600) Loss: 0.2715 (diff=0.1583, repa=0.2264, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 02:37:38[0m] (step=0129700) Loss: 0.2668 (diff=0.1538, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:38:15[0m] (step=0129800) Loss: 0.2676 (diff=0.1543, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:38:53[0m] (step=0129900) Loss: 0.2686 (diff=0.1558, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:39:30[0m] (step=0130000) Loss: 0.2664 (diff=0.1536, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:40:07[0m] (step=0130100) Loss: 0.2676 (diff=0.1545, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:40:44[0m] (step=0130200) Loss: 0.2680 (diff=0.1549, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:41:22[0m] (step=0130300) Loss: 0.2695 (diff=0.1566, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:41:59[0m] (step=0130400) Loss: 0.2692 (diff=0.1556, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:42:36[0m] (step=0130500) Loss: 0.2688 (diff=0.1555, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:43:13[0m] (step=0130600) Loss: 0.2703 (diff=0.1575, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:43:50[0m] (step=0130700) Loss: 0.2702 (diff=0.1572, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:44:28[0m] (step=0130800) Loss: 0.2679 (diff=0.1552, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:45:05[0m] (step=0130900) Loss: 0.2747 (diff=0.1623, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:45:42[0m] (step=0131000) Loss: 0.2691 (diff=0.1564, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:46:19[0m] (step=0131100) Loss: 0.2635 (diff=0.1502, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:46:57[0m] (step=0131200) Loss: 0.2675 (diff=0.1545, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:47:34[0m] (step=0131300) Loss: 0.2697 (diff=0.1569, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:48:11[0m] (step=0131400) Loss: 0.2713 (diff=0.1583, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:48:48[0m] (step=0131500) Loss: 0.2745 (diff=0.1622, repa=0.2247, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:49:25[0m] (step=0131600) Loss: 0.2691 (diff=0.1561, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:50:03[0m] (step=0131700) Loss: 0.2646 (diff=0.1511, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:50:40[0m] (step=0131800) Loss: 0.2667 (diff=0.1537, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:51:17[0m] (step=0131900) Loss: 0.2657 (diff=0.1522, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:51:54[0m] (step=0132000) Loss: 0.2645 (diff=0.1516, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:52:32[0m] (step=0132100) Loss: 0.2695 (diff=0.1570, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:53:09[0m] (step=0132200) Loss: 0.2658 (diff=0.1531, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:53:46[0m] (step=0132300) Loss: 0.2668 (diff=0.1536, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:54:23[0m] (step=0132400) Loss: 0.2692 (diff=0.1564, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:55:01[0m] (step=0132500) Loss: 0.2689 (diff=0.1561, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:55:38[0m] (step=0132600) Loss: 0.2712 (diff=0.1584, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:56:15[0m] (step=0132700) Loss: 0.2661 (diff=0.1529, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:56:52[0m] (step=0132800) Loss: 0.2719 (diff=0.1589, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:57:29[0m] (step=0132900) Loss: 0.2605 (diff=0.1471, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:58:07[0m] (step=0133000) Loss: 0.2670 (diff=0.1540, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:58:44[0m] (step=0133100) Loss: 0.2654 (diff=0.1524, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:59:21[0m] (step=0133200) Loss: 0.2690 (diff=0.1561, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 02:59:58[0m] (step=0133300) Loss: 0.2660 (diff=0.1532, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:00:35[0m] (step=0133400) Loss: 0.2654 (diff=0.1523, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:01:13[0m] (step=0133500) Loss: 0.2693 (diff=0.1565, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:01:50[0m] (step=0133600) Loss: 0.2703 (diff=0.1574, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:02:27[0m] (step=0133700) Loss: 0.2680 (diff=0.1545, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:03:04[0m] (step=0133800) Loss: 0.2654 (diff=0.1526, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:03:41[0m] (step=0133900) Loss: 0.2780 (diff=0.1653, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:04:19[0m] (step=0134000) Loss: 0.2637 (diff=0.1507, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:04:56[0m] (step=0134100) Loss: 0.2706 (diff=0.1575, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:05:33[0m] (step=0134200) Loss: 0.2683 (diff=0.1551, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:06:10[0m] (step=0134300) Loss: 0.2703 (diff=0.1576, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:06:48[0m] (step=0134400) Loss: 0.2712 (diff=0.1583, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:07:25[0m] (step=0134500) Loss: 0.2678 (diff=0.1547, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:08:02[0m] (step=0134600) Loss: 0.2696 (diff=0.1569, repa=0.2255, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 03:08:39[0m] (step=0134700) Loss: 0.2644 (diff=0.1511, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:09:16[0m] (step=0134800) Loss: 0.2709 (diff=0.1581, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:09:54[0m] (step=0134900) Loss: 0.2665 (diff=0.1531, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:10:31[0m] (step=0135000) Loss: 0.2685 (diff=0.1558, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:11:08[0m] (step=0135100) Loss: 0.2668 (diff=0.1534, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:11:45[0m] (step=0135200) Loss: 0.2692 (diff=0.1567, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:12:22[0m] (step=0135300) Loss: 0.2633 (diff=0.1500, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:13:00[0m] (step=0135400) Loss: 0.2688 (diff=0.1561, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:13:37[0m] (step=0135500) Loss: 0.2676 (diff=0.1544, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:14:14[0m] (step=0135600) Loss: 0.2691 (diff=0.1558, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:14:51[0m] (step=0135700) Loss: 0.2661 (diff=0.1535, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:15:28[0m] (step=0135800) Loss: 0.2685 (diff=0.1556, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:16:06[0m] (step=0135900) Loss: 0.2669 (diff=0.1538, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:16:43[0m] (step=0136000) Loss: 0.2677 (diff=0.1545, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:17:20[0m] (step=0136100) Loss: 0.2689 (diff=0.1560, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:17:57[0m] (step=0136200) Loss: 0.2687 (diff=0.1562, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:18:35[0m] (step=0136300) Loss: 0.2653 (diff=0.1521, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:19:12[0m] (step=0136400) Loss: 0.2671 (diff=0.1543, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:19:49[0m] (step=0136500) Loss: 0.2695 (diff=0.1565, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:20:26[0m] (step=0136600) Loss: 0.2714 (diff=0.1587, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:21:03[0m] (step=0136700) Loss: 0.2693 (diff=0.1564, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:21:41[0m] (step=0136800) Loss: 0.2787 (diff=0.1661, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:22:18[0m] (step=0136900) Loss: 0.2654 (diff=0.1524, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:22:55[0m] (step=0137000) Loss: 0.2673 (diff=0.1545, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:23:32[0m] (step=0137100) Loss: 0.2730 (diff=0.1603, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:24:09[0m] (step=0137200) Loss: 0.2599 (diff=0.1468, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:24:47[0m] (step=0137300) Loss: 0.2661 (diff=0.1528, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:25:24[0m] (step=0137400) Loss: 0.2657 (diff=0.1524, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:26:01[0m] (step=0137500) Loss: 0.2657 (diff=0.1526, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:26:38[0m] (step=0137600) Loss: 0.2746 (diff=0.1618, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:27:16[0m] (step=0137700) Loss: 0.2710 (diff=0.1584, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:27:53[0m] (step=0137800) Loss: 0.2700 (diff=0.1573, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:28:30[0m] (step=0137900) Loss: 0.2698 (diff=0.1563, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:29:07[0m] (step=0138000) Loss: 0.2701 (diff=0.1572, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:29:44[0m] (step=0138100) Loss: 0.2665 (diff=0.1535, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:30:22[0m] (step=0138200) Loss: 0.2655 (diff=0.1522, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:30:59[0m] (step=0138300) Loss: 0.2660 (diff=0.1531, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:31:36[0m] (step=0138400) Loss: 0.2692 (diff=0.1562, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:32:13[0m] (step=0138500) Loss: 0.2695 (diff=0.1566, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:32:50[0m] (step=0138600) Loss: 0.2657 (diff=0.1525, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:33:28[0m] (step=0138700) Loss: 0.2624 (diff=0.1492, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:34:05[0m] (step=0138800) Loss: 0.2688 (diff=0.1560, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:34:42[0m] (step=0138900) Loss: 0.2684 (diff=0.1554, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:35:19[0m] (step=0139000) Loss: 0.2639 (diff=0.1508, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:35:56[0m] (step=0139100) Loss: 0.2674 (diff=0.1544, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:36:34[0m] (step=0139200) Loss: 0.2693 (diff=0.1560, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:37:11[0m] (step=0139300) Loss: 0.2674 (diff=0.1545, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:37:48[0m] (step=0139400) Loss: 0.2649 (diff=0.1520, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:38:25[0m] (step=0139500) Loss: 0.2712 (diff=0.1583, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:39:02[0m] (step=0139600) Loss: 0.2690 (diff=0.1564, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:39:39[0m] (step=0139700) Loss: 0.2660 (diff=0.1532, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:40:17[0m] (step=0139800) Loss: 0.2665 (diff=0.1535, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:40:54[0m] (step=0139900) Loss: 0.2666 (diff=0.1537, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:41:31[0m] (step=0140000) Loss: 0.2703 (diff=0.1574, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:41:32[0m] Saved checkpoint to /data4/haksoo/trm_repa/003-DiT-XL-2/checkpoints/0140000.pt
[[34m2026-02-10 03:42:09[0m] (step=0140100) Loss: 0.2689 (diff=0.1560, repa=0.2258, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 03:42:19[0m] Beginning epoch 7...
[[34m2026-02-10 03:42:47[0m] (step=0140200) Loss: 0.2700 (diff=0.1568, repa=0.2265, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 03:43:24[0m] (step=0140300) Loss: 0.2660 (diff=0.1529, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:44:01[0m] (step=0140400) Loss: 0.2690 (diff=0.1564, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:44:38[0m] (step=0140500) Loss: 0.2670 (diff=0.1543, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:45:15[0m] (step=0140600) Loss: 0.2725 (diff=0.1597, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:45:52[0m] (step=0140700) Loss: 0.2720 (diff=0.1589, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:46:30[0m] (step=0140800) Loss: 0.2733 (diff=0.1607, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:47:07[0m] (step=0140900) Loss: 0.2647 (diff=0.1517, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:47:44[0m] (step=0141000) Loss: 0.2737 (diff=0.1613, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:48:21[0m] (step=0141100) Loss: 0.2671 (diff=0.1541, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:48:58[0m] (step=0141200) Loss: 0.2658 (diff=0.1530, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:49:36[0m] (step=0141300) Loss: 0.2686 (diff=0.1557, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:50:13[0m] (step=0141400) Loss: 0.2679 (diff=0.1550, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:50:50[0m] (step=0141500) Loss: 0.2650 (diff=0.1522, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:51:27[0m] (step=0141600) Loss: 0.2635 (diff=0.1504, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:52:04[0m] (step=0141700) Loss: 0.2709 (diff=0.1576, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:52:42[0m] (step=0141800) Loss: 0.2684 (diff=0.1556, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:53:19[0m] (step=0141900) Loss: 0.2669 (diff=0.1537, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:53:56[0m] (step=0142000) Loss: 0.2699 (diff=0.1570, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:54:33[0m] (step=0142100) Loss: 0.2669 (diff=0.1543, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:55:10[0m] (step=0142200) Loss: 0.2700 (diff=0.1576, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:55:47[0m] (step=0142300) Loss: 0.2680 (diff=0.1546, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:56:25[0m] (step=0142400) Loss: 0.2656 (diff=0.1526, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:57:02[0m] (step=0142500) Loss: 0.2699 (diff=0.1572, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:57:39[0m] (step=0142600) Loss: 0.2671 (diff=0.1545, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:58:16[0m] (step=0142700) Loss: 0.2650 (diff=0.1518, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:58:53[0m] (step=0142800) Loss: 0.2661 (diff=0.1529, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 03:59:30[0m] (step=0142900) Loss: 0.2749 (diff=0.1623, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:00:08[0m] (step=0143000) Loss: 0.2697 (diff=0.1572, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:00:45[0m] (step=0143100) Loss: 0.2710 (diff=0.1587, repa=0.2246, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:01:22[0m] (step=0143200) Loss: 0.2657 (diff=0.1530, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:01:59[0m] (step=0143300) Loss: 0.2708 (diff=0.1577, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:02:36[0m] (step=0143400) Loss: 0.2702 (diff=0.1574, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:03:14[0m] (step=0143500) Loss: 0.2666 (diff=0.1539, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:03:51[0m] (step=0143600) Loss: 0.2699 (diff=0.1573, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:04:28[0m] (step=0143700) Loss: 0.2722 (diff=0.1593, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:05:05[0m] (step=0143800) Loss: 0.2747 (diff=0.1621, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:05:42[0m] (step=0143900) Loss: 0.2690 (diff=0.1562, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:06:19[0m] (step=0144000) Loss: 0.2667 (diff=0.1536, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:06:57[0m] (step=0144100) Loss: 0.2740 (diff=0.1614, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:07:34[0m] (step=0144200) Loss: 0.2645 (diff=0.1515, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:08:11[0m] (step=0144300) Loss: 0.2695 (diff=0.1567, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:08:48[0m] (step=0144400) Loss: 0.2694 (diff=0.1568, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:09:25[0m] (step=0144500) Loss: 0.2687 (diff=0.1558, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:10:03[0m] (step=0144600) Loss: 0.2698 (diff=0.1570, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:10:40[0m] (step=0144700) Loss: 0.2619 (diff=0.1483, repa=0.2273, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:11:17[0m] (step=0144800) Loss: 0.2711 (diff=0.1583, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:11:54[0m] (step=0144900) Loss: 0.2654 (diff=0.1526, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:12:31[0m] (step=0145000) Loss: 0.2669 (diff=0.1537, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:13:08[0m] (step=0145100) Loss: 0.2678 (diff=0.1547, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:13:46[0m] (step=0145200) Loss: 0.2684 (diff=0.1555, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:14:23[0m] (step=0145300) Loss: 0.2736 (diff=0.1610, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:15:00[0m] (step=0145400) Loss: 0.2712 (diff=0.1583, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:15:37[0m] (step=0145500) Loss: 0.2739 (diff=0.1611, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:16:14[0m] (step=0145600) Loss: 0.2633 (diff=0.1507, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:16:51[0m] (step=0145700) Loss: 0.2687 (diff=0.1557, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:17:29[0m] (step=0145800) Loss: 0.2756 (diff=0.1630, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:18:06[0m] (step=0145900) Loss: 0.2658 (diff=0.1528, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:18:43[0m] (step=0146000) Loss: 0.2710 (diff=0.1583, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:19:20[0m] (step=0146100) Loss: 0.2660 (diff=0.1529, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:19:57[0m] (step=0146200) Loss: 0.2669 (diff=0.1540, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:20:35[0m] (step=0146300) Loss: 0.2737 (diff=0.1611, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:21:12[0m] (step=0146400) Loss: 0.2657 (diff=0.1523, repa=0.2268, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:21:49[0m] (step=0146500) Loss: 0.2690 (diff=0.1559, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:22:26[0m] (step=0146600) Loss: 0.2671 (diff=0.1544, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:23:03[0m] (step=0146700) Loss: 0.2735 (diff=0.1609, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:23:40[0m] (step=0146800) Loss: 0.2690 (diff=0.1558, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:24:18[0m] (step=0146900) Loss: 0.2673 (diff=0.1543, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:24:55[0m] (step=0147000) Loss: 0.2626 (diff=0.1493, repa=0.2266, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:25:32[0m] (step=0147100) Loss: 0.2636 (diff=0.1500, repa=0.2271, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:26:09[0m] (step=0147200) Loss: 0.2673 (diff=0.1543, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:26:46[0m] (step=0147300) Loss: 0.2729 (diff=0.1603, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:27:24[0m] (step=0147400) Loss: 0.2667 (diff=0.1537, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:28:01[0m] (step=0147500) Loss: 0.2670 (diff=0.1542, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:28:38[0m] (step=0147600) Loss: 0.2695 (diff=0.1566, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:29:15[0m] (step=0147700) Loss: 0.2740 (diff=0.1617, repa=0.2246, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:29:52[0m] (step=0147800) Loss: 0.2689 (diff=0.1564, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:30:29[0m] (step=0147900) Loss: 0.2671 (diff=0.1542, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:31:07[0m] (step=0148000) Loss: 0.2675 (diff=0.1544, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:31:44[0m] (step=0148100) Loss: 0.2722 (diff=0.1596, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:32:21[0m] (step=0148200) Loss: 0.2681 (diff=0.1552, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:32:58[0m] (step=0148300) Loss: 0.2710 (diff=0.1584, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:33:35[0m] (step=0148400) Loss: 0.2666 (diff=0.1539, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:34:13[0m] (step=0148500) Loss: 0.2701 (diff=0.1573, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:34:50[0m] (step=0148600) Loss: 0.2664 (diff=0.1535, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:35:27[0m] (step=0148700) Loss: 0.2706 (diff=0.1578, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:36:04[0m] (step=0148800) Loss: 0.2723 (diff=0.1598, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:36:41[0m] (step=0148900) Loss: 0.2714 (diff=0.1584, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:37:18[0m] (step=0149000) Loss: 0.2674 (diff=0.1549, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:37:56[0m] (step=0149100) Loss: 0.2666 (diff=0.1538, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:38:33[0m] (step=0149200) Loss: 0.2730 (diff=0.1605, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:39:10[0m] (step=0149300) Loss: 0.2655 (diff=0.1528, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:39:47[0m] (step=0149400) Loss: 0.2747 (diff=0.1620, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:40:24[0m] (step=0149500) Loss: 0.2676 (diff=0.1548, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:41:02[0m] (step=0149600) Loss: 0.2691 (diff=0.1561, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:41:39[0m] (step=0149700) Loss: 0.2701 (diff=0.1574, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:42:16[0m] (step=0149800) Loss: 0.2741 (diff=0.1614, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:42:53[0m] (step=0149900) Loss: 0.2732 (diff=0.1608, repa=0.2248, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:43:30[0m] (step=0150000) Loss: 0.2687 (diff=0.1556, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:44:08[0m] (step=0150100) Loss: 0.2722 (diff=0.1593, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:44:45[0m] (step=0150200) Loss: 0.2664 (diff=0.1534, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:45:22[0m] (step=0150300) Loss: 0.2760 (diff=0.1635, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:45:59[0m] (step=0150400) Loss: 0.2710 (diff=0.1580, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:46:36[0m] (step=0150500) Loss: 0.2695 (diff=0.1565, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:47:13[0m] (step=0150600) Loss: 0.2712 (diff=0.1586, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:47:51[0m] (step=0150700) Loss: 0.2675 (diff=0.1548, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:48:28[0m] (step=0150800) Loss: 0.2652 (diff=0.1524, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:49:05[0m] (step=0150900) Loss: 0.2678 (diff=0.1549, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:49:42[0m] (step=0151000) Loss: 0.2661 (diff=0.1533, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:50:19[0m] (step=0151100) Loss: 0.2672 (diff=0.1544, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:50:57[0m] (step=0151200) Loss: 0.2700 (diff=0.1572, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:51:34[0m] (step=0151300) Loss: 0.2740 (diff=0.1614, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:52:11[0m] (step=0151400) Loss: 0.2698 (diff=0.1571, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:52:48[0m] (step=0151500) Loss: 0.2685 (diff=0.1561, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:53:25[0m] (step=0151600) Loss: 0.2681 (diff=0.1553, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:54:02[0m] (step=0151700) Loss: 0.2669 (diff=0.1539, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:54:40[0m] (step=0151800) Loss: 0.2627 (diff=0.1494, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:55:17[0m] (step=0151900) Loss: 0.2659 (diff=0.1528, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:55:54[0m] (step=0152000) Loss: 0.2665 (diff=0.1539, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:56:31[0m] (step=0152100) Loss: 0.2716 (diff=0.1588, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:57:08[0m] (step=0152200) Loss: 0.2651 (diff=0.1519, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:57:45[0m] (step=0152300) Loss: 0.2647 (diff=0.1518, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:58:23[0m] (step=0152400) Loss: 0.2687 (diff=0.1557, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:59:00[0m] (step=0152500) Loss: 0.2645 (diff=0.1515, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 04:59:37[0m] (step=0152600) Loss: 0.2727 (diff=0.1602, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:00:14[0m] (step=0152700) Loss: 0.2654 (diff=0.1524, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:00:51[0m] (step=0152800) Loss: 0.2654 (diff=0.1524, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:01:28[0m] (step=0152900) Loss: 0.2711 (diff=0.1587, repa=0.2247, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:02:06[0m] (step=0153000) Loss: 0.2707 (diff=0.1581, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:02:43[0m] (step=0153100) Loss: 0.2705 (diff=0.1579, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:03:20[0m] (step=0153200) Loss: 0.2679 (diff=0.1550, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:03:57[0m] (step=0153300) Loss: 0.2641 (diff=0.1508, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:04:34[0m] (step=0153400) Loss: 0.2707 (diff=0.1583, repa=0.2248, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:05:11[0m] (step=0153500) Loss: 0.2688 (diff=0.1559, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:05:49[0m] (step=0153600) Loss: 0.2694 (diff=0.1566, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:06:26[0m] (step=0153700) Loss: 0.2616 (diff=0.1481, repa=0.2269, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:07:03[0m] (step=0153800) Loss: 0.2768 (diff=0.1643, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:07:40[0m] (step=0153900) Loss: 0.2689 (diff=0.1558, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:08:17[0m] (step=0154000) Loss: 0.2665 (diff=0.1536, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:08:54[0m] (step=0154100) Loss: 0.2672 (diff=0.1540, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:09:32[0m] (step=0154200) Loss: 0.2610 (diff=0.1478, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:10:09[0m] (step=0154300) Loss: 0.2685 (diff=0.1560, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:10:46[0m] (step=0154400) Loss: 0.2708 (diff=0.1580, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:11:23[0m] (step=0154500) Loss: 0.2666 (diff=0.1537, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:12:00[0m] (step=0154600) Loss: 0.2678 (diff=0.1551, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:12:37[0m] (step=0154700) Loss: 0.2692 (diff=0.1563, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:13:15[0m] (step=0154800) Loss: 0.2676 (diff=0.1551, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:13:52[0m] (step=0154900) Loss: 0.2634 (diff=0.1502, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:14:29[0m] (step=0155000) Loss: 0.2697 (diff=0.1569, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:15:06[0m] (step=0155100) Loss: 0.2671 (diff=0.1538, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:15:43[0m] (step=0155200) Loss: 0.2693 (diff=0.1563, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:16:20[0m] (step=0155300) Loss: 0.2674 (diff=0.1543, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:16:58[0m] (step=0155400) Loss: 0.2692 (diff=0.1567, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:17:35[0m] (step=0155500) Loss: 0.2684 (diff=0.1557, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:18:12[0m] (step=0155600) Loss: 0.2695 (diff=0.1565, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:18:49[0m] (step=0155700) Loss: 0.2639 (diff=0.1509, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:19:26[0m] (step=0155800) Loss: 0.2682 (diff=0.1554, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:20:03[0m] (step=0155900) Loss: 0.2676 (diff=0.1546, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:20:40[0m] (step=0156000) Loss: 0.2622 (diff=0.1492, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:21:18[0m] (step=0156100) Loss: 0.2732 (diff=0.1607, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:21:55[0m] (step=0156200) Loss: 0.2683 (diff=0.1548, repa=0.2272, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:22:32[0m] (step=0156300) Loss: 0.2696 (diff=0.1569, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:23:09[0m] (step=0156400) Loss: 0.2661 (diff=0.1531, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:23:46[0m] (step=0156500) Loss: 0.2761 (diff=0.1639, repa=0.2242, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:24:23[0m] (step=0156600) Loss: 0.2705 (diff=0.1578, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:25:01[0m] (step=0156700) Loss: 0.2663 (diff=0.1532, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:25:38[0m] (step=0156800) Loss: 0.2664 (diff=0.1535, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:26:15[0m] (step=0156900) Loss: 0.2671 (diff=0.1545, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:26:52[0m] (step=0157000) Loss: 0.2647 (diff=0.1520, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:27:29[0m] (step=0157100) Loss: 0.2694 (diff=0.1568, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:28:06[0m] (step=0157200) Loss: 0.2660 (diff=0.1531, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:28:44[0m] (step=0157300) Loss: 0.2655 (diff=0.1525, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:29:21[0m] (step=0157400) Loss: 0.2710 (diff=0.1586, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:29:58[0m] (step=0157500) Loss: 0.2663 (diff=0.1537, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:30:35[0m] (step=0157600) Loss: 0.2706 (diff=0.1580, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:31:13[0m] (step=0157700) Loss: 0.2707 (diff=0.1583, repa=0.2248, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:31:50[0m] (step=0157800) Loss: 0.2628 (diff=0.1500, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:32:27[0m] (step=0157900) Loss: 0.2699 (diff=0.1577, repa=0.2244, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:33:04[0m] (step=0158000) Loss: 0.2688 (diff=0.1559, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:33:41[0m] (step=0158100) Loss: 0.2627 (diff=0.1494, repa=0.2265, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:34:19[0m] (step=0158200) Loss: 0.2653 (diff=0.1529, repa=0.2248, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:34:56[0m] (step=0158300) Loss: 0.2713 (diff=0.1587, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:35:33[0m] (step=0158400) Loss: 0.2655 (diff=0.1528, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:36:10[0m] (step=0158500) Loss: 0.2722 (diff=0.1597, repa=0.2251, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 05:36:48[0m] (step=0158600) Loss: 0.2701 (diff=0.1572, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:37:25[0m] (step=0158700) Loss: 0.2647 (diff=0.1519, repa=0.2256, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 05:38:02[0m] (step=0158800) Loss: 0.2676 (diff=0.1547, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:38:39[0m] (step=0158900) Loss: 0.2672 (diff=0.1542, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:39:16[0m] (step=0159000) Loss: 0.2707 (diff=0.1579, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:39:54[0m] (step=0159100) Loss: 0.2713 (diff=0.1591, repa=0.2245, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:40:31[0m] (step=0159200) Loss: 0.2627 (diff=0.1496, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:41:08[0m] (step=0159300) Loss: 0.2681 (diff=0.1555, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:41:45[0m] (step=0159400) Loss: 0.2645 (diff=0.1515, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:42:23[0m] (step=0159500) Loss: 0.2699 (diff=0.1572, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:43:00[0m] (step=0159600) Loss: 0.2703 (diff=0.1580, repa=0.2246, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:43:37[0m] (step=0159700) Loss: 0.2699 (diff=0.1570, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:44:14[0m] (step=0159800) Loss: 0.2747 (diff=0.1623, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:44:51[0m] (step=0159900) Loss: 0.2680 (diff=0.1552, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:45:29[0m] (step=0160000) Loss: 0.2664 (diff=0.1533, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:45:29[0m] Saved checkpoint to /data4/haksoo/trm_repa/003-DiT-XL-2/checkpoints/0160000.pt
[[34m2026-02-10 05:46:06[0m] (step=0160100) Loss: 0.2633 (diff=0.1505, repa=0.2256, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 05:46:23[0m] Beginning epoch 8...
[[34m2026-02-10 05:46:44[0m] (step=0160200) Loss: 0.2653 (diff=0.1523, repa=0.2260, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-10 05:47:21[0m] (step=0160300) Loss: 0.2695 (diff=0.1572, repa=0.2247, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:47:59[0m] (step=0160400) Loss: 0.2655 (diff=0.1526, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:48:36[0m] (step=0160500) Loss: 0.2696 (diff=0.1572, repa=0.2247, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:49:13[0m] (step=0160600) Loss: 0.2658 (diff=0.1531, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:49:50[0m] (step=0160700) Loss: 0.2634 (diff=0.1505, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:50:27[0m] (step=0160800) Loss: 0.2676 (diff=0.1548, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:51:05[0m] (step=0160900) Loss: 0.2713 (diff=0.1588, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:51:42[0m] (step=0161000) Loss: 0.2720 (diff=0.1595, repa=0.2249, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:52:19[0m] (step=0161100) Loss: 0.2692 (diff=0.1568, repa=0.2247, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:52:56[0m] (step=0161200) Loss: 0.2675 (diff=0.1551, repa=0.2248, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:53:33[0m] (step=0161300) Loss: 0.2617 (diff=0.1486, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:54:10[0m] (step=0161400) Loss: 0.2671 (diff=0.1542, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:54:48[0m] (step=0161500) Loss: 0.2681 (diff=0.1556, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:55:25[0m] (step=0161600) Loss: 0.2723 (diff=0.1596, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:56:02[0m] (step=0161700) Loss: 0.2725 (diff=0.1597, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:56:39[0m] (step=0161800) Loss: 0.2680 (diff=0.1549, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:57:16[0m] (step=0161900) Loss: 0.2677 (diff=0.1549, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:57:54[0m] (step=0162000) Loss: 0.2646 (diff=0.1517, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:58:31[0m] (step=0162100) Loss: 0.2691 (diff=0.1570, repa=0.2243, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:59:08[0m] (step=0162200) Loss: 0.2680 (diff=0.1554, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 05:59:45[0m] (step=0162300) Loss: 0.2656 (diff=0.1526, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:00:22[0m] (step=0162400) Loss: 0.2639 (diff=0.1511, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:00:59[0m] (step=0162500) Loss: 0.2650 (diff=0.1519, repa=0.2262, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:01:37[0m] (step=0162600) Loss: 0.2667 (diff=0.1540, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:02:14[0m] (step=0162700) Loss: 0.2715 (diff=0.1590, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:02:51[0m] (step=0162800) Loss: 0.2662 (diff=0.1531, repa=0.2261, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:03:28[0m] (step=0162900) Loss: 0.2648 (diff=0.1519, repa=0.2258, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:04:06[0m] (step=0163000) Loss: 0.2655 (diff=0.1528, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:04:43[0m] (step=0163100) Loss: 0.2737 (diff=0.1611, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:05:20[0m] (step=0163200) Loss: 0.2689 (diff=0.1561, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:05:57[0m] (step=0163300) Loss: 0.2701 (diff=0.1572, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:06:34[0m] (step=0163400) Loss: 0.2676 (diff=0.1551, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:07:12[0m] (step=0163500) Loss: 0.2639 (diff=0.1507, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:07:49[0m] (step=0163600) Loss: 0.2620 (diff=0.1490, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:08:26[0m] (step=0163700) Loss: 0.2672 (diff=0.1542, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:09:03[0m] (step=0163800) Loss: 0.2664 (diff=0.1533, repa=0.2263, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:09:40[0m] (step=0163900) Loss: 0.2620 (diff=0.1487, repa=0.2267, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:10:18[0m] (step=0164000) Loss: 0.2685 (diff=0.1558, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:10:55[0m] (step=0164100) Loss: 0.2715 (diff=0.1589, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:11:32[0m] (step=0164200) Loss: 0.2667 (diff=0.1544, repa=0.2246, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:12:09[0m] (step=0164300) Loss: 0.2685 (diff=0.1560, repa=0.2250, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:12:46[0m] (step=0164400) Loss: 0.2645 (diff=0.1518, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 06:13:23[0m] (step=0164500) Loss: 0.2633 (diff=0.1502, repa=0.2263, λ=0.5) Steps/Sec: 2.69
W0210 06:13:56.161000 725276 site-packages/torch/distributed/elastic/agent/server/api.py:739] Received 1 death signal, shutting down workers
W0210 06:13:56.164000 725276 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 725370 closing signal SIGHUP
W0210 06:13:56.166000 725276 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 725371 closing signal SIGHUP
W0210 06:13:56.166000 725276 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 725372 closing signal SIGHUP
W0210 06:13:56.167000 725276 site-packages/torch/distributed/elastic/multiprocessing/api.py:1010] Sending process 725373 closing signal SIGHUP
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 995, in <module>
    main()
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 991, in main
    run(args)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/run.py", line 982, in run
    elastic_launch(
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 170, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 308, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 134, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 731, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 908, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/haksoo/anaconda3/envs/DiT_cu128/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 86, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 725276 got signal: 1

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Starting rank=1, seed=1, world_size=4.
Starting rank=2, seed=2, world_size=4.
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
Starting rank=3, seed=3, world_size=4.
Starting rank=0, seed=0, world_size=4.
[[34m2026-02-10 13:10:05[0m] Experiment directory created at /data4/haksoo/trm_repa/004-DiT-XL-2
[[34m2026-02-10 13:10:05[0m] Loading REPA teacher via torch.hub: facebookresearch/dinov2::dinov2_vitb14
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
Using cache found in /home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/home/haksoo/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
[[34m2026-02-10 13:10:05[0m] using MLP layer as FFN
[[34m2026-02-10 13:10:07[0m] Attached REPA projector: student_dim=1152 -> teacher_dim=768
[[34m2026-02-10 13:10:07[0m] Resumed from /data4/haksoo/trm_repa/003-DiT-XL-2/checkpoints/0160000.pt at step=160000
[[34m2026-02-10 13:10:07[0m] Registered REPA forward hooks on student blocks.
[[34m2026-02-10 13:10:08[0m] DiT Parameters: 30,578,338
[[34m2026-02-10 13:10:10[0m] Dataset contains 1,281,167 images (/data/ImageNet1k/train)
[[34m2026-02-10 13:10:10[0m] Training for 1400 epochs...
[[34m2026-02-10 13:10:10[0m] Beginning epoch 7...
[[34m2026-02-10 13:19:04[0m] (step=0160100) Loss: 0.2692 (diff=0.1567, repa=0.2250, λ=0.5) Steps/Sec: 0.19
[[34m2026-02-10 13:19:32[0m] Beginning epoch 8...
[[34m2026-02-10 13:20:01[0m] (step=0160200) Loss: 0.2665 (diff=0.1536, repa=0.2258, λ=0.5) Steps/Sec: 1.75
[[34m2026-02-10 13:20:38[0m] (step=0160300) Loss: 0.2723 (diff=0.1594, repa=0.2259, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:21:15[0m] (step=0160400) Loss: 0.2681 (diff=0.1553, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:21:53[0m] (step=0160500) Loss: 0.2640 (diff=0.1512, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:22:30[0m] (step=0160600) Loss: 0.2684 (diff=0.1557, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:23:07[0m] (step=0160700) Loss: 0.2687 (diff=0.1560, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:23:44[0m] (step=0160800) Loss: 0.2656 (diff=0.1528, repa=0.2255, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 13:24:22[0m] (step=0160900) Loss: 0.2622 (diff=0.1490, repa=0.2264, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:24:59[0m] (step=0161000) Loss: 0.2697 (diff=0.1572, repa=0.2250, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 13:25:37[0m] (step=0161100) Loss: 0.2673 (diff=0.1543, repa=0.2259, λ=0.5) Steps/Sec: 2.60
[[34m2026-02-10 13:26:15[0m] (step=0161200) Loss: 0.2644 (diff=0.1517, repa=0.2254, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 13:26:52[0m] (step=0161300) Loss: 0.2701 (diff=0.1574, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:27:29[0m] (step=0161400) Loss: 0.2671 (diff=0.1544, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:28:06[0m] (step=0161500) Loss: 0.2713 (diff=0.1587, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:28:43[0m] (step=0161600) Loss: 0.2678 (diff=0.1552, repa=0.2252, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:29:21[0m] (step=0161700) Loss: 0.2700 (diff=0.1572, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:29:58[0m] (step=0161800) Loss: 0.2723 (diff=0.1597, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:30:35[0m] (step=0161900) Loss: 0.2648 (diff=0.1517, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:31:12[0m] (step=0162000) Loss: 0.2696 (diff=0.1569, repa=0.2253, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:31:49[0m] (step=0162100) Loss: 0.2693 (diff=0.1565, repa=0.2256, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:32:27[0m] (step=0162200) Loss: 0.2625 (diff=0.1495, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:33:04[0m] (step=0162300) Loss: 0.2682 (diff=0.1555, repa=0.2254, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:33:41[0m] (step=0162400) Loss: 0.2656 (diff=0.1531, repa=0.2251, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:34:18[0m] (step=0162500) Loss: 0.2686 (diff=0.1559, repa=0.2255, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:34:55[0m] (step=0162600) Loss: 0.2676 (diff=0.1546, repa=0.2260, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:35:33[0m] (step=0162700) Loss: 0.2649 (diff=0.1521, repa=0.2257, λ=0.5) Steps/Sec: 2.69
[[34m2026-02-10 13:36:10[0m] (step=0162800) Loss: 0.2624 (diff=0.1493, repa=0.2262, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 13:36:48[0m] (step=0162900) Loss: 0.2679 (diff=0.1551, repa=0.2256, λ=0.5) Steps/Sec: 2.62
[[34m2026-02-10 13:37:26[0m] (step=0163000) Loss: 0.2705 (diff=0.1585, repa=0.2240, λ=0.5) Steps/Sec: 2.64
[[34m2026-02-10 13:38:03[0m] (step=0163100) Loss: 0.2693 (diff=0.1566, repa=0.2254, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 13:38:41[0m] (step=0163200) Loss: 0.2685 (diff=0.1558, repa=0.2254, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-10 13:39:18[0m] (step=0163300) Loss: 0.2712 (diff=0.1585, repa=0.2255, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-10 13:39:55[0m] (step=0163400) Loss: 0.2707 (diff=0.1580, repa=0.2254, λ=0.5) Steps/Sec: 2.67
[[34m2026-02-10 13:40:33[0m] (step=0163500) Loss: 0.2639 (diff=0.1511, repa=0.2255, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:41:11[0m] (step=0163600) Loss: 0.2686 (diff=0.1558, repa=0.2254, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 13:41:48[0m] (step=0163700) Loss: 0.2727 (diff=0.1601, repa=0.2252, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:42:26[0m] (step=0163800) Loss: 0.2617 (diff=0.1484, repa=0.2266, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 13:43:04[0m] (step=0163900) Loss: 0.2681 (diff=0.1552, repa=0.2258, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 13:43:41[0m] (step=0164000) Loss: 0.2694 (diff=0.1572, repa=0.2244, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:44:19[0m] (step=0164100) Loss: 0.2680 (diff=0.1550, repa=0.2261, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 13:44:57[0m] (step=0164200) Loss: 0.2662 (diff=0.1530, repa=0.2262, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:45:35[0m] (step=0164300) Loss: 0.2703 (diff=0.1581, repa=0.2244, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 13:46:12[0m] (step=0164400) Loss: 0.2690 (diff=0.1563, repa=0.2253, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:46:50[0m] (step=0164500) Loss: 0.2713 (diff=0.1588, repa=0.2251, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:47:27[0m] (step=0164600) Loss: 0.2760 (diff=0.1636, repa=0.2248, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:48:05[0m] (step=0164700) Loss: 0.2731 (diff=0.1607, repa=0.2250, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:48:43[0m] (step=0164800) Loss: 0.2689 (diff=0.1561, repa=0.2255, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:49:20[0m] (step=0164900) Loss: 0.2636 (diff=0.1503, repa=0.2267, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:49:58[0m] (step=0165000) Loss: 0.2706 (diff=0.1579, repa=0.2253, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:50:35[0m] (step=0165100) Loss: 0.2744 (diff=0.1619, repa=0.2250, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 13:51:13[0m] (step=0165200) Loss: 0.2679 (diff=0.1552, repa=0.2254, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 13:51:51[0m] (step=0165300) Loss: 0.2591 (diff=0.1464, repa=0.2254, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:52:28[0m] (step=0165400) Loss: 0.2649 (diff=0.1518, repa=0.2263, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:53:06[0m] (step=0165500) Loss: 0.2710 (diff=0.1584, repa=0.2253, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:53:44[0m] (step=0165600) Loss: 0.2713 (diff=0.1589, repa=0.2248, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:54:21[0m] (step=0165700) Loss: 0.2712 (diff=0.1588, repa=0.2249, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:54:59[0m] (step=0165800) Loss: 0.2643 (diff=0.1511, repa=0.2264, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:55:36[0m] (step=0165900) Loss: 0.2640 (diff=0.1513, repa=0.2254, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:56:14[0m] (step=0166000) Loss: 0.2678 (diff=0.1553, repa=0.2250, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:56:52[0m] (step=0166100) Loss: 0.2674 (diff=0.1550, repa=0.2250, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:57:29[0m] (step=0166200) Loss: 0.2675 (diff=0.1549, repa=0.2252, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:58:07[0m] (step=0166300) Loss: 0.2716 (diff=0.1593, repa=0.2247, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:58:44[0m] (step=0166400) Loss: 0.2618 (diff=0.1492, repa=0.2252, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 13:59:22[0m] (step=0166500) Loss: 0.2672 (diff=0.1544, repa=0.2256, λ=0.5) Steps/Sec: 2.68
[[34m2026-02-10 14:00:06[0m] (step=0166600) Loss: 0.2732 (diff=0.1608, repa=0.2247, λ=0.5) Steps/Sec: 2.26
[[34m2026-02-10 14:00:50[0m] (step=0166700) Loss: 0.2698 (diff=0.1571, repa=0.2254, λ=0.5) Steps/Sec: 2.25
[[34m2026-02-10 14:01:31[0m] (step=0166800) Loss: 0.2703 (diff=0.1576, repa=0.2252, λ=0.5) Steps/Sec: 2.47
[[34m2026-02-10 14:02:09[0m] (step=0166900) Loss: 0.2679 (diff=0.1551, repa=0.2256, λ=0.5) Steps/Sec: 2.62
[[34m2026-02-10 14:02:47[0m] (step=0167000) Loss: 0.2717 (diff=0.1588, repa=0.2256, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 14:03:24[0m] (step=0167100) Loss: 0.2684 (diff=0.1554, repa=0.2259, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 14:04:02[0m] (step=0167200) Loss: 0.2697 (diff=0.1568, repa=0.2258, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 14:04:40[0m] (step=0167300) Loss: 0.2661 (diff=0.1535, repa=0.2253, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 14:05:17[0m] (step=0167400) Loss: 0.2678 (diff=0.1547, repa=0.2262, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 14:05:55[0m] (step=0167500) Loss: 0.2671 (diff=0.1544, repa=0.2255, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 14:06:33[0m] (step=0167600) Loss: 0.2666 (diff=0.1538, repa=0.2256, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 14:07:10[0m] (step=0167700) Loss: 0.2683 (diff=0.1560, repa=0.2245, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 14:07:48[0m] (step=0167800) Loss: 0.2624 (diff=0.1496, repa=0.2256, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 14:08:26[0m] (step=0167900) Loss: 0.2667 (diff=0.1539, repa=0.2255, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 14:09:04[0m] (step=0168000) Loss: 0.2742 (diff=0.1619, repa=0.2246, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 14:09:41[0m] (step=0168100) Loss: 0.2670 (diff=0.1542, repa=0.2256, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 14:10:19[0m] (step=0168200) Loss: 0.2702 (diff=0.1574, repa=0.2257, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 14:10:57[0m] (step=0168300) Loss: 0.2690 (diff=0.1559, repa=0.2261, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 14:11:34[0m] (step=0168400) Loss: 0.2687 (diff=0.1561, repa=0.2253, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 14:12:12[0m] (step=0168500) Loss: 0.2640 (diff=0.1508, repa=0.2265, λ=0.5) Steps/Sec: 2.66
[[34m2026-02-10 14:12:49[0m] (step=0168600) Loss: 0.2639 (diff=0.1511, repa=0.2256, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 14:13:27[0m] (step=0168700) Loss: 0.2706 (diff=0.1580, repa=0.2254, λ=0.5) Steps/Sec: 2.65
[[34m2026-02-10 14:14:05[0m] (step=0168800) Loss: 0.2716 (diff=0.1589, repa=0.2255, λ=0.5) Steps/Sec: 2.66
